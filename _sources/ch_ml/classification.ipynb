{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vulnerable-palestine",
   "metadata": {},
   "source": [
    "# 3.1. Hồi qui Logistic\n",
    "\n",
    "Các mô hình phân loại đều tìm cách xác định một đường biên phân chia tốt nhất các nhóm giữa liệu. Trong hồi qui logistic chúng ta cũng tìm kiếm một đường biên phân chia như vậy để phân loại tốt nhóm 0 và 1.\n",
    "\n",
    "![](https://i.imgur.com/pVWaYTt.jpeg)\n",
    "\n",
    "Trong hồi qui tuyến tính chúng ta đưa ra một hàm hồi qui giả thuyết $h_{\\mathbf{w}}(\\mathbf{x}) = \\mathbf{w}^{\\intercal}\\mathbf{x}$ để dự báo biến mục tiêu $y$. Giá trị của chúng có thể vượt ngoài khoảng $[0, 1]$ nên trong hồi qui Logistic cần một hàm số để ràng buộc giá trị đầu ra nằm trong khoảng $[0, 1]$ và đồng thời tạo ra tính phi tuyến cho phương trình hồi qui nhằm giúp nó có đường biên phân chia giữa hai nhóm tốt hơn. Đó chính là hàm Sigmoid hoặc hàm Logistic mà chúng ta sẽ tìm hiểu bên dưới."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-desert",
   "metadata": {
    "id": "wzQ6jhzW4n_C"
   },
   "source": [
    "## 3.1.1. Hàm sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-review",
   "metadata": {
    "id": "Br8J8GMg0WiV"
   },
   "source": [
    "Mô hình hồi qui _Logistic_ là sự tiếp nối ý tưởng của hồi qui tuyến tính vào các bài toán phân loại. Từ đầu ra của hàm tuyến tính chúng ta đưa vào hàm _Sigmoid_ để tìm ra phân phối xác suất của dữ liệu. Hàm _Sigmoid_ có công thức:\n",
    "\n",
    "$$\\sigma{(x)} = \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-correction",
   "metadata": {
    "id": "gezIHUFopOkP"
   },
   "source": [
    "Bên dưới là khảo sát sơ bộ của hàm _Sigmoid_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "capable-testimony",
   "metadata": {
    "id": "0P9ueJOApW_m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-10, 10, 200)\n",
    "\n",
    "def _sigmoid(x):\n",
    "  s = 1/(1+np.exp(-x))\n",
    "  return s\n",
    "\n",
    "# Xác suất dự báo từ hàm sigmoid\n",
    "y = [_sigmoid(xi) for xi in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-allergy",
   "metadata": {
    "id": "tDVToZN8pdsW"
   },
   "source": [
    "Vẽ đồ thị hàm _Sigmoid_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "possible-orchestra",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "jn7Rjr-Iludw",
    "outputId": "462a1dd1-5435-44fe-e8c1-7cd864e45fae"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4fe9b451803c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize hàm sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize hàm sigmoid\n",
    "\n",
    "plt.figure(figsize = (16, 8))\n",
    "plt.plot(x, y, marker = 'o')\n",
    "plt.axvline(0)\n",
    "plt.text(0.0, 0.3, \"x=0.5\")\n",
    "plt.axhline(1, color=\"green\")\n",
    "plt.text(-7.5, 0.9, \"y=1.0\")\n",
    "plt.axhline(0, color=\"red\")\n",
    "plt.text(-7.5, 0.05, \"y=0.0\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-video",
   "metadata": {
    "id": "FzDvnkLUljoY"
   },
   "source": [
    "Ta nhận thấy: Hàm `Sigmoid` có hình dạng là một **đường cong chữ `S`** và **đơn điệu tăng**. Chính vì thế nên nó còn có tên một tên gọi khác là hàm chữ `S`. Một vài tài liệu còn gọi nó là hàm `Logistic` đại diện cho hồi qui `Logistic`.\n",
    "\n",
    "Ngoài ra ta dễ dàng chứng minh giá trị của hàm `Sigmoid` nằm trong khoảng $[0, 1]$. Thật vậy:\n",
    "\n",
    "$$\\lim_{x \\rightarrow +\\infty} \\sigma(x) = \\lim_{x \\rightarrow +\\infty} \\frac{1}{1+e^{-x}}=1$$\n",
    "\n",
    "và\n",
    "\n",
    "$$\\lim_{x \\rightarrow -\\infty} \\sigma(x) = \\lim_{x \\rightarrow -\\infty} \\frac{1}{1+e^{-x}}=0$$\n",
    "\n",
    "Do đó hàm `Sigmoid` rất phù hợp để áp dụng vào dự báo xác suất ở các bài toán phân loại.\n",
    "\n",
    "Quay trở lại với bài toán hồi qui tuyến tính. Với 2 biến đầu vào dự báo là $\\mathbf{x} = (x_1, x_2)$ ta thu được một hàm hồi qui:\n",
    "\n",
    "$$\\hat{y} = g(x) = w_0 + w_1 x_1 + w_2 x_2 = \\mathbf{w}^{\\intercal}\\mathbf{x}$$\n",
    "\n",
    "Ở đây $\\mathbf{w} = (w_0, w_1, w_2)$ là véc tơ dòng của các hệ số hồi qui.\n",
    "\n",
    "Chuyển tiếp giá trị này qua hàm _Sigmoid_ để dự báo xác suất và tạo tính phi tuyến cho mô hình hồi qui:\n",
    "\n",
    "$$P(y=1 | \\mathbf{x}, \\mathbf{w}) = \\sigma(\\mathbf{w}^\\intercal\\mathbf{x}) = \\frac{1}{1+e^{-\\mathbf{w}^\\intercal\\mathbf{x}}}$$\n",
    "\n",
    "\n",
    "Ở công thức trên thì $P(y=1 | \\mathbf{x}, \\mathbf{w})$ chính là xác suất có điều kiện của $y=1$ khi đã biết quan sát đầu vào $\\mathbf{x}$, và trọng số $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-monaco",
   "metadata": {
    "id": "9dNMYo2gDIwb"
   },
   "source": [
    "## 3.1.2. Đường biên phân chia của hàm Sigmoid\n",
    "\n",
    "Trong bài toán phân loại nhị phân chúng ta sẽ lựa chọn một ngưỡng threshold về xác suất để đưa ra dự báo nhãn cho một quan sát. Giả định ta chọn ngưỡng xác suất là 0.5. Khi đó dự báo nhãn sẽ là:\n",
    "\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "0 \\text{ if } P(y=1|\\mathbf{x}, \\mathbf{w}) \\leq 0.5 \\\\\n",
    "1 \\text{ if } P(y=1|\\mathbf{x}, \\mathbf{w}) > 0.5\n",
    "\\end{matrix}\n",
    "\\right.$$\n",
    "\n",
    "* Trong trường hợp $y=1$:\n",
    "\n",
    "$$\\begin{eqnarray}h_{\\mathbf{w}}(\\mathbf{x}) & > & 0.5 \\\\\n",
    "& \\leftrightarrow & \\frac{1}{1+e^{-\\mathbf{w}^{\\intercal}\\mathbf{x}}} > 0.5 \\\\\n",
    "& \\leftrightarrow & e^{-\\mathbf{w}^{\\intercal}\\mathbf{x}} < 1 \\\\\n",
    "& \\leftrightarrow & \\mathbf{w}^{\\intercal}\\mathbf{x} > 0 \\\\\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "* Trong trường hợp $y=0$:\n",
    "\n",
    "$$\\begin{eqnarray}h_{\\mathbf{w}}(\\mathbf{x}) & \\leq & 0.5 \\\\\n",
    "& \\leftrightarrow & \\frac{1}{1+e^{-\\mathbf{w}^{\\intercal}\\mathbf{x}}} \\leq 0.5 \\\\\n",
    "& \\leftrightarrow & e^{-\\mathbf{w}^{\\intercal}\\mathbf{x}} \\geq 1 \\\\\n",
    "& \\leftrightarrow & \\mathbf{w}^{\\intercal}\\mathbf{x} \\leq 0 \\\\\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Như vậy ta có thể nhận ra những điểm thuộc về nhãn 1 sẽ nằm bên phải đường biên phân chia $\\mathbf{w}\\mathbf{x}$ trong khi những điểm thuộc về nhãn 1 sẽ nằm bên phải. Đồng thời đường biên phân chia hai nhãn 0 và 1 cũng là một phương trình tuyến tính."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-freeware",
   "metadata": {
    "id": "gMMSHO8DIAvS"
   },
   "source": [
    "## 3.1.3. Chỉ số Odd ratio\n",
    "\n",
    "Odd ratio là một chỉ số đo lường tỷ lệ xác suất giữa trường hợp _tích cực_ và _tiêu cực_ được dự báo từ mô hình hồi qui logistic. Một dự đoán có tỷ lệ Odd ratio càng lớn thì khả năng rơi vào nhãn _tích cực_ sẽ càng cao. Nếu Odd ratio > 1 thì mẫu được dự báo có xác suất thuộc nhãn _tích cực_ là lớn hơn so với _tiêu cực_ và ngược lại.\n",
    "\n",
    "$$\\text{Odd Ratio} = \\frac{P(y=1|\\mathbf{x}, \\mathbf{w})}{P(y=0|\\mathbf{x}, \\mathbf{w})} = \\frac{P(y=1|\\mathbf{x}, \\mathbf{w})}{1-P(y=1|\\mathbf{x}, \\mathbf{w})} = e^{-\\mathbf{w}^{\\intercal}\\mathbf{x}}$$\n",
    "\n",
    "Ngoài ra ta thường căn cứ vào log Odd Ratio để nhận biết xác suất _tích cực_ hay _tiêu cực_ lớn hơn. Tức là so sánh $\\mathbf{w}^{\\intercal}\\mathbf{x}$ với 0 để đưa ra kết luận."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-traveler",
   "metadata": {
    "id": "ammHUmEBNpfb"
   },
   "source": [
    "## 3.1.4. Biểu diễn đồ thị của hồi qui logistic\n",
    "\n",
    "Chúng ta có thể xem hàm Sigmoid là một hàm hạt nhân (_kernel function_) giúp biến đổi giá trị đầu ra. Chúng ta sẽ còn gặp lại khái niệm về hàm hạt nhân này ở nhiều lớp mô hình khác như Softmax, MLP, SVM, ....\n",
    "\n",
    "Dưới góc nhìn của graphic model thì mô hình Logistic regression có dạng như sau:\n",
    "\n",
    "![](https://imgur.com/ppnjQrY.png)\n",
    "\n",
    "Đồ thị trên sẽ bao gồm hai bước:\n",
    "\n",
    "* **Bước 1**: Kết hợp tuyến tính.\n",
    "\n",
    "Mỗi một node đại diễn cho 1 biến đầu vào. Các cạnh sẽ có hình mũi tên thể hiện hướng tính toán của đồ thị. Đầu vào sẽ là node ở gốc mũi tên và đầu ra là node ở ngọn mũi tên? Giá trị này sẽ được điều tiết bằng cách nhân với hệ số $w_i$. Cuối cùng ta sẽ kết hợp tuyến tính các nodes đầu vào để tính ra đầu ra $\\hat{y}$.\n",
    "\n",
    "Về căn bản bước này tương đương với quá trình dự báo trong hồi qui tuyến tính.\n",
    "\n",
    "\n",
    "* **Bước 2**: Biểu diễn hàm sigmoid.\n",
    "\n",
    "Giá trị $\\hat{y}$ lại tiếp tục được đưa qua hàm $\\sigma$ để tính ra xác suất $P(y=1)$ ở output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-salmon",
   "metadata": {
    "id": "fOSHmUX2kiRP"
   },
   "source": [
    "## 3.1.5. Xác suất của Logistic và phân phối Bernoulli\n",
    "\n",
    "Chúng ta còn nhớ về phân phối Bernoulli chứ? Giả sử một sự kiện vỡ nợ xảy ra với xác suất là $p$. Phân phối Bernoulli cho chúng ta biết xác suất xảy ra của sự kiện khi thực hiện một phép thử như sau:\n",
    "\n",
    "\n",
    "$$P(X=k)={\\begin{cases}p&{\\text{if }}k=1,\\\\[6pt]1-p&{\\text{if }}k=0.\\end{cases}}$$\n",
    "\n",
    "\n",
    "Tìm hiểu thêm về phân phối Bernoulli tại [Chương 2, phân phối xác suất Bernoulli](https://phamdinhkhanh.github.io/deepai-book/ch_probability/appendix_probability.html#phan-phoi-bernoulli).\n",
    "\n",
    "\n",
    "Như vậy xác suất trong bài toán phân loại nhị phân tuân theo phân phối Bernoulli. Chúng ta còn có thể khái quát hoá xác suất này qua phương trình tổng quát cho cả hai trường hợp $0$ và $1$ như sau:\n",
    "\n",
    "$$P(X=k) = p^{k}(1-p)^{1-k} \\tag{1}$$\n",
    "\n",
    "Thật vậy, trường hợp $k=1$ thì:\n",
    "\n",
    "$$P(X=1)=p^{1}(1-p)^{0} = p$$\n",
    "\n",
    "và tương tự với trường hợp $k=0$ ta cũng có:\n",
    "\n",
    "$$P(X=0)=p^{0}(1-p)^{1} = 1-p$$\n",
    "\n",
    "Xác suất xảy ra của điểm $\\mathbf{x}_i$ theo hàm Sigmoid:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "    P(y=1| \\mathbf{x}_i) &=& \\sigma(\\mathbf{w}^\\intercal\\mathbf{x}_i)~~~ \\\\\n",
    "    P(y=0| \\mathbf{x}_i) &=& 1-\\sigma(\\mathbf{w}^\\intercal\\mathbf{x}_i)~~~ \n",
    "\\end{matrix}\n",
    "\\right.$$\n",
    "\n",
    "Như vậy trong mô hình hồi qui Logistic, xác suất tổng quát cho một mẫu cho cả hai trường hợp $\\{0, 1 \\}$ sẽ là:\n",
    "\n",
    "$$P(y_i|\\mathbf{x}_i, \\mathbf{w}) = P(y=1)^{y_i}(1-P(y=1))^{(1-y_i)}$$\n",
    "\n",
    "Ở trên là xác suất tại một điểm dữ liệu. Giả sử các quan sát trong bộ dữ liệu của chúng ta là độc lập. Khi đó xác suất đồng thời của toàn bộ các quan sát trong bộ dữ liệu sẽ bằng tích các xác suất tại từng điểm dữ liệu và bằng:\n",
    "\n",
    "$$P(\\mathbf{y}|\\mathbf{X}, \\mathbf{w}) = \\prod_{i=1}^{n} P(y_i|\\mathbf{x}_i; \\mathbf{w}) \\tag{2}$$\n",
    "\n",
    "Vế phải của biểu thức $(2)$ chính là một hàm Likelihood đo lường mức độ hợp lý (_goodness of fit_) của mô hình thống kê đối với dữ liệu. \n",
    "\n",
    "Chúng ta kỳ vọng giá trị của Likelihood phải lớn. Điều đó đồng nghĩa với các trường hợp _tích cực_ phải có xác suất càng gần 1 và _tiêu cực_ có xác suất gần bằng 0. Do đó mục tiêu của chúng ta là tìm $\\mathbf{w}$ sao cho biểu thức (2) là lớn nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-riverside",
   "metadata": {
    "id": "vv5TQ7fWM1R-"
   },
   "source": [
    "## 3.1.6. Ước lượng hợp lý cực đại (_Maximum Likelihood Estimation_) và Hàm Cross Entropy\n",
    "\n",
    "Như vậy quá trình tìm nghiệm $\\mathbf{w}$ thực chất là giải bài toán tối ưu hàm hợp lý (_Maximum Likelihood Function_). Phương pháp tìm nghiệm $\\mathbf{w}$ dựa trên hàm hợp lý còn được gọi là ước lượng hợp lý cực đại (_Maximum Likelihood Function_). \n",
    "\n",
    "Do đó việc tối ưu trực tiếp $(2)$ là khó khăn nên chúng ta sẽ logarith để chuyển tích sang tổng để tối ưu nhẹ nhàng hơn. Khi đó qui về bài toán tối ưu hàm _Log Likelihood_ như sau:\n",
    "\n",
    "$$\\begin{eqnarray}\\log P(y_i|\\mathbf{x}_i; \\mathbf{w}) & = & \\log [P(y=1)^{y_i}(1-P(y=1))^{(1-y_i)}] \\\\\n",
    "& = & y_i\\log P(y=1) + (1-y_i)\\log (1-P(y=1))\\end{eqnarray}$$\n",
    "\n",
    "Việc tìm giá trị cực đại của phương trình (2) tương ứng với bài toán tối ưu:\n",
    "\n",
    "$$\\begin{eqnarray}\\hat{\\mathbf{w}} & = & \\arg \\max_{\\mathbf{w}} ~~~ \\log(\\prod_{i=1}^{n} P(y_i|\\mathbf{x}_i; \\mathbf{w})) \\\\\n",
    "& = & \\arg \\max_{\\mathbf{w}} \\sum_{i=1}^{n} y_i\\log(P(y_i=1)) + (1-y_i)\\log(1-P(y_i=1)) \\\\\n",
    "& = & \\arg \\min_{\\mathbf{w}} \\sum_{i=1}^{n} -[y_i\\log(\\hat{y_i}) + (1-y_i)\\log(1-\\hat{y}_i)] \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Ở đây $\\hat{y}_i = P(y_i=1)$ là ước lượng xác suất tại điểm $\\mathbf{x}_i$. Từ dòng 2 chuyển sang dòng 3 là vì chúng ta đổi dấu. Khi đó hàm mất mát (_Loss function_) sẽ có dạng: \n",
    "\n",
    "$$\\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\sum_{i=1}^{n} -[y_i\\log(\\hat{y_i}) + (1-y_i)\\log(1-\\hat{y}_i)]$$\n",
    "\n",
    "Hàm mất mát trên còn được gọi là hàm _Cross Entropy_. Nó là một độ đo (_metric_) đo lường mức độ tương quan giữa phân phối xác suất dự báo $(\\hat{y}_i, 1-\\hat{y}_i)$ và phân phối xác suất thực tế $(y_i, 1-y_i)$. Giá trị của _Cross Entropy_ sẽ càng nhỏ nếu hai phân phối xác suất càng sát nhau, tức là giá trị dự báo  giống với thực tế nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-database",
   "metadata": {
    "id": "0vRczGvjImRs"
   },
   "source": [
    "Để minh chứng cho nhận định trên chúng ta sẽ mô phỏng hàm cross-entropy cho các trường hợp $y=0, 1$ và $0.5$. Cho $\\hat{y}$ di chuyển liên tục trong khoảng từ $[0, 1]$ và tính giá trị của cross-entropy. Sau đó biểu diễn trên đồ thị để tìm cực trị."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-happiness",
   "metadata": {
    "id": "72KoOpjIIf9W"
   },
   "source": [
    "* Trường hợp $y=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-ideal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "RAeYHpf5Wa63",
    "outputId": "5acea871-0e0e-4aa9-80f1-9fc9ab5d5754"
   },
   "outputs": [],
   "source": [
    "# Tính cross entropy theo yhat và y\n",
    "def _cross_entropy(yhat, y):\n",
    "  return -(y*np.log(yhat)+(1-y)*np.log((1-yhat)))\n",
    "# Khởi tạo gía trị yhat từ 0 đến 1\n",
    "yhat = np.linspace(0.001, 0.999, 200)\n",
    "\n",
    "# Hàm visualize cross entropy\n",
    "def _plot_crs(yhat, y):\n",
    "  cross_entropy = _cross_entropy(yhat, y)\n",
    "  plt.figure(figsize = (8, 4))\n",
    "  plt.plot(yhat, cross_entropy)\n",
    "  plt.xlabel('yhat')\n",
    "  plt.ylabel('cross entropy')\n",
    "  plt.title('Cross Entropy With y={}'.format(y))\n",
    "  plt.show()\n",
    "\n",
    "_plot_crs(yhat, y=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-submission",
   "metadata": {
    "id": "O2rJbsZ4LQfx"
   },
   "source": [
    "* Trường hợp $y=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-sympathy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "B18LgUkKZws0",
    "outputId": "83e8d712-1132-4d31-e2fa-938b4a0b786d"
   },
   "outputs": [],
   "source": [
    "_plot_crs(yhat, y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-scene",
   "metadata": {
    "id": "vd98XZ5fLUyq"
   },
   "source": [
    "* Trường hợp $y=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-unknown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "GxqTlVsIaDCu",
    "outputId": "d7c71b90-39ca-4611-ad85-ffe77da9ad5f"
   },
   "outputs": [],
   "source": [
    "_plot_crs(yhat, y=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-reader",
   "metadata": {
    "id": "oudULqIsagdy"
   },
   "source": [
    "Biểu đồ chung cho cả 3 trường hợp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-public",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "NdSdOLmYaf1L",
    "outputId": "8121fdeb-791d-47bf-cd25-5d2ff3d327d5"
   },
   "outputs": [],
   "source": [
    "crs1 = _cross_entropy(yhat, y=0.5)\n",
    "crs2 = _cross_entropy(yhat, y=0.7)\n",
    "crs3 = _cross_entropy(yhat, y=0.1)\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot(yhat, crs1, label='y=0.5')\n",
    "plt.plot(yhat, crs2, label='y=0.7')\n",
    "plt.plot(yhat, crs3, label='y=0.1')\n",
    "plt.xlabel('yhat')\n",
    "plt.ylabel('cross entropy')\n",
    "plt.title('Cross Entropy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-patrick",
   "metadata": {
    "id": "aedlJyANLd15"
   },
   "source": [
    "Như vậy ta nhận thấy giá trị cực tiểu của hàm cross entropy luôn đạt được tại $y=\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-yield",
   "metadata": {
    "id": "kBilKolTIEPw"
   },
   "source": [
    "## 3.1.7. Điều kiện cực trị của Cross Entropy\n",
    "\n",
    "Để chứng minh cho nhận định giá trị của _Cross Entropy_ đạt cực tiểu tại $y = \\hat{y}$ không quá khó. Ở phần này tôi sẽ đưa ra một chứng minh trực quan cho bạn nào yêu toán bằng phương pháp Lagrange. Đối với những bạn không thực sự quan tâm tới toán có thể bỏ qua."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-scoop",
   "metadata": {
    "id": "mkFF3r6v7dA2"
   },
   "source": [
    "### 3.1.7.1. Phương pháp nhân tử Lagrange (_Lagrange multiplier_)\n",
    "\n",
    "Để giải bài toán cực trị của hàm _Cross Entropy_ thì chúng ta phải làm quen với phương pháp _nhân tử Lagrange_ trong tối ưu. Đây là một phương pháp giúp tìm kiếm cực trị địa phương cho các hàm mục tiêu $f(\\mathbf{x})$ đi kèm với điều kiện ràng buộc là những đẳng thức hoặc bất đẳng thức đối với $\\mathbf{x}$. Ví dụ về bài toán tối ưu với điều kiện ràng buộc:\n",
    "\n",
    "$$\\mathbf{x} = \\arg \\min_{\\mathbf{x}} f(\\mathbf{x})$$\n",
    "\n",
    "Thoả mãn: $g(\\mathbf{x}) = 0$\n",
    "\n",
    "Trong đó $g(\\mathbf{x}) = 0$ được gọi là điều kiện ràng buộc. Một bài toán có thể có một hoặc nhiều điều kiện ràng buộc. Chúng ta gọi chung những điều kiện mà $\\mathbf{x}$ cần thoả mãn là hệ điều kiện ràng buộc.\n",
    "\n",
    "Ý tưởng của phương pháp _nhân tử Lagrange_ là chuyển từ bài toán ràng buộc sang bài toán không ràng buộc và sử dụng khảo sát đạo hàm bậc nhất hàm Lagrange có dạng:\n",
    "\n",
    "$$\\mathcal{L}(\\lambda, x_1, x_2) = f(\\mathbf{x}) + \\lambda g(\\mathbf{x})$$\n",
    "\n",
    "với $\\lambda \\geq 0$.\n",
    "\n",
    "Thông qua tính đạo hàm bậc nhất theo $\\lambda$ thì các điều kiện ràng buộc sẽ được thoả mãn. Do đó chúng ta không cần thêm điều kiện ràng buộc. Bên dưới là ứng dụng của phương pháp nhân tử Lagrange để giải bài toán tối ưu.  \n",
    "\n",
    "\n",
    "### 3.1.7.2. Điều kiện để Cross Entropy là cực trị\n",
    "\n",
    "Giả sử $\\mathbf{y} = [y_1, ..., y_C]$ là phân phối xác suất ground truth đã biết và $\\hat{\\mathbf{y}} = [\\hat{y}_1, \\dots , \\hat{y}_C]$ là phân phối xác suất dự báo thỏa mãn điều kiện ràng buộc $\\sum_{i=1}^{C} \\hat{y}_i = 1$. Tìm nghiệm tối ưu của hàm cross entropy:\n",
    "\n",
    "$$f(\\mathbf{\\hat{y}}|\\mathbf{y}) = \\sum_{i=1}^C {-y_i\\log(\\hat{y_i})}$$\n",
    "\n",
    "Ta có hàm lagrange:\n",
    "\n",
    "$$\\begin{eqnarray}\\mathcal{L}(\\lambda, \\mathbf{\\hat{y}}) & = & f(\\mathbf{\\hat{y}}|\\mathbf{y}) + \\lambda (1-\\sum_{i=1}^{C} \\hat{y}_i) \\\\\n",
    "& = & \\sum_{i=1}^C {-y_i\\log(\\hat{y_i})} + \\lambda (1-\\sum_{i=1}^{C} \\hat{y}_i) \\end{eqnarray}$$\n",
    "\n",
    "Hệ phương trình đạo hàm bậc nhất theo các biến $\\hat{y}_i, \\lambda$ ta được:\n",
    "\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "    \\nabla_{\\hat{y}_i} \\mathcal{L}(\\lambda, \\mathbf{\\hat{y}}) &=& - {\\frac{y_i}{\\hat{y_i}}} - \\lambda~~~ &, \\forall i=\\overline{1, C} ~~~ \\\\\n",
    "    \\nabla_{\\lambda} \\mathcal{L}(\\lambda, \\mathbf{\\hat{y}}) &=& 1-\\sum_{i=1}^{C} \\hat{y}_i & ~~~ \n",
    "\\end{matrix}\n",
    "\\right.$$\n",
    "\n",
    "Giải phương trình đạo hàm bậc nhất bằng 0 ta suy ra nghiệm $y_i = \\hat{y}_i, \\forall i=\\overline{1, C}$. Tức là phân phối xác suất dự báo $\\hat{\\mathbf{y}}$ phải bằng ground truth $\\mathbf{y}$. Đây chính là lý do vì sao chúng ta coi _Cross Entropy_ là một độ đo mức độ tương đồng giữa phân phối xác suất của giá trị dự báo và ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-horizontal",
   "metadata": {
    "id": "gcbWYD1N8UpQ"
   },
   "source": [
    "# 3.2. Tìm nghiệm tối ưu bằng hạ dốc (_gradient descent_)\n",
    "\n",
    "Phương pháp hạ dốc (_gradient descent_) là một kỹ thuật quan trọng trong học máy và đặc biệt là học sâu, giúp ta tìm cực trị địa phương của mọi hàm số dựa trên gradient. Trên thực tế việc tìm ra được lời giải chính xác cho một số dạng hàm mất mát là không dễ dàng, đặc biệt là những hàm số có đạo hàm quá phức tạp và những hàm không lồi. Do đó _phương pháp hạ dốc_ là một trong những lựa chọn tốt nhất để tiến dần đến cực trị cho những bài toán như vậy. Tuy nhiên hạn chế của phương pháp này đó là cực trị tìm được chỉ là nghiệm gần đúng và không đảm bảo chắc chắn là cực trị toàn cục. \n",
    "\n",
    "Để hiểu về phương pháp hạ dốc là gì chúng ta sẽ cùng phân tích một ví dụ đơn giản đó là bài toán tìm cực trị của hàm $f(x) = x^2-2x+5$ .\n",
    "\n",
    "Hàm này có đạo hàm là $f'(x) = 2x-2$\n",
    "\n",
    "Không khó để phát hiện ra $f'(x)$ có nghiệm $x=1$ và là hàm lồi tại nghiệm đó nên nó có cực tiểu là $(x*, y*)=(1, 5)$.\n",
    "\n",
    "Tiếp theo ta sẽ vẽ đồ thị của hàm số này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-porcelain",
   "metadata": {
    "id": "BNEUnjfMgcps"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Khởi tạo x\n",
    "x = np.arange(-9, 11, 0.1)\n",
    "\n",
    "def _f(x):\n",
    "  return x**2-2*x+5\n",
    "\n",
    "# Tính f(x)\n",
    "y = _f(x)\n",
    "# Đạo hàm f'(x)\n",
    "y_grad = 2*x-2\n",
    "\n",
    "# Lấy ra các điểm ngẫu nhiên\n",
    "x0, y0 = x[10], y[10]\n",
    "x1, y1 = x[-20], y[-20]\n",
    "\n",
    "# Cực tiểu của hàm số\n",
    "x_star=1\n",
    "y_star=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-castle",
   "metadata": {
    "id": "4Xu2BcMBgxOs"
   },
   "source": [
    "Vẽ đồ thị"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-arkansas",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "5OHbCroQgydG",
    "outputId": "0b70db46-a0d6-4ddf-80f5-71b9ea3666ce"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(x, y)\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.plot(x0, y0, marker=\"o\", markersize=15, color=\"red\")\n",
    "plt.text(x0, y0, \"(x0, y0)\")\n",
    "plt.plot(x1, y1, marker=\"o\", markersize=15, color=\"blue\")\n",
    "plt.text(x1, y1, \"(x1, y1)\")\n",
    "plt.text(x_star, y_star, \"(x*, y*)\")\n",
    "plt.plot(x_star, y_star, marker=\"o\", markersize=15, color=\"green\")\n",
    "plt.plot(x, y_grad, linestyle='-')\n",
    "plt.axhline(0)\n",
    "plt.axvline(x0, linestyle=\"--\")\n",
    "plt.axvline(x1, linestyle=\"--\")\n",
    "plt.text(x0, 2*x0-2, \"f'(x)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.title(\"f(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-activation",
   "metadata": {
    "id": "s85khuRjoQ51"
   },
   "source": [
    "Từ đồ thị ta thấy điểm $(x_0, y_0)$ nằm ở bên trái điểm cực tiểu thì giá trị đạo hàm là âm. Để di chuyển tới $(x*, y*)$ thì ta phải **tăng** $x_0$.\n",
    "\n",
    "Tương tự tại điểm $(x_1, y_1)$ nằm bên phải của điểm cực tiểu thì giá trị của đạo hàm sẽ dương. Để đi tới $(x*, y*)$ thì cần **giảm** $x_1$.\n",
    "\n",
    "Như vậy trong cả hai trường hợp ta đều cần di chuyển ngược chiều đạo hàm để tiến tới gần hơn với cực trị. Ta có thể cập nhật dần dần nghiệm sau mỗi bước bằng một hệ số học tập (_learning rate_) $\\alpha$ có dạng như sau:\n",
    "\n",
    "$$x_{new} = x_0-\\alpha \\nabla_{x_0} f(x_0)$$\n",
    "\n",
    "\n",
    "Như vậy tại mọi vị trí, chỉ cần di chuyển ngược chiều của đạo hàm tại một điểm  một khoảng rất nhỏ thì **có khả năng rất cao** là ta sẽ thu được một giá trị nhỏ nhơn. \n",
    "\n",
    "Thế nhưng có khi nào di chuyển ngược chiều đạo hàm mà khiến giá trị $f(x)$ lớn hơn không? Đó là khi ta đã vượt dốc, chẳng hạn như khi đã đến rất gần điểm cực trị $(x^*, y^*)$ nhưng _hệ số học tập_ quá lớn làm cho khoảng thay đổi ở bước tiếp theo cũng lớn theo và là nguyên nhân khiến nghiệm cập nhật vượt quá điểm cực trị. Trường hợp này gọi là nhảy dốc (_StepOver_).\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/0g58QdZ.jpeg.jpeg)\n",
    "\n",
    "**Hình 2:** Hình bên trái là chiến lược học tập được thiết lập với hệ số học tập phù hợp. Hình bên phải xảy ra hiện tượng _nhảy dốc_. Sau mỗi lượt cập nhật nghiệm thì các điểm có xu hướng nhảy qua lại hai bên xung quanh cực trị địa phương thay vì hội tụ từ từ.\n",
    "\n",
    "Để hạn chế hiện tượng _nhảy dốc_ thì ta cần lựa chọn $\\alpha$ rất nhỏ từ $0.001$ tới $0.005$ và áp dụng những phương pháp tối ưu (_optimizer_) khác nhau để kiểm soát quá trình huấn luyện. Một số phương pháp tối ưu phổ biến là `Adam, Ada, RMProp, ...` và hiện chúng đều đã có sẵn trong các framework Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-courtesy",
   "metadata": {
    "id": "s4GA3ZgN4wwF"
   },
   "source": [
    "## 3.2.1. Cập nhật gradient descent trên Logistic regression\n",
    "\n",
    "Để tìm ra nghiệm của hồi qui Logistic thì chúng ta sẽ thực hiện cập nhật nghiệm trên từng điểm dữ liệu $(\\mathbf{x}_i, y_i)$. Các điểm được lựa chọn một cách ngẫu nhiên ở mỗi lượt cập nhật. Phương pháp cập nhật gradient descent như vậy còn được gọi là _Stochastic Gradient Descent_.\n",
    "\n",
    "$$\\mathbf{w} := \\mathbf{w} - \\alpha ~ \\frac{\\delta \\mathcal{L}(\\mathbf{w}; \\mathbf{x}_i, y_i)}{\\delta \\mathbf{w}} \\tag{3}$$\n",
    "\n",
    "\n",
    "Mặt khác:\n",
    "\n",
    "$$\\mathcal{L}(\\mathbf{w}; \\mathbf{x}_i, y_i) = -[y_i \\log {\\hat{y}}_i + (1-y_i) \\log (1 - \\hat{y}_i)]$$\n",
    "\n",
    "Ngoài ra ta dễ dàng chứng minh được:\n",
    "\n",
    "$$\\begin{eqnarray}\\frac{\\delta \\mathcal{L}(\\mathbf{w}; \\mathbf{x}_i, y_i)}{\\delta \\mathbf{w}} & = & -[y_i \\frac{\\delta \\log {\\hat{y}}_i}{\\delta \\mathbf{w}} + (1-y_i) \\frac{\\delta \\log {(1-\\hat{y}}_i)}{\\delta \\mathbf{w}}] \\\\\n",
    "& = & -[y_i \\frac{\\delta \\log \\hat{y}_i}{\\delta \\hat{y}_i}\\frac{\\delta \\hat{y}_i}{\\delta \\mathbf{w}} + (1-y_i) \\frac{\\delta \\log {(1-\\hat{y}}_i)}{\\delta \\hat{y}_i} \\frac{\\delta \\hat{y}_i}{\\delta \\mathbf{w}}] \\\\\n",
    "& = & -[y_i \\frac{1}{\\hat{y}_i} - (1-y_i) \\frac{1}{(1-\\hat{y}_i)}] \\frac{\\delta \\hat{y}_i}{\\delta \\mathbf{w}} \\\\\n",
    "& = & - [\\frac{y_i-\\hat{y}_i}{\\hat{y}_i(1-\\hat{y}_i)}] \\frac{\\delta \\hat{y}_i}{\\delta \\mathbf{w}} \\tag{4}\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Dòng 1 suy ra dòng 2 là vì ta sử dụng công thức vi phân. Đặt $z = e^{\\mathbf{w}^{\\intercal} \\mathbf{x}}$. Tiếp tục khai triển:\n",
    "\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta \\mathbf{w}} = \\frac{\\delta \\frac{1}{1+z_i}}{\\delta \\mathbf{w}} = \\frac{\\delta \\frac{1}{1+z_i}}{\\delta z_i} \\frac{\\delta z_i}{\\delta \\mathbf{w}} = \\frac{-1}{(1+z_i)^2} z_i\\mathbf{x}_i = -\\mathbf{x}\\frac{z_i}{(1+z_i)^2} = -\\mathbf{x}_i\\hat{y}_i(1-\\hat{y}_i)$$\n",
    "\n",
    "Từ đó thế vào $(4)$ ta được:\n",
    "\n",
    "$$\\frac{\\delta \\mathcal{L}(\\mathbf{w}; \\mathbf{x}_i, y_i)}{\\delta \\mathbf{w}} = \\mathbf{x}_i (\\hat{y}_i-y_i)$$\n",
    "\n",
    "Như vậy công thức $(3)$ cập nhật nghiệm theo gradient descent sẽ được rút ngắn xuống thành:\n",
    "\n",
    "$$\\mathbf{w} := \\mathbf{w} - \\alpha ~ \\mathbf{x}_i(\\hat{y}_i-y_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-tennessee",
   "metadata": {
    "id": "scmlwrpi4l8j"
   },
   "source": [
    "# 3.3. Hồi qui Logistic trên sklearn\n",
    "\n",
    "Để xây dựng mô hình hồi qui Logistic trên sklearn chúng ta sử dụng module `sklearn.linear_model.LogisticRegression`.\n",
    "\n",
    "Tiếp theo chúng ta sẽ cùng xây dựng một pipeline đơn giản cho bài toán phân loại nợ xấu sử dụng mô hình hồi qui Logistic. Dữ liệu đầu vào là [hmeq](http://www.creditriskanalytics.net/uploads/1/9/5/1/19511601/hmeq.csv). Bộ dữ liệu HMEQ bao gồm các đặc trưng thông tin về nợ của 5960 khoản vay mua nhà. Đây là những khoản vay mua nhà mà người vay sử dụng vốn chủ sở hữu làm tài sản thế chấp. Tập dữ liệu bao gồm những trường sau:\n",
    "\n",
    "* BAD: 1 = Hồ sơ vay là vi phạm hoặc mất khả năng trả nợ; 0 = hồ sơ vay đã và đang trả nợ.\n",
    "* LOAN: Số tiền yêu cầu cho vay.\n",
    "* MORTDUE: Số tiền đến hạn của khoản thế chấp hiện có.\n",
    "* VALUE: Giá trị tài sản hiện tại.\n",
    "* REASON: DebtCon = nợ hợp nhất; HomeImp = cải thiện nhà.\n",
    "* JOB: Thể loại nghề nghiệp.\n",
    "* YOJ: Số năm kinh nghiệm trong nghề nghiệp hiện tại.\n",
    "* DEROG: Số lượng báo cáo không tín nhiệm.\n",
    "* DELINQ: Số hạn mức tín dụng quá hạn.\n",
    "* CLAGE: Tuổi của hạn mức tín dụng cũ nhất tính theo tháng.\n",
    "* NINQ: Số câu hỏi tín dụng gần đây.\n",
    "* CLNO: Số lượng hạn mức tín dụng.\n",
    "* DEBTINC: Tỷ lệ nợ trên thu nhập.\n",
    "\n",
    "Mục tiêu của chúng ta sẽ là dựa vào các biến đầu vào để phân loại một hồ sơ có khả năng nợ xấu hay không.\n",
    "\n",
    "Như thông lệ, qui trình xây dựng mô hình sẽ bao gồm các bước theo tuần tự:\n",
    "\n",
    "1. Khảo sát dữ liệu.\n",
    "2. Phân chia tập huấn luyện/kiểm tra.\n",
    "3. Xử lý missing và outliers.\n",
    "4. Lựa chọn mô hình.\n",
    "5. Huấn luyện mô hình.\n",
    "6. Đánh giá mô hình.\n",
    "\n",
    "Bên dưới chúng ta sẽ tuần tự thực hành những bước này:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-scholar",
   "metadata": {
    "id": "Y3Au0OUXYSxG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-violin",
   "metadata": {
    "id": "9ULAJk3Tb--F"
   },
   "source": [
    "Đọc dữ liệu từ pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-curve",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "ajAXG518Yexx",
    "outputId": "5855bb19-6b7f-46ad-8220-dd841071037d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('http://www.creditriskanalytics.net/uploads/1/9/5/1/19511601/hmeq.csv', header = 0, sep = ',')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-musical",
   "metadata": {
    "id": "dRZP6rREcBu6"
   },
   "source": [
    "Vẽ biểu đồ khảo sát phân phối của dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-singles",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "bgY-ufBxZNQA",
    "outputId": "dfe56820-066a-4b32-c4b3-dd88450b14e3"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['float','int']).columns\n",
    "\n",
    "def _plot_numeric_classes(df, col, bins=10, hist=True, kde=True):\n",
    "    sns.distplot(df[col],\n",
    "                 bins = bins,\n",
    "                 hist = hist,\n",
    "                 kde = kde)\n",
    "\n",
    "def _distribution_numeric(df, numeric_cols, row=3, col=3, figsize=(20, 15), bins = 10):\n",
    "    '''\n",
    "    numeric_cols: list các tên cột\n",
    "    row: số lượng dòng trong lưới đồ thị\n",
    "    col: số lượng cột trong lưới đồ thị\n",
    "    figsize: kích thước biểu đồ\n",
    "    bins: số lượng bins phân chia trong biểu đồ distribution\n",
    "    '''\n",
    "    print('number of numeric field: ', len(numeric_cols))\n",
    "    assert row*(col-1) < len(numeric_cols)\n",
    "    plt.figure(figsize = figsize)\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=0.5)\n",
    "    for i in range(1, len(numeric_cols)+1, 1):\n",
    "      try:\n",
    "        plt.subplot(row, col, i)\n",
    "        _plot_numeric_classes(df, numeric_cols[i-1], bins = bins)\n",
    "        plt.title(numeric_cols[i-1])\n",
    "      except:\n",
    "        print('Error {}'.format(numeric_cols[i-1]))\n",
    "        break\n",
    "\n",
    "_distribution_numeric(df, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-arrival",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "Tgv-n3qDZgkI",
    "outputId": "6d8be4c3-cce6-4e19-d60b-080c261f2ea7"
   },
   "outputs": [],
   "source": [
    "# Đối với biến phân loại\n",
    "cate_cols = df.select_dtypes('O').columns\n",
    "\n",
    "def _plot_bar_classes(df, cols):\n",
    "    df[cols].value_counts().plot.bar()\n",
    "\n",
    "def _distribution_cate(df, cate_cols, row = 1, col = 2, figsize = (20, 5)):\n",
    "  '''\n",
    "  cate_cols: list các tên cột\n",
    "  row: số lượng dòng trong lưới đồ thị\n",
    "  col: số lượng cột trong lưới đồ thị\n",
    "  figsize: kích thước biểu đồ\n",
    "  '''\n",
    "  print('number of category field: ', len(cate_cols))\n",
    "  plt.figure(figsize = figsize)\n",
    "  plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=0.5)    \n",
    "  for i in range(1, len(cate_cols)+1, 1):\n",
    "    try:\n",
    "      plt.subplot(row, col, i)\n",
    "      _plot_bar_classes(df, cate_cols[i-1])\n",
    "      plt.title(cate_cols[i-1])\n",
    "    except:\n",
    "      break\n",
    "\n",
    "_distribution_cate(df, cate_cols, row = 4, col = 4, figsize = (30, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-cleveland",
   "metadata": {
    "id": "TOJSDUIhcGUq"
   },
   "source": [
    "Phân chia tập huấn luyện/kiểm tra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-david",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-Nb4LOlZoty",
    "outputId": "f44e9413-d6b2-4013-d8ea-a67a361e7a3d"
   },
   "outputs": [],
   "source": [
    "# Chia train/test theo tỷ lệ 80:20.\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify = df['BAD'])\n",
    "X_train = df_train.copy()\n",
    "y_train = X_train.pop(\"BAD\")\n",
    "\n",
    "X_test = df_test.copy()\n",
    "y_test = X_test.pop(\"BAD\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-uncle",
   "metadata": {
    "id": "mwWLY4jMZ-96"
   },
   "source": [
    "Xây dựng pipeline xử lý missing data và outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-helping",
   "metadata": {
    "id": "8leDs51dZ3iU"
   },
   "outputs": [],
   "source": [
    "# Lấy list names của các biến phân loại và biến liên tục.\n",
    "cat_names = list(X_train.select_dtypes('object').columns)\n",
    "num_names = list(X_train.select_dtypes(['float', 'int']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-electric",
   "metadata": {
    "id": "G4v20m73aBtY"
   },
   "outputs": [],
   "source": [
    "# Pipeline xử lý cho biến phân loại\n",
    "cat_pl= Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')), # Xử lý missing data bằng cách thay thế most frequent\n",
    "        ('onehot', OneHotEncoder()), # Biến đổi giá trị của biến phân loại thành véc tơ OneHot\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-round",
   "metadata": {
    "id": "CPHKphfsaFBr"
   },
   "outputs": [],
   "source": [
    "# Pipeline xử lý cho biến liên tục\n",
    "num_pl = Pipeline(\n",
    "    steps=[\n",
    "           ('imputer', KNNImputer(n_neighbors=7)), # Xử lý missing data bằng cách dự báo KNN với n=7.\n",
    "           ('scaler', MinMaxScaler()) # Xử lý missing data bằng MinMax scaler\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-kelly",
   "metadata": {
    "id": "1YEdaI_aaJWV"
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pl, num_names), # áp dụng pipeline cho biến liên tục\n",
    "        ('cat', cat_pl, cat_names), # áp dụng pipeline cho biến phân loại\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-measurement",
   "metadata": {
    "id": "3sevcWyecUoD"
   },
   "source": [
    "Huấn luyện mô hình trên tập huấn luyện và đánh giá trên tập kiểm tra. Ở bước này chúng ta lưu ý một chút về các lựa chọn của LogisticRegression.\n",
    "\n",
    "```\n",
    "LogisticRegression(penalty='l2',\n",
    "tol=0.0001, \n",
    "C=1.0, \n",
    "fit_intercept=True, \n",
    "class_weight=None, \n",
    "solver='lbfgs', \n",
    "max_iter=100)\n",
    "```\n",
    "Trong đó:\n",
    "\n",
    "* `tot` là giá trị bao dung (_tolarance_) để dừng cập nhật gradient descent nếu khoảng thay đổi của hàm mất mát sau một bước huấn luyện nhỏ hơn `tot`.\n",
    "* `max_iter` là số lượt huấn luyện tối đa.\n",
    "* `fit_intercept` để qui định có sử dụng trọng số tự do (chính là $w_0$ không bị phụ thuộc vào dữ liệu) hay không.\n",
    "* `solver` là phương pháp để giải bài toán tối ưu đối với cross entropy. Trong đó có: `liblinear, sag, saga, newton-cg`. Đối với dữ liệu kích thước nhỏ thì `liblinear` sử dụng sẽ phù hợp hơn. Trái lại `sag`, `saga` có tốc độ huấn luyện nhanh hơn cho dữ liệu lớn.\n",
    "* `penalty`: là dạng hàm được sử dụng làm thành phần điều chuẩn (_regularization term_).\n",
    "* `C`: Hệ số nhân của thành phần điều chuẩn.\n",
    "* `class_weight`: Trọng số được nhân thêm ở mỗi nhóm. Thường được sử dụng trong trường hợp mẫu mất cân bằng giữa các nhóm để dự báo nhóm thiểu số tốt hơn. Trong số có tác dụng điều chỉnh mức độ phạt nếu dự báo sai một mẫu theo nhãn ground truth của mẫu. Nếu không được xác định thì ta hiểu trọng số nhóm là cân bằng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-processor",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_WHdozPaKWC",
    "outputId": "15d0edbb-8687-4d88-9611-ebf27d9cb704"
   },
   "outputs": [],
   "source": [
    "# Completed training pipeline\n",
    "completed_pl = Pipeline(\n",
    "    steps=[\n",
    "            (\"preprocessor\", preprocessor), \n",
    "            (\"classifier\", LogisticRegression(penalty='l2', C=0.5, max_iter=200, class_weight=[0.3, 0.7]))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# training\n",
    "completed_pl.fit(X_train, y_train)\n",
    "\n",
    "# accuracy\n",
    "y_train_pred = completed_pl.predict(X_train)\n",
    "print(f\"Accuracy on train: {accuracy_score(list(y_train), list(y_train_pred)):.2f}\")\n",
    "\n",
    "y_pred = completed_pl.predict(X_test)\n",
    "print(f\"Accuracy on test: {accuracy_score(list(y_test), list(y_pred)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-merchandise",
   "metadata": {
    "id": "mt12m12ycbu1"
   },
   "source": [
    "Kết quả mô hình đạt accuracy là 83% trên tập huấn luyện và 82% trên tập kiểm tra. Đây là một kết quả không quá chênh lệch giữa hai tập dữ liệu nên có thể nói mô hình khá ổn định. Phương pháp hồi qui Logistic thường là phương pháp đơn giản nhất trong các lớp mô hình hồi qui nên kết quả của nó thường không phải là tốt nhất. Bạn đọc nên thử nghiệm với nhiều lớp mô hình khác như `SVM, MLP, kNN, Random Forest, CART, Decision Tree` để tìm ra lớp mô hình phù hợp nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-voice",
   "metadata": {
    "id": "bEiAgtecW6Aw"
   },
   "source": [
    "# 3.4. Tổng kết\n",
    "\n",
    "Như vậy ở bài này mình các bạn đã được làm quen với mô hình hồi qui Logistic trong bài toán phân loại nhị phân thuộc lớp mô hình học có giám sát cùng những khái nhiệm liên quan như hàm Sigmoid, ước lượng hợp lý tối đa, hàm Cross Entropy, phương pháp cập nhật nghiệm bằng gradient descent. Đây là những nội dung cơ bản nhưng lại rất quan trọng mà các bạn cần nắm vững để tạo tiền đề học tập và nghiên cứu những phương pháp học máy nâng cao hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-brake",
   "metadata": {
    "id": "SjCKtOS-W8Hw"
   },
   "source": [
    "# 3.5. Bài tập\n",
    "\n",
    "1. Xác suất dự báo của mô hình hồi qui Logistic được xây dựng dựa trên hàm nào? Hàm số đó có đặc điểm gì?\n",
    "2. Sau khi dự báo được xác suất, chúng ta cần làm gì để tiếp tục suy luận ra nhãn dự báo của một quan sát?\n",
    "3. Tỷ lệ Odd Ratio có ý nghĩa như thế nào?\n",
    "4. Đường biên phân chia của hồi qui Logistic có dạng như thế nào?\n",
    "5. Tính các đạo hàm sau đây theo giá trị của $w_0$ và $w_1$.\n",
    "\n",
    "$$\\frac{1}{1+e^{-(w_0+w_1x_1)}}$$ \n",
    "\n",
    "và\n",
    "\n",
    "$$\\frac{1}{1+e^{(w_0+w_1x_1)}}$$\n",
    "\n",
    "Nhận xét gì về đạo hàm của hai hàm số này ?\n",
    "\n",
    "6. Tại sao chúng ta cần thiết lập hệ số học tập (_learning rate_) là một giá trị nhỏ?\n",
    "\n",
    "7. Phương pháp cập nhật nghiệm theo gradient descent bằng cách lấy ngẫu nhiên một điểm dữ liệu được gọi là gì? Chúng có công thức ra sao?\n",
    "\n",
    "8. Thế nào là ước lượng hợp lý cực đại?\n",
    "\n",
    "9. Hàm Cross Entropy là gì ? Ý nghĩa của Crosss Entropy.\n",
    "\n",
    "10. Tại sao chúng ta không sử dụng hồi qui tuyến tính trong bài toán phân loại?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-acceptance",
   "metadata": {
    "id": "llwa2BixW9zz"
   },
   "source": [
    "# 3.6. Tài liệu tham khảo\n",
    "\n",
    "1. [Logistic Regression - Joparga Standford](https://joparga3.github.io/standford_logistic_regression/)\n",
    "2. [Logistic Regression - Jurafsky](https://web.stanford.edu/~jurafsky/slp3/5.pdf)\n",
    "3. [CS109 - Logistic Regression - StandFord](https://web.stanford.edu/class/archive/cs/cs109/cs109.1176/lectures/23-LogisticRegression.pdf)\n",
    "4. [Bishop Pattern Recognition and Machine Learning - 2006](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)\n",
    "5. [C229 - Andrew Ng - Lecture Note](https://datajobs.com/data-science-repo/Generalized-Linear-Models-[Andrew-Ng].pdf)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.8.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "source_map": [
   11,
   22,
   26,
   32,
   36,
   51,
   55,
   79,
   106,
   139,
   149,
   172,
   221,
   246,
   250,
   254,
   281,
   285,
   296,
   300,
   311,
   315,
   337,
   341,
   347,
   392,
   407,
   432,
   436,
   467,
   492,
   528,
   563,
   590,
   594,
   608,
   612,
   656,
   691,
   695,
   713,
   717,
   725,
   737,
   749,
   760,
   783,
   809,
   813,
   819,
   847
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}