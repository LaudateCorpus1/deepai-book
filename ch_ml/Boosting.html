
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>12.1. AdaBoosting &#8212; Deep AI KhanhBlog</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.37f24b989f4638ff9c27c22dc7559d4f.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/Boosting.html" />
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="13. k-Means Clustering" href="index_KMeans.html" />
    <link rel="prev" title="12. Phương pháp tăng cường (Boosting)" href="index_Boosting.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://phamdinhkhanh.github.io/deepai-book/ch_ml/Boosting.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="12.1. AdaBoosting" />
<meta property="og:description" content="12.1. AdaBoosting  Giả định rằng bài toán phân loại nhị phân với biến mục tiêu gồm hai nhãn y \in \{-1, 1\}. Giả định theo phương pháp tăng cường thì hàm dự báo" />
<meta property="og:image"       content="https://phamdinhkhanh.github.io/deepai-book/_static/ML_course_logos.jpeg" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ML_course_logos.jpeg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Deep AI KhanhBlog</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Lời nói đầu
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../contents.html">
   Các chương dự kiến
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contents.html#dong-gop-vao-du-an">
   Đóng góp vào dự án
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/main_contents.html">
   Mục tiêu cuốn sách
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../latex.html">
   Latex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../latex.html#tham-khao-latex">
   Tham khảo latex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../grossary.html">
   Bảng thuật ngữ
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Phụ lục
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/appendix_dtypes.html">
   1. Định dạng dữ liệu
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html">
     1.1. Các định dạng số, boolean và ký tự
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#dinh-dang-sequence">
     1.2. Định dạng sequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#tom-tat">
     1.3. Tóm tắt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#bai-tap">
     1.4 Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#tai-lieu-tham-khao">
     1.5. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_pandas.html">
   2. Pandas
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html">
     2.1. Khởi tạo dataframe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#thao-tac-voi-dataframe">
     2.2. Thao tác với dataframe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#reshape-dataframe-tren-pandas">
     2.3. Reshape dataframe trên pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#thong-ke-theo-nhom-tren-pandas">
     2.4. Thống kê theo nhóm trên pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#join-merge-va-concatenate-bang">
     2.5. Join, Merge và Concatenate bảng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#ket-noi-sql">
     2.6. Kết nối SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#tong-ket">
     2.7. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#bai-tap">
     2.8. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#tai-lieu">
     2.9. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_numpy.html">
   3. Numpy
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html">
     3.1. Khởi tạo một mảng trên numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#doc-va-save-numpy-tu-file">
     3.2. Đọc và save numpy từ file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#truy-cap-mang-tren-numpy">
     3.2. Truy cập mảng trên numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#thay-doi-shape-cua-mang">
     3.3. Thay đổi shape của mảng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-ham-tren-numpy">
     3.4. Các hàm trên numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-ma-tran-dac-biet">
     3.5. Các ma trận đặc biệt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-phep-toan-tren-ma-tran">
     3.6. Các phép toán trên ma trận
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#id1">
     3.7. Các phép toán trên ma trận
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-phep-toan-tren-vec-to">
     3.8. Các phép toán trên véc tơ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#thanh-phan-cua-mang">
     3.9. Thành phần của mảng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#bai-tap">
     3.10. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#tai-lieu">
     3.11. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_matplotlib.html">
   4. Matplotlib
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html">
     4.1. Format chung của một biểu đồ trên matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#cac-bieu-do-co-ban-tren-matplotlib">
     4.2. Các biểu đồ cơ bản trên matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#cac-bieu-do-nang-cao-tren-matplotlib">
     4.3. Các biểu đồ nâng cao trên matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#ve-nhieu-bieu-do-con-tren-mot-bieu-do">
     4.4. Vẽ nhiều biểu đồ con trên một biểu đồ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#bieu-do-dong-tu-gif-file">
     4.5. Biểu đồ động từ gif file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#tong-ket">
     4.6. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#bai-tap">
     4.7. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#tai-lieu-tham-khao">
     4.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_OOP.html">
   5. Lập trình hướng đối tượng (Object Oriented Programming - OOP)
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html">
     5.1. Class và Object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#tinh-ke-thua">
     5.2. Tính kế thừa
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#module-va-package">
     5.3. Module và package
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#tong-ket">
     5.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#bai-tap">
     5.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#tai-lieu">
     5.6. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_pipeline.html">
   6. Sklearn Pipeline
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html">
     6.1. Thiết kế pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#danh-gia-cheo-cross-validation">
     6.2. Đánh giá cheó (
     <em>
      cross validation
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#gridsearch">
     6.3. GridSearch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#tong-ket">
     6.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#bai-tap">
     6.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#tai-lieu-tham-khao">
     6.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_Convex_Opt.html">
   7. Giới thiệu chung về optimization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html">
     7.1. Bài toán dạng tổng quát
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#cac-bai-toan-toi-uu-thuc-tien">
     7.2. Các bài toán tối ưu thực tiễn.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#bai-toan-geometric-programming-gp">
     7.3. Bài toán
     <em>
      Geometric Programming GP
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#bai-toan-quadratic-programming-qp">
     7.4. Bài toán
     <em>
      Quadratic Programming
     </em>
     (
     <em>
      QP
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#tong-ket">
     7.5. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#bai-tap">
     7.6. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#tai-lieu-tham-khao">
     7.7. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Đại số tuyến tính
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html">
   1. Đại số tuyến tính
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html#tom-tat">
   2. Tóm tắt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html#bai-tap">
   3. Bài tập
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Giải tích
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html">
   1. Giải tích tích phân
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html#giai-tich-vi-phan">
   2. Giải tích vi phân
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html#bai-tap">
   3. Bài tập
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html#tai-lieu-tham-khao">
   4. Tài liệu tham khảo
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Xác suất
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html">
   1. Xác suất
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html#phan-phoi-xac-suat">
   2. Phân phối xác suất
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html#bai-tap">
   3. Bài tập
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html#tai-lieu-tham-khao">
   4. Tài liệu tham khảo
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="index_MLIntroduce.html">
   1. Khái quát Machine Learning
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_prediction.html">
   2. Bài toán dự báo
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html">
     2.1. Ứng dụng của hồi qui tuyến tính
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#ham-mat-mat">
     2.2. Hàm mất mát
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#hoi-qui-tuyen-tinh-da-bien">
     2.3. Hồi qui tuyến tính đa biến
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#dien-giai-xac-suat-cua-hoi-qui-tuyen-tinh">
     2.4. Diễn giải xác suất của hồi qui tuyến tính
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#huan-luyen-mo-hinh-hoi-qui-tuyen-tinh-tren-sklearn">
     2.5. Huấn luyện mô hình hồi qui tuyến tính trên sklearn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#do-thi-hoa-ket-qua-mo-hinh">
     2.6. Đồ thị hoá kết quả mô hình
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#danh-gia-mo-hinh-hoi-qui-tuyen-tinh-da-bien">
     2.7. Đánh gía mô hình hổi qui tuyến tính đa biến
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#ridge-regression-va-lasso-regression">
     2.8. Ridge regression và Lasso regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#tom-tat">
     2.9. Tóm tắt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#bai-tap">
     2.10. Bài tập
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_RidgedRegression.html">
   2.2. Hồi qui Ridge và Lasso
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html">
     2.2.2. Hồi qui Ridge
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#hoi-qui-lasso">
     2.2.3. Hồi qui Lasso
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#vi-sao-hoi-qui-lasso-lai-la-hoi-qui-lua-chon-bien">
     2.2.4. Vì sao hồi qui Lasso lại là hồi qui lựa chọn biến
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#elastic-net">
     2.2.5. Elastic Net
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#tuning-he-so-cho-mo-hinh-hoi-qui-ridge-lasso-va-elastic-net">
     2.2.6. Tuning hệ số cho mô hình hồi qui Ridge, Lasso và Elastic Net
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#tong-ket">
     2.2.7. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#bai-tap">
     2.2.8. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#tai-lieu-tham-khao">
     2.2.9. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_classification.html">
   3. Bài toán phân loại
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html">
     3.1. Hồi qui Logistic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#tim-nghiem-toi-uu-bang-ha-doc-gradient-descent">
     3.2. Tìm nghiệm tối ưu bằng hạ dốc (
     <em>
      gradient descent
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#hoi-qui-logistic-tren-sklearn">
     3.3. Hồi qui Logistic trên sklearn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#tong-ket">
     3.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#bai-tap">
     3.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#tai-lieu-tham-khao">
     3.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_OvfAndUdf.html">
   4. Độ chệch (
   <em>
    bias
   </em>
   ) và phương sai (
   <em>
    variance
   </em>
   )
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html">
     4.1. Sự đánh đổi giữa độ chệch và phương sai
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#qua-khop-overfitting-va-vi-khop-underfitting">
     4.2. Quá khớp (
     <em>
      Overfitting
     </em>
     ) và vị khớp (
     <em>
      Underfitting
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#xu-ly-hien-tuong-qua-khop">
     4.3. Xử lý hiện tượng quá khớp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#xu-ly-hien-tuong-vi-khop">
     4.4. Xử lý hiện tượng vị khớp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#tong-ket">
     4.5. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#bai-tap-tham-khao">
     4.6. Bài tập tham khảo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#tai-lieu-tham-khao">
     4.7. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_ModelMetric.html">
   5. Thước đo mô hình phân loại
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html">
     5.1. Bộ dữ liệu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-chinh-xac-accuracy">
     5.2. Độ chính xác (accuracy)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-chuan-xac-precision">
     5.3. Độ chuẩn xác (
     <em>
      precision
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-phu-recall">
     5.4. Độ phủ (
     <em>
      Recall
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#trade-off-giua-do-chuan-xac-va-do-phu">
     5.5. Trade off giữa
     <em>
      độ chuẩn xác
     </em>
     và
     <em>
      độ phủ
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#f1-score">
     5.6. f1 Score
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#tai-sao-f1-score-khong-la-trung-binh-cong-do-chuan-xac-va-do-phu">
     5.7. Tại sao f1 score không là trung bình cộng
     <em>
      độ chuẩn xác
     </em>
     và
     <em>
      độ phủ
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-chinh-xac-accuracy-va-f1-score">
     5.8. Độ chính xác (
     <em>
      accuracy
     </em>
     ) và
     <em>
      f1 score
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#auc">
     5.9. AUC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#moi-quan-he-giua-tpr-va-fpr">
     5.10. Mối quan hệ giữa TPR và FPR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#gini-va-cap">
     5.11. Gini và CAP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#tong-ket">
     5.12. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#bai-tap">
     5.13. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#tai-lieu-tham-khao">
     5.14. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_creditScorecard.html">
   6. Ứng dụng mô hình scorecard
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="creditScorecard.html">
     6.1. Phương pháp chuyên gia và mô hình
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="creditScorecard.html#xay-dung-mo-hinh-credit-scorecard">
     6.2. Xây dựng mô hình credit scorecard
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_SVM.html">
   7. Giới thiệu về SVM
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html">
     7.1. Hàm mất mát của SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#duong-bien-va-le-trong-svm">
     7.2. Đường biên và lề trong SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#bai-toan-toi-uu-svm">
     7.3. Bài toán tối ưu SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#sorf-margin-classification">
     7.4. Sorf Margin Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#ky-thuat-tao-dac-trung">
     7.5. Kỹ thuật tạo đặc trưng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#kernel-trong-svm">
     7.6. Kernel trong SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#vi-du-ve-bai-toan-svm">
     7.7. Ví dụ về bài toán SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#tong-ket">
     7.8. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#bai-tap">
     7.9. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#tai-lieu">
     7.10. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_DecisionTree.html">
   8. Khái niệm về cây quyết định
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html">
     8.1. Mô hình cây quyết định (
     <em>
      decision tree
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#bai-toan-phan-loai-cay-quyet-dinh-tren-bo-du-lieu-boston">
     8.2. Bài toán phân loại cây quyết định trên bộ dữ liệu boston
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#duong-bien-phan-chia-cua-cay-quyet-dinh">
     8.3. Đường biên phân chia của cây quyết định
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#cach-khoi-tao-cay-quyet-dinh">
     8.4. Cách khởi tạo cây quyết định
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#thuat-toan-id3-va-cart">
     8.5. Thuật toán ID3 và CART
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#chi-so-gini">
     8.6. Chỉ số Gini
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#cay-quyet-dinh-cho-bai-toan-du-bao">
     8.7. Cây quyết định cho bài toán dự báo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#dieu-kien-dung-de-giam-qua-khop-overfitting">
     8.8. Điều kiện dừng để giảm quá khớp (
     <em>
      overfitting
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#cat-tia-pruning">
     8.9. Cắt tỉa  (
     <em>
      pruning
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#tuning-sieu-tham-so-cho-mo-hinh-cay-quyet-dinh">
     8.10. Tuning siêu tham số cho mô hình cây quyết định
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#bai-tap">
     8.11. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#tai-lieu-tham-khao">
     8. 12. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_RandomForest.html">
   9. Giới thiệu về mô hình rừng cây (
   <em>
    Random Forest
   </em>
   )
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html">
     9.1. Ý tưởng của mô hình rừng cây
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html#huan-luyen-mo-hinh-rung-cay">
     9.2. Huấn luyện mô hình rừng cây
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html#danh-gia-muc-do-quan-trong-cua-bien">
     9.3. Đánh giá mức độ quan trọng của biến
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html#tong-ket">
     9.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html#bai-tap">
     9.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html#tai-lieu-tham-khao">
     9.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_Bayes.html">
   10. Bạn là
   <em>
    Tần suất
   </em>
   (
   <em>
    Frequentist
   </em>
   ) hay
   <em>
    Bayesian
   </em>
   ?
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html">
     10.1. Ước lượng hợp lý tối đa (
     <em>
      Maximum Likelihood Function - MLE
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html#uoc-luong-hau-nghiem-toi-da-maximum-a-posteriori">
     10.2. Ước lượng hậu nghiệm tối đa (
     <em>
      Maximum A Posteriori
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html#mo-hinh-xac-suat-naive-bayes">
     10.3. Mô hình xác suất Naive Bayes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html#tong-ket">
     10.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html#bai-tap">
     10.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html#tai-lieu">
     10.6. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_FeatureEngineering.html">
   11. Giới thiệu về feature engineering
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html">
     11.1. Feature Engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html#id1">
     11.2. Trích lọc đặc trưng (feature extraction)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html#id2">
     11.3. Biến đổi đặc trưng (feature transformation)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html#id3">
     11.4. Lựa chọn đặc trưng (
     <em>
      feature selection
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html#tong-ket">
     11.5. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html#tai-lieu-tham-khao">
     11.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index_Boosting.html">
   12. Phương pháp tăng cường (
   <em>
    Boosting
   </em>
   )
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     12.1. AdaBoosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#gradient-boosting">
     12.2. Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#tong-ket">
     12.3. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#bai-tap">
     12.4. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#tai-lieu-tham-khao">
     12.5. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_KMeans.html">
   13. k-Means Clustering
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html">
     13.1. Các bước của thuật toán k-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#su-hoi-tu-cua-thuat-toan-k-means-clustering">
     13.2. Sự hội tụ của thuật toán k-Means clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#phuong-phap-elbow-trong-lua-chon-so-cum">
     13.3. Phương pháp Elbow trong lựa chọn số cụm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#bieu-dien-du-lieu-da-chieu-tren-do-thi">
     13.4. Biểu diễn dữ liệu đa chiều trên đồ thị
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#han-che-cua-k-means">
     13.5. Hạn chế của k-Means
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#online-k-means-clustering">
     13.6. Online k-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#tong-ket">
     13.7. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#bai-tap">
     13.8. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#tai-lieu">
     13.9. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_HierarchicalClustering.html">
   14. Hierarchical Clustering (
   <em>
    phân cụm phân cấp
   </em>
   )
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html">
     14.1. Chiến lược hợp nhất (
     <em>
      agglomerative
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#khoang-cach-giua-hai-cum">
     14.2. Khoảng cách giữa hai cụm?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#chien-luoc-phan-chia-divisive">
     14.3. Chiến lược phân chia (
     <em>
      divisive
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#dieu-kien-dung-cua-thuat-toan-phan-cum">
     14.4. Điều kiện dừng của thuật toán phân cụm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#do-phuc-tap-cua-thuat-toan-phan-cum-phan-cap">
     14.5. Độ phức tạp của thuật toán
     <em>
      phân cụm phân cấp
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#thuc-hanh-phan-cum-phan-cap">
     14.6. Thực hành
     <em>
      phân cụm phân cấp
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#tong-ket">
     14.7. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#bai-tap">
     14.8. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#tai-lieu-tham-khao">
     14.9. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_DBSCAN.html">
   15. DBSCAN
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html">
     15.1. Phương pháp phân cụm dựa trên mật độ (
     <em>
      Density-Based Clustering
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#cac-buoc-trong-thuat-toan-dbscan">
     15.3. Các bước trong thuật toán DBSCAN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#xac-dinh-tham-so">
     4. Xác định tham số
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#huan-luyen-thuat-toan-dbscan">
     15.4. Huấn luyện thuật toán DBSCAN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#tong-ket">
     15.5. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#bai-tap">
     15.6. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#tai-lieu-tham-khao">
     15.7. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Đóng góp từ các tác giả khác
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/fubini_and_riemann.html">
   Tích phân Riemann và định lý Fubini
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/information_theory.html">
   Lý thuyết thông tin
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/ch_ml/Boosting.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ch_ml/Boosting.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/phamdinhkhanh/deepai-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/phamdinhkhanh/deepai-book/issues/new?title=Issue%20on%20page%20%2Fch_ml/Boosting.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/phamdinhkhanh/deepai-book/edit/main/book/ch_ml/Boosting.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/phamdinhkhanh/deepai-book/main?urlpath=tree/book/ch_ml/Boosting.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   12.1. AdaBoosting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cac-buoc-cua-thuat-toan-adaboosting">
     12.1.1. Các bước của thuật toán AdaBoosting
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#huan-luyen-adaboosting-tren-sklearn">
     12.1.2. Huấn luyện
     <em>
      AdaBoosting
     </em>
     trên sklearn
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-boosting">
   12.2. Gradient Boosting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cac-buoc-cua-thuat-toan-gradient-boosting">
     12.2.1. Các bước của thuật toán Gradient Boosting
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#huan-luyen-gradient-boosting-tren-sklearn">
     12.2.2 Huấn luyện
     <em>
      Gradient Boosting
     </em>
     trên sklearn
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tong-ket">
   12.3. Tổng kết
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bai-tap">
   12.4. Bài tập
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tai-lieu-tham-khao">
   12.5. Tài liệu tham khảo
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="adaboosting">
<h1>12.1. AdaBoosting<a class="headerlink" href="#adaboosting" title="Permalink to this headline">¶</a></h1>
<p>Giả định rằng bài toán <em>phân loại nhị phân</em> với biến mục tiêu gồm hai nhãn <span class="math notranslate nohighlight">\(y \in \{-1, 1\}\)</span>. Giả định theo <em>phương pháp tăng cường</em> thì hàm dự báo đối với một biến đầu vào <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> là <span class="math notranslate nohighlight">\(\hat{f}(\mathbf{x_i}) \in \{-1, 1 \}\)</span>. Đồng thời biến mục tiêu <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> nhận một trong hai giá trị <span class="math notranslate nohighlight">\(\{-1, 1\}\)</span>. Khi đó sai số trên tập huấn luyện là:</p>
<div class="math notranslate nohighlight">
\[r = \frac{1}{N}\sum_{i=1}^{N} \mathbf{1}(y_i \neq \hat{f}(\mathbf{x}_i))\]</div>
<p>Trong đó hàm <span class="math notranslate nohighlight">\(\mathbf{1}(.)\)</span> là một hàm logic nhận giá trị 1 nếu như điều kiện bên trong hàm trả về là đúng, trái lại thì nhận giá trị 0.</p>
<p>Một <em>mô hình phân loại yếu</em> (<em>weak classifier</em>) có tỷ lệ dự báo sai lớn và giả định nó chỉ tốt hơn so với phân loại ngẫu nhiên một chút. Mục tiêu của <em>phương pháp tăng cường</em> là áp dụng liên tiếp các <em>mô hình phân loại yếu</em> để điều chỉnh lại trọng số cho các quan sát, qua đó ở mô hình sau sẽ ưu tiên phân loại đúng những quan sát đã phân loại sai từ mô hình trước đó. Kết thúc ta thu được một mô hình dự báo được kết hợp từ các mô hình phân loại yếu trong chuỗi. Mô hình kết hợp này thường có hiệu suất cao.</p>
<p><img alt="" src="https://imgur.com/KjfD7mj.png" /></p>
<p><strong>Hình 1:</strong> Sơ đồ của mô hình <em>AdaBoosting</em>. Mỗi một mô hình con được huấn luyện từ bộ dữ liệu được đánh trọng số theo tính toán từ mô hình tiền nhiệm. Dữ liệu có trọng số sau đó được đưa vào huấn luyện mô hình tiếp theo. Đồng thời ta cũng tính ra một <em>trọng số quyết định</em> <span class="math notranslate nohighlight">\(\alpha_p\)</span> thể hiện vai trò của mỗi mô hình ở từng bước huấn luyện. Cứ tiếp tục như vậy cho tới khi số lượng mô hình đạt ngưỡng hoặc tập huấn luyện hoàn toàn được phân loại đúng thì dừng quá trình.</p>
<p>Kết quả dự báo từ mô hình cuối cùng là một kết hợp từ những mô hình với trọng số <span class="math notranslate nohighlight">\(\alpha_i\)</span>:</p>
<div class="math notranslate nohighlight">
\[\hat{f}(\mathbf{x}) = \text{sign} (\sum_{i=1}^{p} \alpha_i \hat{f}^{i}(\mathbf{x}))\]</div>
<p>Trong phương trình trên hàm <span class="math notranslate nohighlight">\(\text{sign}(x)\)</span> là hàm nhận giá trị <span class="math notranslate nohighlight">\(-1\)</span> nếu dấu của <span class="math notranslate nohighlight">\(x\)</span> là dương và nhận giá trị <span class="math notranslate nohighlight">\(-1\)</span> nếu ngược lại.</p>
<p>Các hệ số <span class="math notranslate nohighlight">\(\alpha_i\)</span> được tính từ <em>phương pháp tăng cường</em>, chúng được sử dụng để đánh trọng số mức độ đóng góp từ mỗi một mô hình con <span class="math notranslate nohighlight">\(\hat{f}^{i}\)</span> trong chuỗi nhằm phân bổ vai trò quyết định trên từng mô hình khác nhau tuỳ thuộc vào mức độ chính xác của chúng. Điều này được phân tích kĩ hơn bên dưới.</p>
<p>Khi huấn luyện một mô hình con <span class="math notranslate nohighlight">\(\hat{f}^{i}\)</span> thì chúng ta áp dụng một trọng số <span class="math notranslate nohighlight">\(w_j\)</span> lên từng quan sát <span class="math notranslate nohighlight">\((\mathbf{x}_j, y_j)\)</span> sao cho đối với những quan sát bị dự báo sai thì trọng số của nó sẽ lớn hơn. Như vậy ở mô hình tiếp theo sẽ ưu tiên dự báo đúng những quan sát này hơn so với những quan sát đã được dự báo đúng. Ở thời điểm khởi đầu thì chúng ta gán <span class="math notranslate nohighlight">\(w_j = \frac{1}{N}, ~~ \forall i = \overline{1, N}\)</span>.</p>
<div class="section" id="cac-buoc-cua-thuat-toan-adaboosting">
<h2>12.1.1. Các bước của thuật toán AdaBoosting<a class="headerlink" href="#cac-buoc-cua-thuat-toan-adaboosting" title="Permalink to this headline">¶</a></h2>
<p>1.- Khởi tạo trọng số quan sát <span class="math notranslate nohighlight">\(w_i = \frac{1}{N}, \forall i = \overline{1, N}\)</span>.</p>
<p>2.- Lặp lại quá trình huấn luyện chuỗi mô hình ở mỗi bước <span class="math notranslate nohighlight">\(b\)</span>, <span class="math notranslate nohighlight">\(b = 1,2, \dots, B\)</span> gồm các bước con:</p>
<p>a. Khớp mô hình <span class="math notranslate nohighlight">\(\hat{f}^{b}\)</span> cho tập huấn luyện sử dụng trọng số <span class="math notranslate nohighlight">\(w_i\)</span> cho mỗi quan sát <span class="math notranslate nohighlight">\((\mathbf{x}_i, y_i)\)</span>.</p>
<p>b. Tính sai số huấn luyện:</p>
<div class="math notranslate nohighlight">
\[r_b = \frac{\sum_{i=1}^{N} w_i \mathbf{1}(y_i \neq \hat{f}^{b}(\mathbf{x}_i))}{\sum_{i=1}^{N} w_i}\]</div>
<p>Ở đây <span class="math notranslate nohighlight">\(\mathbf{1}(y_i \neq \hat{f}^{b}(\mathbf{x}_i))\)</span> chính là những quan sát bị dự báo sai ở mô hình thứ <span class="math notranslate nohighlight">\(b\)</span>. Giá trị <span class="math notranslate nohighlight">\(r_b \in [0, 1]\)</span>.</p>
<p>c. Tính trọng số quyết định cho từng mô hình:</p>
<div class="math notranslate nohighlight">
\[\alpha_b = \log(\frac{(1-r_b)}{r_b})\]</div>
<p>d. Cập nhật trọng số cho từng quan sát:</p>
<div class="math notranslate nohighlight">
\[ w_i := w_i \exp[\alpha_b \mathbf{1}(y_i \neq \hat{f}^{b}(\mathbf{x}_i))] \]</div>
<p>với <span class="math notranslate nohighlight">\(\forall i = \overline{1, N}\)</span>. Như vậy ta có thể nhận thấy rằng:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{split}
  w_i := \left\{
  \begin{matrix}
  w_i &amp;\text{ if } y_i = \hat{f}^{b}(\mathbf{x}_i) \\
  w_i \exp(\alpha_b) &amp;\text{ if } y_i \neq \hat{f}^{b}(\mathbf{x}_i)
  \end{matrix}
  \right.\end{split}
  \end{split}\]</div>
<p>Sau khi tính xong các trọng số <span class="math notranslate nohighlight">\(w_i\)</span> thì giá trị của chúng sẽ được chuẩn hoá  bằng cách chia cho tổng <span class="math notranslate nohighlight">\(\sum_{i=1}^{N} w_i\)</span>.</p>
<p>3.- Cập nhật dự báo cuối cùng:</p>
<div class="math notranslate nohighlight">
\[\hat{f}(\mathbf{x}) = \text{sign} (\sum_{i=1}^{p} \alpha_i \hat{f}^{i}(\mathbf{x})) \tag{1}\]</div>
<p>Trọng số <span class="math notranslate nohighlight">\(\alpha_i\)</span> được tính ở bước thứ 2 thể hiện vai trò quan trọng trong việc ra quyết định của mô hình thứ <span class="math notranslate nohighlight">\(i\)</span>. Giá trị này được tính theo một hàm nghịch biến với sai số của mô hình. Chúng ta cùng phân tích hàm này bên dưới:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">alpha</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">z</span><span class="p">)</span><span class="o">/</span><span class="n">z</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;error rate $r_b$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\alpha_b$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\alpha_b$ vs error rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Boosting_3_0.png" src="../_images/Boosting_3_0.png" />
</div>
</div>
<p><strong>Hình 2:</strong> Giá trị của <em>trọng số quyết định</em> <span class="math notranslate nohighlight">\(\alpha_b\)</span> theo sai số <span class="math notranslate nohighlight">\(r_b\)</span>. Đây là một hàm nghịch biến theo <span class="math notranslate nohighlight">\(r_b\)</span> và có giá trị từ <span class="math notranslate nohighlight">\((-\infty, + \infty)\)</span></p>
<p>Bên dưới ta sẽ xét 3 trường hợp đối với sai số dự báo <span class="math notranslate nohighlight">\(r_b\)</span>:</p>
<ul class="simple">
<li><p>Khi <span class="math notranslate nohighlight">\(r_b = 0.5\)</span> tương ứng với kết quả từ một mô hình dự báo ngẫu nhiên. Trường hợp này có <span class="math notranslate nohighlight">\(\alpha_b = 0\)</span>. Khi đó mô hình không có đóng góp gì vào hàm dự báo được thể hiện ở công thức <span class="math notranslate nohighlight">\((1)\)</span>. Điều này là hợp lý vì một giá trị dự báo ngẫu nhiên thì không có ích cho việc phân loại. Đồng thời trọng số sau cập nhật <span class="math notranslate nohighlight">\(w_i \exp(\alpha_b) = w_i\)</span>, tức là vai trò của các quan sát được giữ cố định.</p></li>
<li><p>Khi <span class="math notranslate nohighlight">\(r_b\)</span> tiến dần tới <span class="math notranslate nohighlight">\(0\)</span>, chẳng hạn <span class="math notranslate nohighlight">\(r_b = 0.1\)</span>, tương ứng với mô hình dự báo có tỷ lệ sai số thấp và đây là một mô hình khá mạnh. Khi đó <span class="math notranslate nohighlight">\(\alpha_b = \log \frac{1-0.1}{0.1} = \log{9} = 2.197\)</span> và <span class="math notranslate nohighlight">\(\exp(\alpha_b) = 9\)</span>. Như vậy đối với những quan sát bị dự báo sai thì trọng số của nó được gấp lên 9 lần, điều này giúp cho những mô hình sau sẽ điều chỉnh lại <em>cây quyết định</em> sao cho tập trung vào dự báo đúng những quan sát này. Đồng thời <span class="math notranslate nohighlight">\(\alpha_b \hat{f}^{b}(\mathbf{x}) = 2.197~\hat{f}^{b}(\mathbf{x})\)</span> cho thấy các dự báo từ mô hình này được đánh giá rất cao và góp phần gia tăng điểm số dự báo cuối cùng theo như công thức <span class="math notranslate nohighlight">\((1)\)</span>.</p></li>
<li><p>Khi <span class="math notranslate nohighlight">\(r_b\)</span> tiến dần tới <span class="math notranslate nohighlight">\(1\)</span>, chẳng hạn <span class="math notranslate nohighlight">\(r_b = 0.9\)</span> cho thấy đây là một mô hình rất yếu vì có tỷ lệ sai số dự báo cao. Khi đó <span class="math notranslate nohighlight">\(\alpha_b = \log \frac{1-0.9}{0.9} = \log \frac{1}{9} = -2.197\)</span> là một giá trị âm tương đối nhỏ và <span class="math notranslate nohighlight">\(\exp(\alpha_b) = \frac{1}{9}\)</span> là một giá trị gần 0. Như vậy trọng số <span class="math notranslate nohighlight">\(w_i \exp(\alpha_b)\)</span> sẽ bị giảm gấp 9 lần so với <span class="math notranslate nohighlight">\(w_i\)</span>. Lưu ý rằng trong trường hợp này mô hình đang dự báo hầu hết là sai nên nếu mô hình dự báo sai thì dường như những quan sát đó lại dễ được dự báo đúng và ít quan trọng. Điều này cũng giống như một người dự báo sai tới 90% thì khả năng ta lấy kết quả ngược lại của anh ta sẽ được mô hình dự báo đúng 90% và những trường hợp anh ta dự báo sai thường dễ dàng được phân loại đúng nhờ làm ngược lại. Do đó ta cần giảm trọng số <span class="math notranslate nohighlight">\(w_i\)</span> cho những quan sát mà mô hình dự báo sai, trong trường hợp này là giảm đi 9 lần. Đồng thời đóng góp từ kết quả dự báo vào mô hình là <span class="math notranslate nohighlight">\(\alpha_b \hat{f}^{b}(\mathbf{x}) = -2.197~\hat{f}^{b}(\mathbf{x})\)</span> cho thấy kết quả từ mô hình này sẽ được cập nhật ngược chiều vào điểm số cuối cùng. Điều này cũng giống như chúng ta làm ngược lại gợi ý của một người hay phán đoán sai để thu được phán đoán đúng.</p></li>
</ul>
<p>Quá trình <em>tăng cường</em> mô hình sẽ tiếp tục như vậy cho đến khi mô hình đạt số lượng tối đa hoặc toàn bộ các quan sát trên tập kiểm tra được phân loại đúng. Một lưu ý đó là các mô hình <em>cây quyết định</em> con trong phương pháp <em>tăng cường</em> thường có độ sâu thấp, thông thường chỉ gồm 1 node gốc với hai node lá, trường hợp cây quyết định chỉ gồm một node gốc được gọi là mô hình <em>gốc cây</em> (<em>stump</em>). Sở dĩ chúng ta không cần yêu cầu các <em>cây quyết định</em> phải quá phức tạp là để ngăn ngừa hiện tượng <em>quá khớp</em> có thể xảy ra và đồng thời tăng khả năng giải thích cho mô hình.</p>
<p>Bên dưới chúng ta sẽ thực hành huấn luyện mô hình <em>AdaBoosting</em> trên <em>sklearn</em>.</p>
</div>
<div class="section" id="huan-luyen-adaboosting-tren-sklearn">
<h2>12.1.2. Huấn luyện <em>AdaBoosting</em> trên sklearn<a class="headerlink" href="#huan-luyen-adaboosting-tren-sklearn" title="Permalink to this headline">¶</a></h2>
<p>Trên sklearn thực tế đang sử dụng phiên bản dự báo đa lớp đối với thuật toán <em>AdaBoost</em>, được gọi là <em>SAMME</em>(là viết tắt của <em>Stagewise Additive Modeling using a Multiclass Exponential loss function</em>). Khi chỉ có hai lớp, <em>SAMME</em> tương đương với AdaBoost. Ngoài ra, để mô hình có thể ước lượng được xác suất của lớp (tức là có hàm <em>predict_proba()</em>), thì sklearn có thể sử dụng một biến thể của <em>SAMME</em> được gọi là <em>SAMME.R</em> (chữ R là viết tắt của với “Real”), dựa trên xác suất hơn là giá trị nhãn dự báo và nhìn chung chúng hoạt động tốt hơn. Đoạn mã sau giúp huấn luyện một mô hình AdaBoost dựa trên 200 mô hình <em>gốc cây</em> (<em>stump</em>) bằng cách sử dụng class <em>AdaBoostClassifier</em> của sklearn. Mô hình <em>gốc cây</em> thì có max_depth = 1 hay nói cách khác, đây là cây quyết định bao gồm một node quyết định duy nhất cộng với với hai node lá. Đây cũng chính là cấu hình mặc định cho class <em>AdaBoostClassifier</em>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Load the dataset </span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">1</span>

<span class="c1"># Train/test split</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

<span class="n">idx_train</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
<span class="n">idx_test</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="mi">100</span><span class="p">:]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">idx_train</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_test</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">idx_test</span><span class="p">]</span>

<span class="c1"># Train model</span>
<span class="n">ada_clf</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
  <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
  <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;SAMME.R&quot;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>

<span class="n">ada_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluate model on train and test</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">ada_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;accuracy on train: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_pred_train</span><span class="o">==</span><span class="n">y_train</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>

<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">ada_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;accuracy on test: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_pred_test</span><span class="o">==</span><span class="n">y_test</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>accuracy on train:  1.0
accuracy on test:  0.96
</pre></div>
</div>
</div>
</div>
<p>Như vậy kết quả của mô hình đạt độ chính xác trên tập huấn luyện là 100% và tập kiểm tra là 96%. Kết quả này cao hơn so với mô hình được huấn luyện từ thuật toán <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/RandomForest.html#huan-luyen-mo-hinh-rung-cay">rừng cây</a>.</p>
</div>
</div>
<div class="section" id="gradient-boosting">
<h1>12.2. Gradient Boosting<a class="headerlink" href="#gradient-boosting" title="Permalink to this headline">¶</a></h1>
<p>Phương pháp <em>Gradient Boosting</em> cũng có ý tưởng tương tự như <em>AdaBoosting</em> đó là huấn luyện liên tiếp các mô hình yếu. Nhưng chúng ta không sử dụng sai số của mô hình để tính toán trọng số cho dữ liệu huấn luyện mà sử dụng phần dư. Xuất phát từ mô hình hiện tại, chúng ta cố gắng xây dựng một cây quyết định cố gắng khớp phần dư từ mô hình liền trước. Điểm đặc biệt của mô hình này đó là thay vì chúng ta cố gắng khớp giá trị biến mục tiêu là <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> thì chúng ta sẽ tìm cách khớp giá trị sai số của mô hình trước đó. Sau đó chúng ta sẽ đưa thêm mô hình huấn luyện vào hàm dự báo để cập nhật dần dần phần dư. Mỗi một cây quyết định trong chuỗi mô hình có kích thước rất nhỏ với chỉ một vài <em>nodes quyết định</em> được xác định bởi tham số độ sâu <span class="math notranslate nohighlight">\(d\)</span> trong mô hình. Hình bên dưới sẽ minh hoạ cụ thể hơn quá trình này:</p>
<p><img alt="" src="https://imgur.com/YzvCJ6g.png" /></p>
<p><strong>Hình 3:</strong> Phương pháp huấn luyện mô hình theo <em>Gradient Boosting</em>. Các mô hình <em>cây quyết định</em> được sắp xếp theo chuỗi. Mỗi cây quyết định sẽ được thành lập phụ thuộc vào kết quả dự báo của cây quyết định liền trước. Tại một cây quyết định mô hình sẽ tìm cách khớp phần dư từ cây quyết định trước đó.</p>
<p>Bằng cách khớp trên những cây quyết định có kích thước rất nhỏ trên những phần dư, chúng ta sẽ từ từ cải hiện hàm dự báo <span class="math notranslate nohighlight">\(\hat{f}\)</span> trong vùng mà nó không được dự báo tốt. <em>Tham số co</em> (<em>shrinkage parameter</em>) <span class="math notranslate nohighlight">\(\lambda\)</span> cũng giống như <em>hệ số học tập</em> (<em>learning rate</em>) có tác dụng làm chậm quá trình tiếp cận tới mô hình tốt hơn, điều này cho phép tạo ra nhiều các cây quyết định với hình dạng khác nhau để khớp phần dư. Theo phương pháp tiếp cận chậm bằng cách lấp đầy từ từ phần dư, mô hình thường có hiệu suất cao và vượt trội so với phương pháp <em>bỏtúi</em> khi xây dựng một cây quyết định sâu ngay từ đầu. Lưu ý rằng, theo phương pháp <em>tăng cường</em> thì sự thành lập của mỗi cây quyết định phụ thuộc mạnh mẽ vào những cây quyết định đã được phát triển trước đó.</p>
<p>Ở hình trên chúng ta vừa mô tả quá trình <em>tăng cường</em> đối với một <em>cây hồi quy</em> (<em>regression tree</em>) áp dụng trên bài toán dự báo. Các tiếp cận đối với bài toán <em>phân loại</em> tương tự như phương pháp <em>AdaBoosting</em>. Như vậy trong <em>phương pháp tăng cường</em> sẽ có ba tham số hiệu chỉnh chính:</p>
<ol class="simple">
<li><p>Số lượng cây <span class="math notranslate nohighlight">\(B\)</span>. Không giống như phương pháp <em>rừng cây</em>, <em>phương pháp tăng cường</em> có thể gặp hiện tượng <em>quá khớp</em> nếu <span class="math notranslate nohighlight">\(B\)</span> lớn, mặc dù hiện tượng <em>quá khớp</em> này có xu hướng xảy ra từ từ nếu chúng xuất hiện. Để lựa chọn ra số lượng cây <span class="math notranslate nohighlight">\(B\)</span> phù hợp chúng ta có thể sử dụng <em>đánh giá chéo</em> (<em>cross validation</em>).</p></li>
<li><p><em>Hệ số co</em> <span class="math notranslate nohighlight">\(\lambda\)</span> là một số dương nhỏ. Hệ số này cũng gần giống như <em>learning rate</em> có tác dụng kiểm soát tỷ lệ mà <em>phương pháp tăng cường</em> cập nhật số dư. Các giá trị của <em>hệ số co</em> thường là 0.01 hoặc 0.001, tuỳ thuộc vào từng bài toán và từng bộ dữ liệu cụ thể. Thông thường khi <span class="math notranslate nohighlight">\(\lambda\)</span> rất nhỏ có thể cần sử dụng một giá trị rất lớn của <span class="math notranslate nohighlight">\(B\)</span> để đạt được hiệu suất tốt.</p></li>
<li><p>Độ sâu <span class="math notranslate nohighlight">\(d\)</span> của cây quyết định đại diện cho số lần phân chia tối đa trong mỗi cây quyết định. Thường thì trong <em>phương pháp tăng cường</em> thì chúng ta không cần yêu cầu <span class="math notranslate nohighlight">\(d\)</span> quá lớn. Điều này nhằm kiểm soát mức độ phức tạp của mô hình và tránh hiện tượng <em>quá khớp</em>. Trường hợp phổ biến là <span class="math notranslate nohighlight">\(d = 1\)</span> cho thấy mô hình huấn luyện theo <em>phương pháp tăng cường</em> (gọi là <em>mô hình tăng cường</em>) đã có thể hoạt động tốt, khi đó mỗi cây được gọi là <em>gốc cây</em> (<em>stump</em>) chỉ gồm một node phân chia. Trong trường hợp này, <em>mô hình tăng cường</em> tìm cách khớp một xác suất cộng dồn mà mỗi một phần tử là một mô hình <em>gốc cây</em> chỉ gồm một câu hỏi.</p></li>
</ol>
<div class="section" id="cac-buoc-cua-thuat-toan-gradient-boosting">
<h2>12.2.1. Các bước của thuật toán Gradient Boosting<a class="headerlink" href="#cac-buoc-cua-thuat-toan-gradient-boosting" title="Permalink to this headline">¶</a></h2>
<p>Giả định <span class="math notranslate nohighlight">\(\hat{f}(x)\)</span> là hàm dự báo từ <em>phương pháp tăng cường</em> được áp dụng trên một tác vụ dự báo với ma trận đầu vào <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> và biến mục tiêu là véc tơ <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>. Tại mô hình thứ <span class="math notranslate nohighlight">\(b\)</span> trong chuỗi mô hình dự báo, kí hiệu là <span class="math notranslate nohighlight">\(\hat{f}^{b}\)</span>, ta tìm cách khớp một giá trị phần dư <span class="math notranslate nohighlight">\(\mathbf{r}_i\)</span> từ cây quyết định tiền nhiệm <span class="math notranslate nohighlight">\(\hat{f}^{b-1}\)</span>. Các bước trong quá trình huấn luyện mô hình theo <em>phương pháp tăng cường</em> được tóm tắt như sau:</p>
<p>1.- Ban đầu ta thiết lập hàm dự báo <span class="math notranslate nohighlight">\(\hat{f}(\mathbf{x}) = 0\)</span> và số dư <span class="math notranslate nohighlight">\(\mathbf{r}_0 = \mathbf{y}\)</span> cho toàn bộ quan sát trong tập huấn luyện.</p>
<p>2.- Lặp lại quá trình huấn luyện cây quyết định theo chuỗi tương ứng với <span class="math notranslate nohighlight">\(b = 1,2, \dots, B\)</span>. Với một lượt huấn luyện gồm các bước con sau đây:</p>
<p>a. Khớp một cây quyết định <span class="math notranslate nohighlight">\(\hat{f}^{b}\)</span> có độ sâu là <span class="math notranslate nohighlight">\(d\)</span> trên tập huấn luyện <span class="math notranslate nohighlight">\((\mathbf{X}, \mathbf{r}_b)\)</span>.</p>
<p>b. Cập nhật <span class="math notranslate nohighlight">\(\hat{f}\)</span>  bằng cách cộng thêm vào giá trị dự báo của một cây quyết đinh, giá trị này được nhân với hệ số co <span class="math notranslate nohighlight">\(\lambda\)</span>:</p>
<div class="math notranslate nohighlight">
\[\hat{f}(\mathbf{x}) = \hat{f}(\mathbf{x})+\lambda \hat{f}^{b}(\mathbf{x})\]</div>
<p>c. Cập nhật phần dư cho mô hình:</p>
<div class="math notranslate nohighlight">
\[\mathbf{r}_{b+1} := \mathbf{r}_b - \lambda \hat{f}^{b}(\mathbf{x})\]</div>
<p>Thuật toán sẽ dừng cập nhật khi số lượng cây quyết định đạt ngưỡng tối đa <span class="math notranslate nohighlight">\(B\)</span> hoặc toàn bộ các quan sát trên tập huấn luyện được dự báo đúng.</p>
<p>3.- Kết quả dự báo từ chuỗi mô hình sẽ là kết hợp của các mô hình con:</p>
<div class="math notranslate nohighlight">
\[\hat{f}(\mathbf{x}) = \sum_{b=1}^{B} \lambda \hat{f}^{b}(\mathbf{x})\]</div>
</div>
<div class="section" id="huan-luyen-gradient-boosting-tren-sklearn">
<h2>12.2.2 Huấn luyện <em>Gradient Boosting</em> trên sklearn<a class="headerlink" href="#huan-luyen-gradient-boosting-tren-sklearn" title="Permalink to this headline">¶</a></h2>
<p>Mô hình <em>Gradient Boosting</em> sử dụng các mô hình <em>cây quyết định</em> (<em>Decision Trees</em>) còn được gọi là <em>Gradient Tree Boosting</em> hoặc <em>Gradient Boosted Regression Tree</em> (viết tắt là <em>GBRT</em>). Một cách đơn giản để huấn luyện <em>GBRT</em> trên <em>sklearn</em> là sử dụng class <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor">GradientBoostingRegressor</a>. Các tham số của class này cũng tương tự như <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/RandomForest.html#huan-luyen-mo-hinh-rung-cay">mô hình rừng cây</a>. Chúng ta cũng sẽ có những tham số chính để kiểm soát độ lớn của mô hình bao gồm:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GradientBoostingRegressor</span><span class="p">(</span>
  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;ls&#39;</span><span class="p">,</span> 
  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> 
  <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>  
  <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
  <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
  <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
  <span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
  <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
</pre></div>
</div>
<p>Về các hệ số này các bạn có thể xem lại <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/RandomForest.html#huan-luyen-mo-hinh-rung-cay">mô hình rừng cây</a>. Chúng ta cần quan tâm tới các tham số chính sau:</p>
<ul class="simple">
<li><p>max_depth: Độ sâu tối đa của một <em>cây quyết định</em>, tương ứng với tham số <span class="math notranslate nohighlight">\(d\)</span>.</p></li>
<li><p>min_samples_leaf: Số mẫu tối đa được phép của một node lá.</p></li>
<li><p>n_estimators: Số lượng tối đa các cây quyết định trong mô hình, tương ứng với tham số <span class="math notranslate nohighlight">\(B\)</span>.</p></li>
<li><p>learning_rate: Hệ số co trong quá trình cập nhật phần dư, tương ứng với <span class="math notranslate nohighlight">\(\lambda\)</span>.</p></li>
</ul>
<p>Bên dưới chúng ta sẽ thực hành huấn luyện mô hình <em>GradientBoostingRegressor</em> cho một tác vụ dự báo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Initialize train/test</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">250</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="mf">3.4</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">250</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">200</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[:</span><span class="mi">200</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">200</span><span class="p">:,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="mi">200</span><span class="p">:]</span>

<span class="c1"># Regression model</span>
<span class="n">gb_rt</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                                 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                                 <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">gb_rt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluation model</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">gb_rt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MAPE on train: </span><span class="si">{:01f}</span><span class="s1"> %&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">y_train</span><span class="o">-</span><span class="n">y_pred_train</span><span class="p">)</span><span class="o">/</span><span class="n">y_train</span><span class="p">))))</span>

<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">gb_rt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MAPE on test: </span><span class="si">{:01f}</span><span class="s1"> %&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">y_test</span><span class="o">-</span><span class="n">y_pred_test</span><span class="p">)</span><span class="o">/</span><span class="n">y_test</span><span class="p">))))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MAPE on train: 5.253766 %
MAPE on test: 9.215335 %
</pre></div>
</div>
</div>
</div>
<p>Kết quả MAPE là 5.1% và 8.63% là tương đối cao. Chúng ta có thể huấn luyện thêm bộ dữ liệu trên với những mô hình dự báo khác như <em>hồi qui tuyến tính, Support Vector Regression, Ridge Regression, Lasso Regression, RandomForest</em> để so sánh hiệu quả giữa những lớp mô hình này với nhau.</p>
<p>Để tinh chỉnh siêu tham số cho mô hình <em>boosting</em> thì chúng ta chủ yếu cần quan tâm tới 3 tham số chính là số lượng cây <span class="math notranslate nohighlight">\(B\)</span>, độ sâu cây quyết định <span class="math notranslate nohighlight">\(d\)</span> và hệ số co <span class="math notranslate nohighlight">\(\lambda\)</span>. Bạn đọc có thể xem lại <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_appendix/appendix_pipeline.html#gridsearch">gridsearch - sklearn pipeline</a> để tiến hành tinh chỉnh siêu tham số cho mô hình.</p>
</div>
</div>
<div class="section" id="tong-ket">
<h1>12.3. Tổng kết<a class="headerlink" href="#tong-ket" title="Permalink to this headline">¶</a></h1>
<p>Huấn luyện mô hình theo <em>phương pháp tăng cường</em> thường mang lại hiệu quả cao trên đồng thời cả hai tác vụ phân loại và dự báo. Ý tưởng chính của <em>phương pháp tăng cường</em> đó là chúng ta sẽ huấn luyện một chuỗi các mô hình sao cho mỗi một mô hình sẽ sử dụng thông tin dự báo của mô hình tiền nhiệm để tìm cách khắc phục lỗi trên những dự báo của mô hình trước. Như vậy, sự hình thành của một mô hình sẽ chịu sự ảnh hưởng từ kết quả dự báo của mô hình tiền nhiệm. Phương pháp <em>AdaBoosting</em> được áp dụng trong bài toán phân loại sẽ thay đổi tập huấn luyện thông qua cập nhật trọng số huấn luyện cho từng quan sát được tính dựa trên tỷ lệ sai số của mô hình tiền nhiệm. Trong khi đó phương pháp <em>Gradient Boosting</em> không sử dụng trực tiếp biến mục tiêu <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> là giá trị dự báo mà thay thế bằng phần dư của mô hình trước đó. Phần dư sẽ được cập nhật một cách từ từ theo một hệ số co để giúp chuỗi mô hình đa dạng các <em>cây quyết định</em> hơn. Các mô hình sẽ ngừng được thêm vào cho tới khi số lượng các mô hình dự báo đạt ngưỡng tối đa hoặc toàn bộ các quan sát được phân loại hoặc dự báo đúng.</p>
</div>
<div class="section" id="bai-tap">
<h1>12.4. Bài tập<a class="headerlink" href="#bai-tap" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p>Nếu mô hình <em>AdaBoosting</em> gặp hiện tượng <em>vị khớp</em> (<em>underfitting</em>) thì bạn sẽ cần tinh chỉnh những tham số nào?</p></li>
<li><p>Tương tự như vậy nếu <em>AdaBoosting</em> gặp hiện tượng <em>quá khớp</em> (<em>overfitting</em>) thì bạn cần tinh chỉnh những tham số nào?</p></li>
<li><p>Khi <em>Gradient Boosting</em> gặp hiện tượng <em>quá khớp</em> thì cần tăng hay giảm <em>hệ số co</em>? Tại sao?</p></li>
<li><p>Độ sâu <span class="math notranslate nohighlight">\(d\)</span> của mô hình nên được tăng hay giảm khi mô hình <em>AdaBoosting</em> gặp hiện tượng <em>quá khớp</em>?</p></li>
<li><p>Số lượng cây quyết định nên tăng hay giảm khi mô hình <em>AdaBoosting</em> gặp hiện tượng quá khớp?</p></li>
<li><p>Điểm khác biệt chính của <em>phương pháp tăng cường</em> (<em>boosting</em>) so với phương pháp huấn luyện <em>kết hợp</em> và <em>bỏ túi</em> là gì?</p></li>
<li><p>Hãy lựa chọn một trong những bộ dữ liệu trên <a class="reference external" href="https://archive.ics.uci.edu/ml/datasets.php?format=&amp;task=reg&amp;att=&amp;area=&amp;numAtt=&amp;numIns=&amp;type=&amp;sort=nameUp&amp;view=table">UCI</a>, phân chia tập train/test và thực hiện huấn luyện mô hình theo phương pháp <em>Gradient Boosting</em> hoặc <em>AdaBoosting</em>.</p></li>
<li><p>Thực hiện tinh chỉnh (<em>tuning</em>) siêu tham số cho mô hình ở câu 7.</p></li>
<li><p>Dự báo mô hình trên tập test và tính toán sai số dự báo theo RMSE, MAP và MAPE.</p></li>
<li><p>Mô hình xảy ra hiện <em>quá khớp</em> hay <em>vị khớp</em>? Tìm cách khắc phục mô hình.</p></li>
</ol>
</div>
<div class="section" id="tai-lieu-tham-khao">
<h1>12.5. Tài liệu tham khảo<a class="headerlink" href="#tai-lieu-tham-khao" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p><a class="reference external" href="https://amzn.to/3gYt0V9">An Introduction to Statistical Learning: with Applications in R - page 321</a></p></li>
<li><p><a class="reference external" href="https://amzn.to/31SA3bt">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a></p></li>
<li><p><a class="reference external" href="https://amzn.to/3iFPHhq">Applied Predictive Modeling - page 203 to 389</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/chapter/10.1007/3-540-59119-2_166#page-1">A decision-theoretic generalization of on-line learning and an application to boosting</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/article/10.1023/A:1007614523901">Improved Boosting Algorithms Using Confidence-rated Predictions</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-642-41136-6_5">Explaining Adaboost, Chapter from Empirical Inference</a></p></li>
<li><p><a class="reference external" href="http://www.site.uottawa.ca/%7Estan/csi5387/boost-tut-ppr.pdf">A Short Introduction to Boosting</a></p></li>
<li><p><a class="reference external" href="https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/">https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/</a></p></li>
<li><p><a class="reference external" href="https://www.mygreatlearning.com/blog/adaboost-algorithm/">https://www.mygreatlearning.com/blog/adaboost-algorithm/</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/AdaBoost">https://en.wikipedia.org/wiki/AdaBoost</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/boosting-algorithm-adaboost-b6737a9ee60c">https://towardsdatascience.com/boosting-algorithm-adaboost-b6737a9ee60c</a></p></li>
<li><p><a class="reference external" href="https://www.analyticsvidhya.com/blog/2021/03/introduction-to-adaboost-algorithm-with-python-implementation/">https://www.analyticsvidhya.com/blog/2021/03/introduction-to-adaboost-algorithm-with-python-implementation/</a></p></li>
<li><p><a class="reference external" href="https://www.kdnuggets.com/2020/12/implementing-adaboost-algorithm-from-scratch.html">https://www.kdnuggets.com/2020/12/implementing-adaboost-algorithm-from-scratch.html</a></p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html</a></p></li>
</ol>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="index_Boosting.html" title="previous page">12. Phương pháp tăng cường (<em>Boosting</em>)</a>
    <a class='right-next' id="next-link" href="index_KMeans.html" title="next page">13. k-Means Clustering</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Pham Dinh Khanh<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>