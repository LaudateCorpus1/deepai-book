
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>16.1. Ước lượng MLE cho phân phối Gaussian đa chiều &#8212; Deep AI KhanhBlog</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.37f24b989f4638ff9c27c22dc7559d4f.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/GMM.html" />
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tích phân Riemann và định lý Fubini" href="../ch_donation/fubini_and_riemann.html" />
    <link rel="prev" title="16. Gaussian Mixture Model" href="index_GMM.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://phamdinhkhanh.github.io/deepai-book/ch_ml/GMM.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="16.1. Ước lượng MLE cho phân phối Gaussian đa chiều" />
<meta property="og:description" content="16.1. Ước lượng MLE cho phân phối Gaussian đa chiều  Giả sử chúng ta có một bộ dữ liệu gồm các quan sát độc lập và xác định (iid) là \mathcal{D} = \{ \mathbf{x}" />
<meta property="og:image"       content="https://phamdinhkhanh.github.io/deepai-book/_static/ML_course_logos.jpeg" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ML_course_logos.jpeg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Deep AI KhanhBlog</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Lời nói đầu
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../contents.html">
   Các chương dự kiến
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contents.html#dong-gop-vao-du-an">
   Đóng góp vào dự án
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/main_contents.html">
   Mục tiêu cuốn sách
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../latex.html">
   Latex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../latex.html#tham-khao-latex">
   Tham khảo latex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../grossary.html">
   Bảng thuật ngữ
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Phụ lục
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/appendix_dtypes.html">
   1. Định dạng dữ liệu
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html">
     1.1. Các định dạng số, boolean và ký tự
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#dinh-dang-sequence">
     1.2. Định dạng sequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#tom-tat">
     1.3. Tóm tắt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#bai-tap">
     1.4 Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#tai-lieu-tham-khao">
     1.5. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_pandas.html">
   2. Pandas
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html">
     2.1. Khởi tạo dataframe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#thao-tac-voi-dataframe">
     2.2. Thao tác với dataframe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#reshape-dataframe-tren-pandas">
     2.3. Reshape dataframe trên pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#thong-ke-theo-nhom-tren-pandas">
     2.4. Thống kê theo nhóm trên pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#join-merge-va-concatenate-bang">
     2.5. Join, Merge và Concatenate bảng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#ket-noi-sql">
     2.6. Kết nối SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#tong-ket">
     2.7. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#bai-tap">
     2.8. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#tai-lieu">
     2.9. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_numpy.html">
   3. Numpy
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html">
     3.1. Khởi tạo một mảng trên numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#doc-va-save-numpy-tu-file">
     3.2. Đọc và save numpy từ file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#truy-cap-mang-tren-numpy">
     3.2. Truy cập mảng trên numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#thay-doi-shape-cua-mang">
     3.3. Thay đổi shape của mảng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-ham-tren-numpy">
     3.4. Các hàm trên numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-ma-tran-dac-biet">
     3.5. Các ma trận đặc biệt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-phep-toan-tren-ma-tran">
     3.6. Các phép toán trên ma trận
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#id1">
     3.7. Các phép toán trên ma trận
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-phep-toan-tren-vec-to">
     3.8. Các phép toán trên véc tơ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#thanh-phan-cua-mang">
     3.9. Thành phần của mảng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#bai-tap">
     3.10. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#tai-lieu">
     3.11. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_matplotlib.html">
   4. Matplotlib
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html">
     4.1. Format chung của một biểu đồ trên matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#cac-bieu-do-co-ban-tren-matplotlib">
     4.2. Các biểu đồ cơ bản trên matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#cac-bieu-do-nang-cao-tren-matplotlib">
     4.3. Các biểu đồ nâng cao trên matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#ve-nhieu-bieu-do-con-tren-mot-bieu-do">
     4.4. Vẽ nhiều biểu đồ con trên một biểu đồ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#bieu-do-dong-tu-gif-file">
     4.5. Biểu đồ động từ gif file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#tong-ket">
     4.6. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#bai-tap">
     4.7. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#tai-lieu-tham-khao">
     4.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_OOP.html">
   5. Lập trình hướng đối tượng (Object Oriented Programming - OOP)
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html">
     5.1. Class và Object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#tinh-ke-thua">
     5.2. Tính kế thừa
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#module-va-package">
     5.3. Module và package
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#tong-ket">
     5.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#bai-tap">
     5.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#tai-lieu">
     5.6. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_pipeline.html">
   6. Sklearn Pipeline
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html">
     6.1. Thiết kế pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#danh-gia-cheo-cross-validation">
     6.2. Đánh giá cheó (
     <em>
      cross validation
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#gridsearch">
     6.3. GridSearch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#tong-ket">
     6.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#bai-tap">
     6.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#tai-lieu-tham-khao">
     6.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_Convex_Opt.html">
   7. Giới thiệu chung về optimization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html">
     7.1. Bài toán dạng tổng quát
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#cac-bai-toan-toi-uu-thuc-tien">
     7.2. Các bài toán tối ưu thực tiễn.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#bai-toan-geometric-programming-gp">
     7.3. Bài toán
     <em>
      Geometric Programming GP
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#bai-toan-quadratic-programming-qp">
     7.4. Bài toán
     <em>
      Quadratic Programming
     </em>
     (
     <em>
      QP
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#tong-ket">
     7.5. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#bai-tap">
     7.6. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html#tai-lieu-tham-khao">
     7.7. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Đại số tuyến tính
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html">
   1. Đại số tuyến tính
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html#tom-tat">
   2. Tóm tắt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html#bai-tap">
   3. Bài tập
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Giải tích
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html">
   1. Giải tích tích phân
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html#giai-tich-vi-phan">
   2. Giải tích vi phân
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html#bai-tap">
   3. Bài tập
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html#tai-lieu-tham-khao">
   4. Tài liệu tham khảo
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Xác suất
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html">
   1. Xác suất
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html#phan-phoi-xac-suat">
   2. Phân phối xác suất
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html#bai-tap">
   3. Bài tập
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html#tai-lieu-tham-khao">
   4. Tài liệu tham khảo
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="index_MLIntroduce.html">
   1. Khái quát Machine Learning
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_prediction.html">
   2. Bài toán dự báo
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html">
     2.1. Ứng dụng của hồi qui tuyến tính
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#ham-mat-mat">
     2.2. Hàm mất mát
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#hoi-qui-tuyen-tinh-da-bien">
     2.3. Hồi qui tuyến tính đa biến
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#dien-giai-xac-suat-cua-hoi-qui-tuyen-tinh">
     2.4. Diễn giải xác suất của hồi qui tuyến tính
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#huan-luyen-mo-hinh-hoi-qui-tuyen-tinh-tren-sklearn">
     2.5. Huấn luyện mô hình hồi qui tuyến tính trên sklearn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#do-thi-hoa-ket-qua-mo-hinh">
     2.6. Đồ thị hoá kết quả mô hình
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#danh-gia-mo-hinh-hoi-qui-tuyen-tinh-da-bien">
     2.7. Đánh gía mô hình hổi qui tuyến tính đa biến
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#ridge-regression-va-lasso-regression">
     2.8. Ridge regression và Lasso regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#tom-tat">
     2.9. Tóm tắt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#bai-tap">
     2.10. Bài tập
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_RidgedRegression.html">
   2.2. Hồi qui Ridge và Lasso
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html">
     2.2.2. Hồi qui Ridge
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#hoi-qui-lasso">
     2.2.3. Hồi qui Lasso
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#vi-sao-hoi-qui-lasso-lai-la-hoi-qui-lua-chon-bien">
     2.2.4. Vì sao hồi qui Lasso lại là hồi qui lựa chọn biến
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#elastic-net">
     2.2.5. Elastic Net
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#tuning-he-so-cho-mo-hinh-hoi-qui-ridge-lasso-va-elastic-net">
     2.2.6. Tuning hệ số cho mô hình hồi qui Ridge, Lasso và Elastic Net
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#tong-ket">
     2.2.7. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#bai-tap">
     2.2.8. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html#tai-lieu-tham-khao">
     2.2.9. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_classification.html">
   3. Bài toán phân loại
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html">
     3.1. Hồi qui Logistic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#tim-nghiem-toi-uu-bang-ha-doc-gradient-descent">
     3.2. Tìm nghiệm tối ưu bằng hạ dốc (
     <em>
      gradient descent
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#hoi-qui-logistic-tren-sklearn">
     3.3. Hồi qui Logistic trên sklearn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#tong-ket">
     3.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#bai-tap">
     3.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#tai-lieu-tham-khao">
     3.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_OvfAndUdf.html">
   4. Độ chệch (
   <em>
    bias
   </em>
   ) và phương sai (
   <em>
    variance
   </em>
   )
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html">
     4.1. Sự đánh đổi giữa độ chệch và phương sai
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#qua-khop-overfitting-va-vi-khop-underfitting">
     4.2. Quá khớp (
     <em>
      Overfitting
     </em>
     ) và vị khớp (
     <em>
      Underfitting
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#xu-ly-hien-tuong-qua-khop">
     4.3. Xử lý hiện tượng quá khớp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#xu-ly-hien-tuong-vi-khop">
     4.4. Xử lý hiện tượng vị khớp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#tong-ket">
     4.5. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#bai-tap-tham-khao">
     4.6. Bài tập tham khảo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#tai-lieu-tham-khao">
     4.7. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_ModelMetric.html">
   5. Thước đo mô hình phân loại
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html">
     5.1. Bộ dữ liệu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-chinh-xac-accuracy">
     5.2. Độ chính xác (accuracy)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-chuan-xac-precision">
     5.3. Độ chuẩn xác (
     <em>
      precision
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-phu-recall">
     5.4. Độ phủ (
     <em>
      Recall
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#trade-off-giua-do-chuan-xac-va-do-phu">
     5.5. Trade off giữa
     <em>
      độ chuẩn xác
     </em>
     và
     <em>
      độ phủ
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#f1-score">
     5.6. f1 Score
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#tai-sao-f1-score-khong-la-trung-binh-cong-do-chuan-xac-va-do-phu">
     5.7. Tại sao f1 score không là trung bình cộng
     <em>
      độ chuẩn xác
     </em>
     và
     <em>
      độ phủ
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-chinh-xac-accuracy-va-f1-score">
     5.8. Độ chính xác (
     <em>
      accuracy
     </em>
     ) và
     <em>
      f1 score
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#auc">
     5.9. AUC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#moi-quan-he-giua-tpr-va-fpr">
     5.10. Mối quan hệ giữa TPR và FPR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#gini-va-cap">
     5.11. Gini và CAP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#tong-ket">
     5.12. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#bai-tap">
     5.13. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#tai-lieu-tham-khao">
     5.14. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_creditScorecard.html">
   6. Ứng dụng mô hình scorecard
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="creditScorecard.html">
     6.1. Phương pháp chuyên gia và mô hình
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="creditScorecard.html#xay-dung-mo-hinh-credit-scorecard">
     6.2. Xây dựng mô hình credit scorecard
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_SVM.html">
   7. Giới thiệu về SVM
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html">
     7.1. Hàm mất mát của SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#duong-bien-va-le-trong-svm">
     7.2. Đường biên và lề trong SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#bai-toan-toi-uu-svm">
     7.3. Bài toán tối ưu SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#sorf-margin-classification">
     7.4. Sorf Margin Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#ky-thuat-tao-dac-trung">
     7.5. Kỹ thuật tạo đặc trưng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#kernel-trong-svm">
     7.6. Kernel trong SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#vi-du-ve-bai-toan-svm">
     7.7. Ví dụ về bài toán SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#tong-ket">
     7.8. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#bai-tap">
     7.9. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html#tai-lieu">
     7.10. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_DecisionTree.html">
   8. Khái niệm về cây quyết định
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html">
     8.1. Mô hình cây quyết định (
     <em>
      decision tree
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#bai-toan-phan-loai-cay-quyet-dinh-tren-bo-du-lieu-boston">
     8.2. Bài toán phân loại cây quyết định trên bộ dữ liệu boston
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#duong-bien-phan-chia-cua-cay-quyet-dinh">
     8.3. Đường biên phân chia của cây quyết định
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#cach-khoi-tao-cay-quyet-dinh">
     8.4. Cách khởi tạo cây quyết định
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#thuat-toan-id3-va-cart">
     8.5. Thuật toán ID3 và CART
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#chi-so-gini">
     8.6. Chỉ số Gini
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#cay-quyet-dinh-cho-bai-toan-du-bao">
     8.7. Cây quyết định cho bài toán dự báo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#dieu-kien-dung-de-giam-qua-khop-overfitting">
     8.8. Điều kiện dừng để giảm quá khớp (
     <em>
      overfitting
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#cat-tia-pruning">
     8.9. Cắt tỉa  (
     <em>
      pruning
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#tuning-sieu-tham-so-cho-mo-hinh-cay-quyet-dinh">
     8.10. Tuning siêu tham số cho mô hình cây quyết định
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#bai-tap">
     8.11. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#tai-lieu-tham-khao">
     8. 12. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_RandomForest.html">
   9. Giới thiệu về mô hình rừng cây (
   <em>
    Random Forest
   </em>
   )
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html">
     9.1. Ý tưởng của mô hình rừng cây
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html#huan-luyen-mo-hinh-rung-cay">
     9.2. Huấn luyện mô hình rừng cây
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html#danh-gia-muc-do-quan-trong-cua-bien">
     9.3. Đánh giá mức độ quan trọng của biến
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html#tong-ket">
     9.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html#bai-tap">
     9.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html#tai-lieu-tham-khao">
     9.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_Bayes.html">
   10. Bạn là
   <em>
    Tần suất
   </em>
   (
   <em>
    Frequentist
   </em>
   ) hay
   <em>
    Bayesian
   </em>
   ?
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html">
     10.1. Ước lượng hợp lý tối đa (
     <em>
      Maximum Likelihood Function - MLE
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html#uoc-luong-hau-nghiem-toi-da-maximum-a-posteriori">
     10.2. Ước lượng hậu nghiệm tối đa (
     <em>
      Maximum A Posteriori
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html#mo-hinh-xac-suat-naive-bayes">
     10.3. Mô hình xác suất Naive Bayes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html#tong-ket">
     10.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html#bai-tap">
     10.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html#tai-lieu">
     10.6. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_FeatureEngineering.html">
   11. Giới thiệu về feature engineering
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html">
     11.1. Feature Engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html#id1">
     11.2. Trích lọc đặc trưng (feature extraction)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html#id2">
     11.3. Biến đổi đặc trưng (feature transformation)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html#id3">
     11.4. Lựa chọn đặc trưng (
     <em>
      feature selection
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html#tong-ket">
     11.5. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html#tai-lieu-tham-khao">
     11.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_Boosting.html">
   12. Phương pháp tăng cường (
   <em>
    Boosting
   </em>
   )
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="Boosting.html">
     12.1. AdaBoosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Boosting.html#gradient-boosting">
     12.2. Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Boosting.html#tong-ket">
     12.3. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Boosting.html#bai-tap">
     12.4. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Boosting.html#tai-lieu-tham-khao">
     12.5. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_KMeans.html">
   13. k-Means Clustering
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html">
     13.1. Các bước của thuật toán k-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#su-hoi-tu-cua-thuat-toan-k-means-clustering">
     13.2. Sự hội tụ của thuật toán k-Means clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#phuong-phap-elbow-trong-lua-chon-so-cum">
     13.3. Phương pháp Elbow trong lựa chọn số cụm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#bieu-dien-du-lieu-da-chieu-tren-do-thi">
     13.4. Biểu diễn dữ liệu đa chiều trên đồ thị
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#han-che-cua-k-means">
     13.5. Hạn chế của k-Means
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#online-k-means-clustering">
     13.6. Online k-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#tong-ket">
     13.7. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#bai-tap">
     13.8. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html#tai-lieu">
     13.9. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_HierarchicalClustering.html">
   14. Hierarchical Clustering (
   <em>
    phân cụm phân cấp
   </em>
   )
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html">
     14.1. Chiến lược hợp nhất (
     <em>
      agglomerative
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#khoang-cach-giua-hai-cum">
     14.2. Khoảng cách giữa hai cụm?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#chien-luoc-phan-chia-divisive">
     14.3. Chiến lược phân chia (
     <em>
      divisive
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#dieu-kien-dung-cua-thuat-toan-phan-cum">
     14.4. Điều kiện dừng của thuật toán phân cụm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#do-phuc-tap-cua-thuat-toan-phan-cum-phan-cap">
     14.5. Độ phức tạp của thuật toán
     <em>
      phân cụm phân cấp
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#thuc-hanh-phan-cum-phan-cap">
     14.6. Thực hành
     <em>
      phân cụm phân cấp
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#tong-ket">
     14.7. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#bai-tap">
     14.8. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html#tai-lieu-tham-khao">
     14.9. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_DBSCAN.html">
   15. DBSCAN
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html">
     15.1. Phương pháp phân cụm dựa trên mật độ (
     <em>
      Density-Based Clustering
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#cac-buoc-trong-thuat-toan-dbscan">
     15.3. Các bước trong thuật toán DBSCAN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#xac-dinh-tham-so">
     4. Xác định tham số
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#huan-luyen-thuat-toan-dbscan">
     15.4. Huấn luyện thuật toán DBSCAN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#tong-ket">
     15.5. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#bai-tap">
     15.6. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html#tai-lieu-tham-khao">
     15.7. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index_GMM.html">
   16. Gaussian Mixture Model
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     16.1. Ước lượng MLE cho
     <em>
      phân phối Gaussian đa chiều
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#gaussian-mixture-model">
     16.2. Gaussian Mixture Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#thuc-hanh-mo-hinh">
     16.4. Thực hành mô hình
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#tong-ket">
     16.5. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#bai-tap">
     16.6. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#tai-lieu-tham-khao">
     16.7. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Đóng góp từ các tác giả khác
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/fubini_and_riemann.html">
   Tích phân Riemann và định lý Fubini
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/information_theory.html">
   Lý thuyết thông tin
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/ch_ml/GMM.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ch_ml/GMM.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/phamdinhkhanh/deepai-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/phamdinhkhanh/deepai-book/issues/new?title=Issue%20on%20page%20%2Fch_ml/GMM.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/phamdinhkhanh/deepai-book/edit/main/book/ch_ml/GMM.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/phamdinhkhanh/deepai-book/main?urlpath=tree/book/ch_ml/GMM.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   16.1. Ước lượng MLE cho
   <em>
    phân phối Gaussian đa chiều
   </em>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-mixture-model">
   16.2. Gaussian Mixture Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#uoc-luong-hop-ly-toi-da">
     16.2.1. Ước lượng hợp lý tối đa
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#khai-trien-ham-auxilary">
     16.2.2. Khai triển hàm
     <em>
      auxilary
     </em>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cac-buoc-trong-gmm">
     16.2.3. Các bước trong GMM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#thuc-hanh-mo-hinh">
   16.4. Thực hành mô hình
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tien-xu-ly-du-lieu">
     16.4.1. Tiền xử lý dữ liệu
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mo-hinh-gaussian-mixture">
     16.4.2. Mô hình
     <em>
      Gaussian Mixture
     </em>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lua-chon-sieu-tham-so-cho-mo-hinh-gmm">
     16.4.3. Lựa chọn siêu tham số cho mô hình
     <em>
      GMM
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tong-ket">
   16.5. Tổng kết
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bai-tap">
   16.6. Bài tập
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tai-lieu-tham-khao">
   16.7. Tài liệu tham khảo
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="uoc-luong-mle-cho-phan-phoi-gaussian-da-chieu">
<h1>16.1. Ước lượng MLE cho <em>phân phối Gaussian đa chiều</em><a class="headerlink" href="#uoc-luong-mle-cho-phan-phoi-gaussian-da-chieu" title="Permalink to this headline">¶</a></h1>
<p>Giả sử chúng ta có một bộ dữ liệu gồm các quan sát độc lập và xác định (iid) là <span class="math notranslate nohighlight">\(\mathcal{D} = \{ \mathbf{x}_1, \mathbf{x}_2. \dots, \mathbf{x}_N \}\)</span>. Trong đó mỗi một <span class="math notranslate nohighlight">\(\mathbf{x}_i \in \mathbb{R}^{d}\)</span> là một véc tơ quan sát trong không gian <span class="math notranslate nohighlight">\(d\)</span> chiều được lấy mẫu từ <em>phân phối Gaussian đa chiều</em>. Chúng ta cần ước lượng phân phối của tham số thông qua <em>ước lượng hợp lý tối đa MLE</em>.</p>
<p><span class="math notranslate nohighlight">\(N\)</span> quan sát được giả định là độc lập. Do đó hàm hợp lý của phân phối của <span class="math notranslate nohighlight">\(N\)</span> quan sát sẽ bằng tích của xác suất trên từng quan sát:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
	l(\mathbf{ \mu, \Sigma }|\mathcal{D}) &amp; = \log \prod_{i=1}^m f_{\mathbf{x}_{i}}(\mathbf{x}_{i} | \mu , \mathbf{\Sigma} )
	\\
	&amp; =  \log  \ \prod_{i=1}^N \frac{1}{(2 \pi)^{d/2} |\mathbf{\Sigma}|^{1/2}} \exp \left( - \frac{1}{2} (\mathbf{x}_{i} - \mu)^{\intercal} \mathbf{\Sigma}^{-1} (\mathbf{x}_{i} - \mu) \right) 
	\\
	&amp; = \sum_{i=1}^N \left( - \frac{d}{2} \log (2 \pi) - \frac{1}{2} \log |\mathbf{\Sigma}|  - \frac{1}{2}   \mathbf{(x}_{i} - \mu)^{\intercal} \mathbf{\Sigma}^{-1} (\mathbf{x}_{i} - \mu)  \right) 
  \\
  &amp; = - \frac{N}{2} \log |\mathbf{\Sigma}| - \sum_{i=1}^N  \frac{1}{2}   \mathbf{(x}_{i} - \mu)^{\intercal} \mathbf{\Sigma}^{-1} (\mathbf{x}_{i} - \mu) - \frac{Nd}{2} \log (2 \pi) \\
  &amp; = - \frac{N}{2} \log |\mathbf{\Sigma}| - \sum_{i=1}^N  \frac{1}{2}   \mathbf{(x}_{i} - \mu)^{\intercal} \mathbf{\Sigma}^{-1} (\mathbf{x}_{i} - \mu) + C
\end{aligned}\end{split}\]</div>
<p>Lấy đạo hàm bậc nhất của <span class="math notranslate nohighlight">\(\mu\)</span> và <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span> theo <em>hàm hợp lý</em>.</p>
<p><strong>Đạo hàm theo</strong> <span class="math notranslate nohighlight">\(\mu\)</span>:</p>
<p>Để tính toán đạo hàm bậc nhất chúng ta cần áp dụng công thức:
$<span class="math notranslate nohighlight">\(\frac{\partial \mathbf{w}^{\intercal}\mathbf{A}\mathbf{w}}{\partial \mathbf{w}} = 2\mathbf{A}\mathbf{w}\)</span>$</p>
<p>Coi <span class="math notranslate nohighlight">\(\mathbf{\Sigma}^{-1} = \mathbf{A}\)</span> và <span class="math notranslate nohighlight">\(\mu - \mathbf{x}_i = \mathbf{w}\)</span>, khi đó:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
	\frac{\partial l(\mathbf{ \mu}, \mathbf{ \Sigma} | \mathcal{D} )}{\partial \mu}  &amp; = &amp; \sum_{i=1}^N  \mathbf{ \Sigma^{-1}} ( \mathbf{\mu} - \mathbf{x}_{i} ) \\
  &amp; = &amp; \mathbf{ \Sigma^{-1}}(N\mu - \sum_{i=1}^N \mathbf{x}_i)
\\
  &amp; = &amp; 0
\end{eqnarray}\end{split}\]</div>
<p>Nhân cả hai vế của dòng thứ 2 với <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span> về phía ngoài cùng bên trái ta suy ra nghiệm <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> của phương trình chính là:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
 N\hat{\mu} - \sum_{i=1}^N \mathbf{x}_i &amp; = &amp; 0 \\
 \leftrightarrow \hat{\mu} &amp; = &amp; \frac{\sum_{i=1}^{N} \mathbf{x}_i}{N}
\end{eqnarray}\end{split}\]</div>
<p><strong>Đạo hàm theo</strong> <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>:</p>
<p>Để tính toán đạo hàm theo <span class="math notranslate nohighlight">\(\Sigma\)</span> chúng ta cần áp dụng một số công thức:</p>
<p>1.- Trace của tích ba ma trận không thay đổi nếu hoán vị:</p>
<div class="math notranslate nohighlight">
\[\text{trace}{(\mathbf{ABC})} = \text{trace}{(\mathbf{CAB})} = \text{trace}{(\mathbf{BCA})}\]</div>
<p>2.- Khi <span class="math notranslate nohighlight">\(\mathbf{x}^{\intercal}\mathbf{A}\mathbf{x}\)</span> là một số vô hướng (<em>scalar</em>) thì:</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\intercal}\mathbf{A} \mathbf{x} = \text{trace}(\mathbf{x}^{\intercal}\mathbf{A}\mathbf{x}) = \text{trace}(\mathbf{x}^{\intercal}\mathbf{x}\mathbf{A})\]</div>
<p>3.- Đạo hàm của: $<span class="math notranslate nohighlight">\(\frac{\partial ~ \text{trace}(\mathbf{AB})}{\partial \mathbf{A}} = \frac{\partial ~ \text{trace}(\mathbf{BA})}{\partial \mathbf{A}} = \mathbf{B}^{\intercal}\)</span>$</p>
<p>4.- Đạo hàm của: $<span class="math notranslate nohighlight">\(\frac{\partial \log(\mathbf{A})}{\partial \mathbf{A}} = \mathbf{A}^{-\intercal}\)</span>$</p>
<p>5.- Định thức của một ma trận thì bằng nghịch đảo định thức của ma trận nghịch đảo:
$<span class="math notranslate nohighlight">\(|\mathbf{A}| = \frac{1}{|\mathbf{A}^{-1}|}\)</span>$</p>
<p>Chứng minh những công thức trên không quá khó. Xin dành cho bạn đọc như một bài tập.</p>
<p>Ngoài ra từ công thức thứ 2 và 3 ta suy ra:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial}{\partial \mathbf{A}}  \mathbf{x}^{\intercal}\mathbf{A}\mathbf{x} =\frac{\partial}{\partial \mathbf{A}}  \text{trace} ( \mathbf{x}^{\intercal}\mathbf{x}\mathbf{A} ) = [ \mathbf{x}^{\intercal}\mathbf{x}]^{\intercal} =  \mathbf{x}\mathbf{x}^{\intercal}\]</div>
<p>đồng thời hàm hợp lý cũng được biến đổi thành:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
	l(\mathbf{ \mu, \mathbf{\Sigma}} | \mathcal{D})  &amp; = &amp; C - \frac{N}{2} \log |\mathbf{\Sigma}|  - \frac{1}{2}  \sum_{i=1}^N  (\mathbf{x}_{i} - \mu)^{\intercal} \mathbf{\Sigma}^{-1} (\mathbf{x}_{i} - \mu)   
	\\
	&amp; = &amp; C + \frac{N}{2} \log |\mathbf{\Sigma}^{-1}|  - \frac{1}{2}  \sum_{i=1}^N  \text{trace}\left[ (\mathbf{x}_{i} - \mu)^{\intercal} (\mathbf{x}_{i} - \mu) \mathbf{\Sigma}^{-1}  \right]
\end{eqnarray}
\end{split}\]</div>
<p>Bây giờ chúng ta có thể tính toán đạo hàm theo ma trận <span class="math notranslate nohighlight">\(\mathbf{\Sigma}^{-1}\)</span> như sau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
	\frac{\partial l(\mathbf{ \mu, \Sigma}|\mathcal{D})}{\partial \mathbf{\Sigma}^{-1}}  &amp; = &amp; \frac{N}{2}\mathbf{\Sigma}^{\intercal} - \frac{1}{2}  \sum_{i=1}^N (\mathbf{x}_{i} - \mu) (\mathbf{x}_{i} - \mu)^{\intercal} \\
&amp; = &amp; \frac{N}{2}\mathbf{\Sigma} - \frac{1}{2}  \sum_{i=1}^N (\mathbf{x}_{i} - \mu) (\mathbf{x}_{i} - \mu)^{\intercal}
  \end{eqnarray}
\end{split}\]</div>
<p>Dòng thứ 2 thu được là vì <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span> là ma trận đối xứng. Như vậy nghiệm <span class="math notranslate nohighlight">\(\hat{\mathbf{\Sigma}}\)</span> chính là:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\frac{N}{2}\hat{\mathbf{\Sigma}} - \frac{1}{2}  \sum_{i=1}^N (\mathbf{x}_{i} - \mu) (\mathbf{x}_{i} - \mu)^{\intercal} &amp; = &amp; 0
\\ \leftrightarrow \hat{\mathbf{\Sigma}} = \frac{\sum_{i=1}^N (\mathbf{x}_{i} - \mu) (\mathbf{x}_{i} - \mu)^{\intercal}}{N}
\end{eqnarray}\end{split}\]</div>
<p>Như vậy ước lượng hợp lý tối đa cho các tham số của <em>phân phối Gassian đa chiều chính là</em>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\hat{\mu} &amp; = &amp; \frac{\sum_{i=1}^{N} \mathbf{x}_i}{N} = \mathbb{E}(\mathbf{X}) \\
\hat{\mathbf{\Sigma}} &amp; = &amp; \frac{\sum_{i=1}^N (\mathbf{x}_{i} - \mu) (\mathbf{x}_{i} - \mu)^{\intercal}}{N} = \mathbb{Cov}(\mathbf{X})
\end{eqnarray}\end{split}\]</div>
</div>
<div class="section" id="gaussian-mixture-model">
<h1>16.2. Gaussian Mixture Model<a class="headerlink" href="#gaussian-mixture-model" title="Permalink to this headline">¶</a></h1>
<p><em>Gaussian Mixture Model</em> (viết tắt <em>GMM</em>) là một mô hình phân cụm thuộc lớp bài toán học không giám sát mà phân phối xác suất của mỗi một cụm được giả định là <em>phân phối Gassian đa chiều</em>. Sở dĩ mô hình được gọi là <em>Mixture</em> là vì xác suất của mỗi điểm dữ liệu không chỉ phụ thuộc vào một phân phối <em>Gaussian</em> duy nhất mà là kết hợp từ nhiều phân phối <em>Gaussian</em> khác nhau từ mỗi cụm.</p>
<p><img alt="" src="https://imgur.com/6OvUE6Z.png" /></p>
<p><strong>Hình 3</strong>: <em>Phân phối Gaussian đa chiều</em> với số cụm <span class="math notranslate nohighlight">\(k=3\)</span> đối với bộ dữ liệu một chiều (bên trái) và hai chiều (bên phải).</p>
<p>Mục tiêu của mô hình <em>GMM</em> là ước lượng tham số phù hợp nhất cho <span class="math notranslate nohighlight">\(k\)</span> cụm thông qua phương pháp ước lượng hợp lý tối đa mà chúng ta sẽ thảo luận kĩ hơn ở bên dưới. Một số giả định của mô hình <em>GMM</em>:</p>
<ul class="simple">
<li><p>Có <span class="math notranslate nohighlight">\(k\)</span> cụm cần phân chia mà mỗi cụm tuân theo <em>phân phối Gaussian đa chiều</em> với tập tham số đặc trưng <span class="math notranslate nohighlight">\(\{{(\mu_i, \mathbf{\Sigma}_i)}\}_{i=1}^{k}\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(z_{k}\)</span> được giả định là một biến ngẫu nhiên nhận giá trị 1 nếu như quan sát <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> rơi vào cụm thứ <span class="math notranslate nohighlight">\(k\)</span>, các trường hợp còn lại nhận giá trị 0.</p></li>
<li><p><span class="math notranslate nohighlight">\(z_{k}\)</span> được coi như là một <em>biến ẩn</em> (<em>latent variable</em> hoặc <em>hidden variable</em>) mà ta chưa biết giá trị của nó. Xác suất xảy ra của <span class="math notranslate nohighlight">\(p(z_{k}=1 | \mathbf{x})\)</span> giúp chúng ta xác định tham số phân phối của <em>Gaussian Mixture</em>. Điều này sẽ được thảo luận kĩ hơn bên dưới.</p></li>
</ul>
<p>Tập hợp các giá trị của <span class="math notranslate nohighlight">\(z_{k}\)</span> đối với các cụm sẽ tạo thành một phân phối xác suất sẽ tạo thành một phân phối xác suất <span class="math notranslate nohighlight">\((\pi_1, \pi_2, \dots, \pi_k)\)</span> trong đó <span class="math notranslate nohighlight">\(\pi_k = p(z_{k}=1 | \mathbf{x})\)</span>.</p>
<p>Một xác suất hỗn hợp tại một điểm dữ liệu <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> sẽ được tính theo công thức Bayes như sau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}p(\mathbf{x}) &amp; = &amp; \sum_{c=1}^{k}p(z_c)p(\mathbf{x}|z_c)\\
&amp; = &amp; \sum_{c=1}^{k} p(z_c=1) p(\mathbf{x}|\mu_c, \mathbf{\Sigma}_c) \\
&amp; = &amp; \sum_{c=1}^{k} \pi_c p(\mathbf{x}|\mu_c, \mathbf{\Sigma}_c) \\
&amp; = &amp; \sum_{c=1}^{k} \pi_c N(\mathbf{x}|\mu_c, \mathbf{\Sigma}_c) 
\end{eqnarray}\end{split}\]</div>
<p>Thành phần xác suất <span class="math notranslate nohighlight">\(p(\mathbf{x}|\mu_i, \mathbf{\Sigma}_i)\)</span> được tính từ phân phối <em>Guassian đa chiều</em> và chúng đồng thời là mục tiêu mà chúng ta cần tham số hoá.</p>
<div class="section" id="uoc-luong-hop-ly-toi-da">
<h2>16.2.1. Ước lượng hợp lý tối đa<a class="headerlink" href="#uoc-luong-hop-ly-toi-da" title="Permalink to this headline">¶</a></h2>
<p>Bài toán đặt ra đó là giả sử chúng ta có một tập dữ liệu <span class="math notranslate nohighlight">\(\mathcal{X} = \{\mathbf{x}_i\}_{i=1}^{N}\)</span> hãy tìm ra ước lượng hợp lý tối đa của các tham số <span class="math notranslate nohighlight">\(\theta\)</span> sao cho lớp mô hình được giả định là <em>GMM</em> khớp nhất bộ dữ liệu. Như vậy <span class="math notranslate nohighlight">\(\theta^{*}\)</span> chính là nghiệm của bài toán:</p>
<div class="math notranslate nohighlight">
\[\theta^{*} = \arg \max_{\theta} p(\mathbf{X}|\theta) = \arg \max_{\theta} \prod_{i=1}^{N} p(\mathbf{x}_i| \theta)\]</div>
<p>Để giải phương trình trên chúng ta có thể dựa trên hai cách tiếp cận:</p>
<ul class="simple">
<li><p>Giải trực tiếp phương trình đạo hàm của hàm logarith để theo các hệ số để tìm ra nghiệm tối ưu như đã thực hiện đối với <em>phân phối Gaussian đa biến</em> cho 1 cụm. Tuy nhiên phương pháp này tỏ ra bất khả thi bởi đối với bài toán có nhiều cụm thì hàm mất mát trở nên phức tạp hơn nhiều lần. Việc giải phương trình đạo hàm dường như là không thể.</p></li>
<li><p>Sử dụng thuật toán <em>EM (Expectation-Maximization)</em> để cập nhật dần dần nghiệm của <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
</ul>
<p>Thuật toán <em>EM</em> là một trong những phương pháp thường được sử dụng để cập nhật nghiệm theo hàm hợp lý. Đây là một phương pháp đơn giản và hiệu quả, phù hợp với các bài toán phức tạp khi mà lời giải trực tiếp từ đạo hàm không dễ dàng tìm kiếm. Bên dưới chúng ta sẽ tiếp tục tìm hiểu phương pháp này:</p>
<p>Trong thuật toán <em>EM</em> sẽ liên tục thực hiện các vòng lặp mà mỗi vòng lặp sẽ lặp lại một chu kì bao gồm hai bước huấn luyện chính:</p>
<ul class="simple">
<li><p>E-Step: Ước lượng phân phối của <em>biến ẩn</em> <span class="math notranslate nohighlight">\(z\)</span> thể hiện phân phối xác suất của các cụm tương ứng với dữ liệu và bộ tham số phân phối.</p></li>
<li><p>M-Step: Tối đa hoá phân phối xác suất đồng thời (<em>join distribution probability</em>) của dữ liệu và <em>biến ẩn</em>.</p></li>
</ul>
<p>Cụ thể những bước này sẽ được thể hiện qua hình minh hoạ:</p>
<p><img alt="" src="https://imgur.com/NNCFeR1.png" /></p>
<p><strong>Hình 4</strong>: Hình bên trái là bước E-Step. Tại bước này chúng ta tính toán phân phối xác suất tại từng điểm dữ liệu ứng với mỗi cụm theo bộ tham số phân phối trên từng cụm lúc ban đầu. Chẳng hạn tại một điểm trong hình ở phía trên chúng ta tính ra hai xác suất là <span class="math notranslate nohighlight">\(P(A)=0.6\)</span> và <span class="math notranslate nohighlight">\(P(B)=0.4\)</span> và tại một điểm ở phía dưới tính ra xác suất <span class="math notranslate nohighlight">\(P(A)=0.2\)</span> và <span class="math notranslate nohighlight">\(P(B)=0.8\)</span>. Tiếp theo hình bên phải là bước M-Step thể hiện cách cập nhật lại tham số để phù hợp với phân phối của các cụm dữ liệu. Ở đây tham số trung bình của các cụm được cập nhật lại đồng nghĩa với việc dịch chuyển cụm sao cho giá trị hợp lý của phân phối lý thuyết được tối đa hoá và tiến gần tới phân phối thực ở mỗi cụm.</p>
<p>Để cập nhật tham số thì chúng ta xét một hàm <em>auxilary</em> như sau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}Q(\theta, \theta_t) &amp; = &amp; \mathbb{E}_{z}(\log p(\mathbf{X}, \mathbf{Z} | \theta_t)) \\
&amp; = &amp; \sum_z p(z|\mathbf{X}, \theta_t) \log p(\mathbf{X}, \mathbf{Z} | \theta) \\
&amp; = &amp; \sum_z p(z|\mathbf{X}, \theta_t) \log \left[~ p(\mathbf{Z} | \mathbf{X}, \theta) p(\mathbf{X} | \theta) \right] \\
&amp; = &amp; \sum_z p(z|\mathbf{X}, \theta_t) \log p(\mathbf{Z} | \mathbf{X}, \theta) + \underbrace{\left[ \sum_z p(z|\mathbf{X}, \theta) \right]}_{1} \log p(\mathbf{X} | \theta) \\
&amp; = &amp; \sum_z p(z|\mathbf{X}, \theta_t) \log p(\mathbf{Z} | \mathbf{X}, \theta) + \log p(\mathbf{X} | \theta)
\end{eqnarray}\end{split}\]</div>
<p>Như vậy <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span> chính là kì vọng của logarith xác suất chung của <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> và <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span> trên từng cụm dữ liệu. Giá trị kì vọng này bằng tổng theo trọng số của xác suất tiên nghiệm <span class="math notranslate nohighlight">\(p(z|\mathbf{X}, \theta_t)\)</span> trên từng cụm. Xác suất này có thể tính được dựa trên tham số <span class="math notranslate nohighlight">\(\theta_t\)</span> trước đó (<span class="math notranslate nohighlight">\(\theta\)</span> ở đây là đại diện chung cho cả <span class="math notranslate nohighlight">\(\mu\)</span> và <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>). Tham số mà chúng ta cần cập nhật sẽ nằm ở <em>log likehood</em> của xác suất chung <span class="math notranslate nohighlight">\(\log p(\mathbf{X}, \mathbf{Z} | \theta) \)</span>. Để tính xác suất này chúng ta phân tích chúng theo công thức Bayes giữa <span class="math notranslate nohighlight">\(p(\mathbf{Z} | \mathbf{X}, \theta)\)</span> và <span class="math notranslate nohighlight">\(p(\mathbf{X} | \theta)\)</span>. Cuối cùng chúng ta rút gọn thành tổng giữa logarith hàm hợp lý <span class="math notranslate nohighlight">\(\log p(\mathbf{X} | \theta)\)</span> và logarith xác suất hậu nghiệm <span class="math notranslate nohighlight">\(\log p(\mathbf{Z} | \mathbf{X}, \theta)\)</span>.</p>
<p>Tại sao tối đa hoá hàm hợp lý chúng ta lại thông qua <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span>. Đó là bởi khi giá trị <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span> gia tăng thì kéo theo sự gia tăng <em>hàm hợp lý</em>. Như vậy tồn tại một chuỗi vô hạn <span class="math notranslate nohighlight">\(\{\theta_j'\}_{j=0}^{\infty}\)</span> sao cho <span class="math notranslate nohighlight">\(Q(\theta_j', \theta_t)\)</span> là một chuỗi tăng và dẫn tới <span class="math notranslate nohighlight">\(\{\theta_j'\}_{j=0}^{\infty}\)</span> hội tụ về nghiệm cực đại <span class="math notranslate nohighlight">\(\theta^{*}\)</span>. Khi đó giá trị <em>hàm hợp lý</em> <span class="math notranslate nohighlight">\(\log p(\mathbf{X} | \theta')\)</span> cũng là một chuỗi tăng và có nghiệm hội tụ về <span class="math notranslate nohighlight">\(\theta^*\)</span>. Tức là quá trình tìm nghiệm của <em>hàm hợp lý</em> có thể tìm được thông qua hàm <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span>.</p>
<p>Tiếp theo ta sẽ chứng minh rằng sự gia tăng của <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span> kéo theo sự gia tăng của <em>hàm hợp lý</em>. Thật vậy:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}Q(\theta, \theta_t) - Q(\theta_t, \theta_t) &amp; = &amp; \log p(\mathbf{X} | \theta) - \log p(\mathbf{X} | \theta_t) - \sum_z p(z|\mathbf{X}, \theta_t) \log \frac{p(\mathbf{Z} | \mathbf{X}, \theta)}{p(\mathbf{Z} | \mathbf{X}, \theta_t)} \\
&amp; = &amp; \log p(\mathbf{X} | \theta) - \log p(\mathbf{X} | \theta_t) - \underbrace{\text{KL}(p(\mathbf{Z} | \mathbf{X}, \theta), p(\mathbf{Z} | \mathbf{X}, \theta_t))}_{\geq 0} \\
&amp; \leq &amp;  \log p(\mathbf{X} | \theta) - \log p(\mathbf{X} | \theta_t)
\end{eqnarray}\end{split}\]</div>
<p>Dòng thứ 2 được suy ra là bởi <span class="math notranslate nohighlight">\(\sum_z p(z|\mathbf{X}, \theta_t) \log \frac{p(\mathbf{Z} | \mathbf{X}, \theta)}{p(\mathbf{Z} | \mathbf{X}, \theta_t)}\)</span> chính là một độ đo Kullback-Leibler Divergence về khoảng cách giữa hai phân phối. Giá trị này luôn lớn hơn hoặc bằng 0. Bạn có thể xem thêm chứng minh tại <a class="reference external" href="https://phamdinhkhanh.github.io/2020/07/25/GAN_Wasserstein.html#3-kullback-leibler-divergence">Kullback-Leibler Divergence</a>.</p>
<p>Bất đẳng thức trên cho thấy khi <span class="math notranslate nohighlight">\(Q(\theta, \theta_t) \geq Q(\theta_t, \theta_t)\)</span> sẽ kéo theo <span class="math notranslate nohighlight">\(\log p(\mathbf{X} | \theta) \geq \log p(\mathbf{X} | \theta_t)\)</span>. Như vậy thay vì tối đa hoá hàm mục tiêu là <em>hàm hợp lý</em> thì chúng ta có thể tối đa hoá hàm <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span>.</p>
</div>
<div class="section" id="khai-trien-ham-auxilary">
<h2>16.2.2. Khai triển hàm <em>auxilary</em><a class="headerlink" href="#khai-trien-ham-auxilary" title="Permalink to this headline">¶</a></h2>
<p>Xác suất xảy ra tại một điểm dữ liệu có thể được biểu diễn theo <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_probability/appendix_probability.html#phan-phoi-category">phân phối Category</a> như sau:</p>
<div class="math notranslate nohighlight">
\[p(\mathbf{x}_i, \mathbf{z} | \theta) = \prod_{j=1}^{k} [p(\mathbf{x}_i, z_{j}| \theta)]^{z_{j}}  = \prod_{j=1}^{k} [p(\mathbf{x}_i | z_{j}, \theta) p(z_{j} | \theta)]^{z_{j}} = \prod_{j=1}^{k} [p(\mathbf{x}_i | z_{j}, \theta) \pi_j]^{z_{j}}\]</div>
<p>Như vậy giá trị hàm hợp lý của phân phối xác suất đồng thời có thể được viết như sau:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\mathbf{X}, \mathbf{Z} | \theta) = p(\mathbf{X}, \mathbf{Z} | \theta) = \prod_{i=1}^{N}\prod_{j=1}^{k} \left[ p(\mathbf{x}_i, z_{j} | \theta) \right]^{z_{j}} = \prod_{i=1}^{N}\prod_{j=1}^{k} \left[ p(\mathbf{x}_i | z_{j}, \theta)\pi_j \right]^{z_{j}}\]</div>
<p>Lấy logarith hai vế ta thu được:</p>
<div class="math notranslate nohighlight">
\[\log[p(\mathbf{X}, \mathbf{Z})] = \sum_{i=1}^{N} \sum_{j=1}^{k} z_{j} \log p(\mathbf{x}_i | z_{j}, \theta) + z_{j} \log \pi_j\]</div>
<p>Như vậy:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}Q(\theta, \theta_t) &amp; = &amp; \mathbb{E}_{z} \left[ \log p(\mathbf{X}, \mathbf{Z})| \theta_t \right] \\
&amp; = &amp; \mathbb{E}_{z} \left[ \sum_{i=1}^{N} \sum_{j=1}^{k} z_{j} \log p(\mathbf{x}_i | z_{j}, \theta) + z_{j} \log \pi_j | \theta_t \right] \\
&amp; = &amp;  \sum_{i=1}^{N} \sum_{j=1}^{k} \mathbb{E}_{z} [ z_{j}|\theta_t] \log p(\mathbf{x}_i | z_{j}, \theta) + \mathbb{E}_{z} [z_{j} | \theta_t] \log \pi_j \\
&amp; = &amp; \sum_{i=1}^{N} \sum_{j=1}^{k} p(z_{j} | \mathbf{x}_i , \theta_t) \left[ \log p(\mathbf{x}_i | z_{j}, \theta) + \log \pi_j \right] \\
&amp; = &amp; \sum_{i=1}^{N}\sum_{j=1}^{k} p( z_{j} | \mathbf{x}_i , \theta_t)  \left[  \log \frac{\exp \left( - \frac{1}{2} (\mathbf{x}_{i} - \mu_j)^{\intercal} \mathbf{\Sigma}_j^{-1} (\mathbf{x}_{i} - \mu_j) \right)}{(2 \pi)^{d/2} |\mathbf{\Sigma}_j|^{1/2}} + \log \pi_j \right] \\
&amp; = &amp; \sum_{i=1}^{N}\sum_{j=1}^{k} p( z_{j} | \mathbf{x}_i , \theta_t) \left[ - \frac{1}{2} \log |\mathbf{\Sigma}_j| - \frac{1}{2}   \mathbf{(x}_{i} - \mu_j)^{\intercal} \mathbf{\Sigma}_j^{-1} (\mathbf{x}_{i} - \mu_j) + \log \pi_j+  C_j  \right]
\end{eqnarray}\end{split}\]</div>
</div>
<div class="section" id="cac-buoc-trong-gmm">
<h2>16.2.3. Các bước trong GMM<a class="headerlink" href="#cac-buoc-trong-gmm" title="Permalink to this headline">¶</a></h2>
<p><strong>Bước E-Step</strong>:</p>
<p>Mục tiêu của bước E-Step là tính xác suất của mỗi điểm dữ liệu dựa vào <em>phân phối Gaussian đa chiều</em> dựa trên tham số <span class="math notranslate nohighlight">\(\theta_t\)</span> của vòng lặp gần nhất. Xác suất này được tính như sau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\mathbb{E}_{z}(z_{j} | \mathbf{x}_i, \theta_t) &amp; = &amp; 1 \times p(z_{j} = 1 |  \mathbf{x}_i, \theta_t) + 0 \times p(z_{j} = 0 |  \mathbf{x}_i,\theta_t) \\
&amp; = &amp; p(z_{j}|\mathbf{x}_i, \theta_t) \\
&amp; = &amp; \frac{p(z_{j} | \theta_t) p(\mathbf{x}_i | z_{j}, \theta_t)}{p(\mathbf{x}_i | \theta_t)} \\
&amp; = &amp; \frac{\pi_j N(\mu_{jt}, \mathbf{\Sigma}_{jt}|\mathbf{x}_i)}{\sum_{j} \pi_j N(\mu_{jt}, \mathbf{\Sigma}_{jt}|\mathbf{x}_i)}
\end{eqnarray}\end{split}\]</div>
<p>Xác suất <span class="math notranslate nohighlight">\(\pi_j\)</span> chính là <em>xác suất tiên nghiệm</em> (<em>posteriori probability</em>) bằng với tỷ lệ các quan sát thuộc về cụm <span class="math notranslate nohighlight">\(j\)</span> ở vòng lặp thứ <span class="math notranslate nohighlight">\(t\)</span>. Trong khi <span class="math notranslate nohighlight">\(N(\mu_{jt}, \mathbf{\Sigma}_{jt}|\mathbf{x}_i)\)</span> là xác suất của <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> rơi vào cụm thứ <span class="math notranslate nohighlight">\(j\)</span> được tính theo <em>phân phối Gaussian đa chiều</em>. Hai xác suất này có thể tính được và sau cùng ta thu được xác suất rơi vào mỗi cụm tại mỗi một quan sát <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span>.</p>
<p><strong>Bước M-Step</strong>:</p>
<p>Tại bước M-Step chúng ta cần cập nhật lại tham số phân phối theo hàm <em>auxiliary</em> <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span>. Cực trị đạt được khi đạo hàm bậc nhất bằng 0:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial Q(\theta, \theta_t)}{\partial \theta} = 0\]</div>
<p>Ở đây <span class="math notranslate nohighlight">\(\theta\)</span> là các tham số <span class="math notranslate nohighlight">\(\{\pi_j, \mu_j, \mathbf{\Sigma}_j \}_{j=1}^k\)</span>. Lần lượt giải phương trình đạo hàm theo <span class="math notranslate nohighlight">\(\mu_j\)</span> và <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_j\)</span> tương tự như đối với ước lượng MLE đã trình bày ở chương thứ hai:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\frac{\partial Q(\theta, \theta_t)}{\partial \mu_j} &amp; = &amp;  \frac{\partial}{\partial \mu_j} \sum_{i=1}^{N}\sum_{j=1}^{k} p( z_{j} | \mathbf{x}_i , \theta_t) \left[ - \frac{1}{2} \log |\mathbf{\Sigma}_j| - \frac{1}{2}   \mathbf{(x}_{i} - \mu_j)^{\intercal} \mathbf{\Sigma}_j^{-1} (\mathbf{x}_{i} - \mu_j) + \log \pi_j+  C_j  \right] \\
&amp; = &amp; \frac{\partial}{\partial \mu_j} p( z_{j} | \mathbf{x}_i , \theta_t) \left[ \sum_{i=1}^N  \mathbf{\Sigma}_j^{-1} (\mu_j-\mathbf{x}_{i})  \right] \\
&amp; = &amp; \frac{\partial}{\partial \mu_j} \mathbf{\Sigma}_j^{-1} \left[ \sum_{i=1}^N  p( z_{j} | \mathbf{x}_i , \theta_t) (\mu_j-\mathbf{x}_{i})  \right] \\
&amp; = &amp; 0
\end{eqnarray}\end{split}\]</div>
<p>Từ đó suy ra:</p>
<div class="math notranslate nohighlight">
\[\mu_j^{*} = \frac{\sum_{i=1}^{N} p(z_j| \mathbf{x}_i, \theta_t) \mathbf{x}_i}{\sum_{i=1}^N p(z_j | \mathbf{x}_i, \theta_t)}\]</div>
<p>Trong đó <span class="math notranslate nohighlight">\(p(z_j| \mathbf{x}_i, \theta_t)\)</span> chính là xác suất tương ứng để <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> thuộc về cụm <span class="math notranslate nohighlight">\(j\)</span> được tính từ bước E-Step.</p>
<p>Tiếp theo ta cần tính đạo hàm theo <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_j\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\frac{\partial Q(\theta, \theta_t)}{\partial \mathbf{\Sigma}_j^{-1}} &amp; = &amp;  \frac{\partial}{\partial \mu_j} \sum_{i=1}^{N}\sum_{j=1}^{k} p( z_{j} | \mathbf{x}_i , \theta_t) \left[ - \frac{1}{2} \log |\mathbf{\Sigma}_j| - \frac{1}{2}   \mathbf{(x}_{i} - \mu_j)^{\intercal} \mathbf{\Sigma}_j^{-1} (\mathbf{x}_{i} - \mu_j) + \log \pi_j+  C_j  \right] \\
&amp; = &amp; \sum_{i=1}^{N}p( z_{j} | \mathbf{x}_i , \theta_t) \left[ \frac{1}{2}\mathbf{\Sigma}_j - \frac{1}{2}  (\mathbf{x}_{i} - \mu_j) (\mathbf{x}_{i} - \mu_j)^{\intercal} \right] \\
&amp; = &amp; 0
\end{eqnarray}\end{split}\]</div>
<p>Suy ra:</p>
<div class="math notranslate nohighlight">
\[\mathbf{\Sigma}_j^{*} = \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t) [(\mathbf{x}_i-\mu_j)(\mathbf{x}_i-\mu_j)^{\intercal}]}{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t)}\]</div>
<p>Như vậy tham số tối ưu ở mỗi cụm sẽ được cập nhật theo công thức:</p>
<div class="math notranslate nohighlight">
\[\mu_j^* = \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t) \mathbf{x}_i}{\sum_{i=1}^{N} p(z_{j}| \mathbf{x}_i, \theta_t)}\]</div>
<div class="math notranslate nohighlight">
\[\mathbf{\Sigma}_j^* = \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t) [(\mathbf{x}_i-\mu_j)(\mathbf{x}_i-\mu_j)^{\intercal}]}{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t)}\]</div>
<p>Để tính <span class="math notranslate nohighlight">\(\pi_j\)</span> chúng ta dựa vào điều kiện ràng buộc <span class="math notranslate nohighlight">\(\sum_{j=1}^k \pi_j=1\)</span>. Khi đó hàm Lagrange tương ứng với <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span> là:</p>
<div class="math notranslate nohighlight">
\[J(\theta, \theta_t) = Q(\theta, \theta_t) + \lambda(1 - \sum_{j=1}^{k} \pi_j)\]</div>
<p>Do đó:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\frac{\partial J(\theta, \theta_t)}{\partial \pi_j} &amp; = &amp; \frac{\partial Q(\theta, \theta_t)}{\partial \pi_j} - \lambda \\
&amp; = &amp; \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t)}{\pi_j} - \lambda = 0
\end{eqnarray}\end{split}\]</div>
<p>Từ đó suy ra:</p>
<div class="math notranslate nohighlight">
\[\pi_j = \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t)}{\lambda} \tag{1}\]</div>
<p>Mặt khác ta có <span class="math notranslate nohighlight">\(\sum_{j=1}^{k} \pi_j = 1\)</span>. Do đó:</p>
<div class="math notranslate nohighlight">
\[\sum_{j=1}^k \pi_j = \frac{\sum_{i=1}^{N} \sum_{j=1}^k p(z_{j} | \mathbf{x}_i, \theta_t)}{\lambda} = \frac{N}{\lambda} = 1\]</div>
<p>Suy ra <span class="math notranslate nohighlight">\(\lambda = N\)</span> và thế vào công thức <span class="math notranslate nohighlight">\((1)\)</span> ta được:</p>
<div class="math notranslate nohighlight">
\[\pi_j^* = \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t)}{N}\]</div>
<p>Như vậy chúng ta đã tìm ra được tham số tối ưu của thuật toán <em>GMM</em> sau mỗi vòng lặp. Việc giải trực tiếp bài toán tối ưu <em>hàm hợp lý</em> theo ước lượng <em>MLE</em> là bất khả thi trong điều kiện có nhiều cụm dữ liệu. Chính vì thế thuật toán <em>EM</em> được áp dụng để cập nhật dần dần tham số của mô hình. Thuật toán sẽ dần dần hội tụ sau một hữu hạn bước. Về lý thuyết của thuật toán <em>GMM</em> chúng ta sẽ phải trải qua nhiều tính toán đạo hàm tương đối phức tạp. Tuy nhiên để thực hành thuật toán này lại tương đối dễ dàng trong sklearn. Chúng ta cùng sang phần thực hành để nắm rõ chi tiết.</p>
</div>
</div>
<div class="section" id="thuc-hanh-mo-hinh">
<h1>16.4. Thực hành mô hình<a class="headerlink" href="#thuc-hanh-mo-hinh" title="Permalink to this headline">¶</a></h1>
<p>Đầu tiên chúng ta sẽ import các package cần thiết cho quá trình tiền xử lý dữ liệu, huấn luyện và biểu đồ hoá kết quả.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">linalg</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.patheffects</span> <span class="k">as</span> <span class="nn">PathEffects</span>
<span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Ellipse</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="tien-xu-ly-du-lieu">
<h2>16.4.1. Tiền xử lý dữ liệu<a class="headerlink" href="#tien-xu-ly-du-lieu" title="Permalink to this headline">¶</a></h2>
<p>Để tiện so sánh hiệu quả giữa các thuật toán phân cụm trong học không giám sát. Bộ dữ liệu được sử dụng chung là <a class="reference external" href="https://raw.githubusercontent.com/phamdinhkhanh/datasets/cf391fa1a7babe490fdd10c088f0ca1b6d377f59/shopping-data.csv">shopping-data</a>. Bộ dữ liệu này bao gồm các trường thông tin như <code class="docutils literal notranslate"><span class="pre">giới</span> <span class="pre">tính,</span> <span class="pre">độ</span> <span class="pre">tuổi,</span> <span class="pre">thu</span> <span class="pre">nhập</span> <span class="pre">hàng</span> <span class="pre">năm</span> <span class="pre">và</span> <span class="pre">điểm</span> <span class="pre">số</span> <span class="pre">mua</span> <span class="pre">sắm</span></code> nhằm mô tả hành vi mua sắm của những khách hàng. Mục tiêu của chúng ta đó là phân cụm khác hàng thành những nhóm dựa trên hành vi mua sắm đặc trưng của họ.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/phamdinhkhanh/datasets/cf391fa1a7babe490fdd10c088f0ca1b6d377f59/shopping-data.csv&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(200, 4)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genre</th>
      <th>Age</th>
      <th>Annual Income (k$)</th>
      <th>Spending Score (1-100)</th>
    </tr>
    <tr>
      <th>CustomerID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Male</td>
      <td>19</td>
      <td>15</td>
      <td>39</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Male</td>
      <td>21</td>
      <td>15</td>
      <td>81</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Female</td>
      <td>20</td>
      <td>16</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Female</td>
      <td>23</td>
      <td>16</td>
      <td>77</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Female</td>
      <td>31</td>
      <td>17</td>
      <td>40</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Để đơn giản hoá chúng ta chỉ cần sử dụng hai trường thông tin đầu vào là thu nhập và điểm shopping. Để thuật toán không bị ảnh hưởng bởi sự khác biệt về đơn vị thì chúng ta cần chuẩn hoá theo <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code>. Bạn đọc cũng có thể lựa chọn những phương pháp chuẩn hoá dữ liệu khác. Xem thêm <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/FeatureEngineering.html#id2">các phương pháp chuẩn hoá dữ liệu</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Lấy ra thu nhập va điểm shopping</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Chuẩn hoá dữ liệu</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_std</span> <span class="o">=</span> <span class="n">std</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_std</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(200, 2)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="mo-hinh-gaussian-mixture">
<h2>16.4.2. Mô hình <em>Gaussian Mixture</em><a class="headerlink" href="#mo-hinh-gaussian-mixture" title="Permalink to this headline">¶</a></h2>
<p>Để xây dựng mô hình <em>Gaussian Mixture</em> trên sklearn chúng ta sử dụng class <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture.fit">sklearn.mixture.GaussianMixture</a>. Class này có ý nghĩa như sau:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> 
  <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span> 
  <span class="n">tol</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> 
  <span class="n">reg_covar</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> 
  <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
  <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
  <span class="n">init_params</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span>
  <span class="o">...</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Trong đó:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_components</span></code>: Là số lượng cụm mà chúng ta cần phân chia.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">covariance_type</span></code>: Định dạng covariance được sử dụng trong thuật toán <em>GMM</em>. Trong đó bao gồm: <code class="docutils literal notranslate"><span class="pre">{'full',</span> <span class="pre">'tied',</span> <span class="pre">'diag',</span> <span class="pre">'spherical'}</span></code>. Lựa chọn ‘full’ mặc định có nghĩa rằng mỗi một thành phần cụm có một ma trận hiệp phương sai riêng. ‘tied’ được lựa chọn khi chúng ta muốn đồng nhất ma trận hiệp phương sai giữa các cụm. ‘diag’ tương ứng với ma trận hiệp phương sai là ma trận đường chéo và khi lựa chọn ‘spherical’ có nghĩa rằng mỗi một thành phần cụm sẽ có một phương sai riêng.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tol</span></code>: Ngưỡng hội tụ của thuật toán <em>EM</em>. Nếu mức độ cải thiện của hàm mục tiếu thấp hơn ngưỡng này thì mô hình sẽ dừng.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_iter</span></code>: Số lượng vòng lặp tối đa của thuật toán <em>EM</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">init_params</span></code>: Lựa chọn khởi tạo tham số cho mô hình lúc ban đầu. Mặc định mô hình sẽ sử dụng khởi tạo từ thuật toán k-Means clustering. Như vậy sau mỗi vòng lặp thì thuật toán sẽ sửa lỗi của k-Means và tạo ra một kết quả với mức độ hợp lý cao hơn so với k-Means.</p></li>
</ul>
<p>Bên dưới chúng ta cùng tạo ra mô hình <em>GMM</em> với số lượng cụm cần phân chia là 5. Sau huấn luyện thì trung bình và ma trận hiệp phương sai của mỗi cụm có thể thu được thông qua hai thuộc tính là <em>means</em>_ và <em>covariances</em>_.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                     <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span> 
                     <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;means: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">gm</span><span class="o">.</span><span class="n">means_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;covariances: </span><span class="se">\n</span><span class="s1"> &#39;</span><span class="p">,</span> <span class="n">gm</span><span class="o">.</span><span class="n">covariances_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>means: 
 [[0.60502531 0.15433196]
 [0.33368985 0.49394756]
 [0.58393969 0.82673863]
 [0.0829305  0.80743088]
 [0.09861098 0.21597752]]
covariances: 
  [[[ 0.01818446  0.00433814]
  [ 0.00433814  0.00873064]]

 [[ 0.00613567 -0.00231927]
  [-0.00231927  0.0051635 ]]

 [[ 0.01808598 -0.00031096]
  [-0.00031096  0.0091568 ]]

 [[ 0.00337483 -0.0001437 ]
  [-0.0001437   0.01026088]]

 [[ 0.00453005  0.00255303]
  [ 0.00255303  0.01918353]]]
</pre></div>
</div>
</div>
</div>
<p>Chúng ta nhận thấy rằng các tâm của các cụm cách xa nhau nên khả năng thuật toán sẽ mang lại kết quả tốt với số cụm <span class="math notranslate nohighlight">\(k=5\)</span>. Ma trận hiệp phương sai là những ma trận vuông đối xứng.</p>
</div>
<div class="section" id="lua-chon-sieu-tham-so-cho-mo-hinh-gmm">
<h2>16.4.3. Lựa chọn siêu tham số cho mô hình <em>GMM</em><a class="headerlink" href="#lua-chon-sieu-tham-so-cho-mo-hinh-gmm" title="Permalink to this headline">¶</a></h2>
<p>Để lựa chọn siêu tham số cho mô hình <em>GMM</em> chúng ta sẽ dựa trên mức độ phù hợp được đánh giá thông qua chỉ số <a class="reference external" href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">BIC (Bayesian Information Criteria)</a>. Đây là chỉ số đo lường mức độ hợp lý của mô hình đối với một bộ tham số được tính dựa trên giá trị tối đa của <em>hàm hợp lý</em> như sau:</p>
<div class="math notranslate nohighlight">
\[\text{BIC} = k \ln(n) - 2 \ln (\hat{L})\]</div>
<p>Với <span class="math notranslate nohighlight">\(k\)</span> là số lượng tham số được ước lượng từ mô hình, <span class="math notranslate nohighlight">\(n\)</span> là số lượng quan sát của bộ dữ liệu và <span class="math notranslate nohighlight">\(\hat{L}\)</span> là giá trị ước lượng tối đa của <em>hàm hợp lý</em>. Chỉ số <em>BIC</em> là một trong những giá trị quan trọng thường được sử dụng để đánh giá và lựa chọn các mô hình khác nhau. Mô hình có <em>BIC</em> càng nhỏ thì mức độ hợp lý của mô hình đối với bộ dữ liệu càng cao. Chúng ta sẽ huấn luyện mô hình <em>GMM</em> với nhiều tham số <code class="docutils literal notranslate"><span class="pre">n_components</span></code> và tìm ra giá trị có BIC là nhỏ nhất. Đó chính là số lượng thành phần phù hợp nhất của bộ dữ liệu được tính theo mô hình <em>GMM</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lowest_bic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">infty</span>
<span class="n">bic</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">n_components_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="c1"># cv_types = [&#39;spherical&#39;, &#39;tied&#39;, &#39;diag&#39;, &#39;full&#39;]</span>
<span class="n">cv_types</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">,</span> <span class="s1">&#39;tied&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">cv_type</span> <span class="ow">in</span> <span class="n">cv_types</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">n_components</span> <span class="ow">in</span> <span class="n">n_components_range</span><span class="p">:</span>
        <span class="c1"># Fit Gaussian mixture theo phương pháp huấn luyện EM</span>
        <span class="n">gmm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span>
                                      <span class="n">covariance_type</span><span class="o">=</span><span class="n">cv_type</span><span class="p">)</span>
        <span class="n">gmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>
        <span class="n">bic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">bic</span><span class="p">(</span><span class="n">X_std</span><span class="p">))</span>
        <span class="c1"># Gán model có BIC scores thấp nhất là model tốt nhất</span>
        <span class="k">if</span> <span class="n">bic</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">lowest_bic</span><span class="p">:</span>
            <span class="n">lowest_bic</span> <span class="o">=</span> <span class="n">bic</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">best_gmm</span> <span class="o">=</span> <span class="n">gmm</span>

<span class="n">bic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">bic</span><span class="p">)</span>
<span class="n">color_iter</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">cycle</span><span class="p">([</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="s1">&#39;turquoise&#39;</span><span class="p">])</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">best_gmm</span>
<span class="n">bars</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Vẽ biểu đồ BIC scores</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">cv_type</span><span class="p">,</span> <span class="n">color</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">cv_types</span><span class="p">,</span> <span class="n">color_iter</span><span class="p">)):</span>
    <span class="n">xpos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">)</span> <span class="o">+</span> <span class="o">.</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">bars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">xpos</span><span class="p">,</span> <span class="n">bic</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">):</span>
                                  <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">)],</span>
                        <span class="n">width</span><span class="o">=.</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">bic</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.01</span> <span class="o">-</span> <span class="o">.</span><span class="mi">01</span> <span class="o">*</span> <span class="n">bic</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">bic</span><span class="o">.</span><span class="n">max</span><span class="p">()])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;BIC score per model&#39;</span><span class="p">)</span>
<span class="n">xpos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">bic</span><span class="o">.</span><span class="n">argmin</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">))</span> <span class="o">+</span> <span class="o">.</span><span class="mi">65</span> <span class="o">+</span>\
    <span class="o">.</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">bic</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xpos</span><span class="p">,</span> <span class="n">bic</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.97</span> <span class="o">+</span> <span class="o">.</span><span class="mi">03</span> <span class="o">*</span> <span class="n">bic</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">bars</span><span class="p">],</span> <span class="n">cv_types</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7f0ad0458550&gt;
</pre></div>
</div>
<img alt="../_images/GMM_24_1.png" src="../_images/GMM_24_1.png" />
</div>
</div>
<p>Như vậy ta có thể nhận thấy mô hình phù hợp nhất là mô hình có <code class="docutils literal notranslate"><span class="pre">n_components</span> <span class="pre">=</span> <span class="pre">6</span></code> và dạng <code class="docutils literal notranslate"><span class="pre">covariance_type</span></code> được sử dụng là <code class="docutils literal notranslate"><span class="pre">tied</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_gmm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GaussianMixture(covariance_type=&#39;tied&#39;, n_components=6)
</pre></div>
</div>
</div>
</div>
<p>Tiếp theo chúng ta sẽ dự báo cụm và vẽ biểu đồ các điểm trên không gian 2 chiều.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_plot_kmean_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    X: dữ liệu đầu vào</span>
<span class="sd">    labels: nhãn dự báo</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># lựa chọn màu sắc</span>
    <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
    <span class="n">palette</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;hls&quot;</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>

    <span class="c1"># vẽ biểu đồ scatter</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">()</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">palette</span><span class="p">[</span><span class="n">labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)])</span>

    <span class="c1"># thêm nhãn cho mỗi cluster</span>
    <span class="n">txts</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
        <span class="c1"># Vẽ text tên cụm tại trung vị của mỗi cụm</span>
        <span class="n">xtext</span><span class="p">,</span> <span class="n">ytext</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">txt</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xtext</span><span class="p">,</span> <span class="n">ytext</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">24</span><span class="p">)</span>
        <span class="n">txt</span><span class="o">.</span><span class="n">set_path_effects</span><span class="p">([</span>
            <span class="n">PathEffects</span><span class="o">.</span><span class="n">Stroke</span><span class="p">(</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">foreground</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">),</span>
            <span class="n">PathEffects</span><span class="o">.</span><span class="n">Normal</span><span class="p">()])</span>
        <span class="n">txts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;t-sne visualization&#39;</span><span class="p">)</span>

<span class="n">labels</span> <span class="o">=</span> <span class="n">best_gmm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>
<span class="n">_plot_kmean_scatter</span><span class="p">(</span><span class="n">X_std</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GMM_28_0.png" src="../_images/GMM_28_0.png" />
</div>
</div>
<p>Chúng ta nhận thấy rằng thuật toán <em>GMM</em> đưa ra kết quả rất chuẩn xác. Nếu so sánh với các thuật toán khác như <em>k-Means, Hierarchical Clustering, DBSCAN</em> thì kết quả của <em>GMM</em> là chuẩn xác nhất trên bộ dữ liệu shopping-data. Tuy nhiên nhận định này không đúng trong mọi trường hợp đối với mọi bộ dữ liệu nên chúng ta cần phải thử nghiệm nhiều mô hình khác nhau để so sánh.</p>
</div>
</div>
<div class="section" id="tong-ket">
<h1>16.5. Tổng kết<a class="headerlink" href="#tong-ket" title="Permalink to this headline">¶</a></h1>
<p><em>GMM</em> là một mô hình xác suất. Mô hình này thể hiện sự cải tiến so với <em>k-Means</em> đó là các điểm dữ liệu được sinh ra từ một phân phối hỗn hợp của một số hữu hạn các <em>phân phối Gaussian đa chiều</em>. Tham số của những phân phối này được giả định là chưa biết. Để tìm ra tham số huấn luyện cho các mô hình thì chúng ta sẽ tìm cách tối đa hoá hàm <em>auxiliary</em> thông qua thuật toán <em>EM</em>, thuật toán này sẽ cập nhật nghiệm sau mỗi vòng lặp để đi đến điểm cực trị. Chúng ta có thể coi rằng các mô hình hỗn hợp như là một dạng khái quát của thuật toán <em>k-Means clustering</em> nhằm kết hợp với thông tin về hiệp phương sai của dữ liệu cũng như là tâm của các phân phối <em>Gaussian</em> tiềm ẩn. Cùng tổng kết một số kiến thức mà chương này mang lại:</p>
<ul class="simple">
<li><p><em>Phân phối Guassian đa biến</em> là gì ? Chúng được đặc trưng bởi những tham số nào?</p></li>
<li><p>Phương pháp <em>EM</em> trong huấn luyện <em>hàm hợp lý</em>.</p></li>
<li><p>Xây dựng mô hình <em>GMM</em> trên sklearn.</p></li>
<li><p>Cách thức lựa chọn tham số cho mô hình <em>GMM</em> thông qua chỉ số <em>BIC</em>.</p></li>
</ul>
</div>
<div class="section" id="bai-tap">
<h1>16.6. Bài tập<a class="headerlink" href="#bai-tap" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p>Giả sử một biến <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^{2}\)</span> có <em>phân phối Gaussian đa chiều</em> với trung bình là <span class="math notranslate nohighlight">\(\mu = [1, 1]\)</span> và ma trận hiệp phương sai là ma trận đơn vị <span class="math notranslate nohighlight">\(\mathbf{\Sigma} = \mathbf{I}_2\)</span>. Hãy tính xác suất:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[N(\mu, \mathbf{\Sigma}| \mathbf{x}_i = [0, 0]))\]</div>
<ol class="simple">
<li><p>Ước lượng MLE của <em>phân phối Gaussian đa chiều</em> có kết quả như thế nào?</p></li>
<li><p>Trong mô hình <em>GMM</em> thì mỗi một điểm dữ liệu là kết hợp của một hay nhiều phân phối xác suất thành phần?</p></li>
<li><p>Thuật toán <em>EM</em> giúp huấn luyện mô hình <em>GMM</em> bao gồm những bước nào? Mỗi bước thực hiện mục tiêu gì?</p></li>
<li><p>Có những siêu tham số chính nào được sử dụng để tuning mô hình <em>GMM</em>?</p></li>
<li><p>Để tìm ra những siêu tham số cho mô hình <em>GMM</em> chúng ta dựa trên chỉ số nào? Chỉ số đó có ý nghĩa gì?</p></li>
<li><p>Có những dạng covariance nào trong thuật toán <em>GMM</em> những dạng này có ý nghĩa gì?</p></li>
<li><p>Sử dụng bộ dữ liệu <a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly">Weekly Sale Transaction</a> hãy phân chia tập train/test theo tỷ lệ 80:20.</p></li>
<li><p>Tìm kiếm tham số phù hợp cho mô hình <em>GMM</em>.</p></li>
<li><p>Biểu đồ hoá kết quả dự báo trên tập train và tập test.</p></li>
</ol>
</div>
<div class="section" id="tai-lieu-tham-khao">
<h1>16.7. Tài liệu tham khảo<a class="headerlink" href="#tai-lieu-tham-khao" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95">https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95</a></p>
<p>[1] Bishop, Christopher M. Pattern Recognition and Machine Learning (2006) Springer-Verlag Berlin, Heidelberg.</p>
<p>[2] Murphy, Kevin P. Machine Learning: A Probabilistic Perspective (2012) MIT Press, Cambridge, Mass,</p>
<p><a class="reference external" href="https://people.eecs.berkeley.edu/%7Ejordan/courses/260-spring10/other-readings/chapter13.pdf">https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf</a></p>
<p><a class="reference external" href="http://ttic.uchicago.edu/%7Eshubhendu/Slides/Estimation.pdf">http://ttic.uchicago.edu/~shubhendu/Slides/Estimation.pdf</a></p>
<p><a class="reference external" href="https://web.iitd.ac.in/%7Esumeet/GMM_said_crv10_tutorial.pdf">https://web.iitd.ac.in/~sumeet/GMM_said_crv10_tutorial.pdf</a></p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="index_GMM.html" title="previous page">16. Gaussian Mixture Model</a>
    <a class='right-next' id="next-link" href="../ch_donation/fubini_and_riemann.html" title="next page">Tích phân Riemann và định lý Fubini</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Pham Dinh Khanh<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>