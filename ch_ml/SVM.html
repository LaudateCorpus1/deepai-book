
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>7.1. Hàm mất mát của SVM &#8212; Deep AI KhanhBlog</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.37f24b989f4638ff9c27c22dc7559d4f.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/SVM.html" />
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8. Khái niệm về cây quyết định" href="index_DecisionTree.html" />
    <link rel="prev" title="7. Giới thiệu về SVM" href="index_SVM.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://phamdinhkhanh.github.io/deepai-book/ch_ml/SVM.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="7.1. Hàm mất mát của SVM" />
<meta property="og:description" content="7.1. Hàm mất mát của SVM  7.1.1. Góc nhìn từ hồi qui Logistic  Trong hồi qui Logistic chúng ta đã làm quen với hàm mất mát (loss function) dạng:  \mathcal{L}(\m" />
<meta property="og:image"       content="https://phamdinhkhanh.github.io/deepai-book/_static/img.jpg" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/img.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Deep AI KhanhBlog</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Lời nói đầu
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../contents.html">
   Các chương dự kiến
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contents.html#dong-gop-vao-du-an">
   Đóng góp vào dự án
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/main_contents.html">
   Mục tiêu cuốn sách
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../latex.html">
   Latex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../latex.html#tham-khao-latex">
   Tham khảo latex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../grossary.html">
   Bảng thuật ngữ
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Phụ lục
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/appendix_dtypes.html">
   1. Định dạng dữ liệu
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html">
     1.1. Các định dạng số, boolean và ký tự
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#dinh-dang-sequence">
     1.2. Định dạng sequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#tom-tat">
     1.3. Tóm tắt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#bai-tap">
     1.4 Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html#tai-lieu-tham-khao">
     1.5. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_pandas.html">
   2. Pandas
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html">
     2.1. Khởi tạo dataframe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#thao-tac-voi-dataframe">
     2.2. Thao tác với dataframe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#reshape-dataframe-tren-pandas">
     2.3. Reshape dataframe trên pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#thong-ke-theo-nhom-tren-pandas">
     2.4. Thống kê theo nhóm trên pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#join-merge-va-concatenate-bang">
     2.5. Join, Merge và Concatenate bảng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#ket-noi-sql">
     2.6. Kết nối SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#tong-ket">
     2.7. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#bai-tap">
     2.8. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html#tai-lieu">
     2.9. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_numpy.html">
   3. Numpy
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html">
     3.1. Khởi tạo một mảng trên numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#doc-va-save-numpy-tu-file">
     3.2. Đọc và save numpy từ file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#truy-cap-mang-tren-numpy">
     3.2. Truy cập mảng trên numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#thay-doi-shape-cua-mang">
     3.3. Thay đổi shape của mảng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-ham-tren-numpy">
     3.4. Các hàm trên numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-ma-tran-dac-biet">
     3.5. Các ma trận đặc biệt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-phep-toan-tren-ma-tran">
     3.6. Các phép toán trên ma trận
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#id1">
     3.7. Các phép toán trên ma trận
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#cac-phep-toan-tren-vec-to">
     3.8. Các phép toán trên véc tơ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#thanh-phan-cua-mang">
     3.9. Thành phần của mảng
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#bai-tap">
     3.10. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html#tai-lieu">
     3.11. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_matplotlib.html">
   4. Matplotlib
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html">
     4.1. Format chung của một biểu đồ trên matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#cac-bieu-do-co-ban-tren-matplotlib">
     4.2. Các biểu đồ cơ bản trên matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#cac-bieu-do-nang-cao-tren-matplotlib">
     4.3. Các biểu đồ nâng cao trên matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#ve-nhieu-bieu-do-con-tren-mot-bieu-do">
     4.4. Vẽ nhiều biểu đồ con trên một biểu đồ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#bieu-do-dong-tu-gif-file">
     4.5. Biểu đồ động từ gif file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#tong-ket">
     4.6. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#bai-tap">
     4.7. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html#tai-lieu-tham-khao">
     4.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_OOP.html">
   5. Lập trình hướng đối tượng (Object Oriented Programming - OOP)
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html">
     5.1. Class và Object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#tinh-ke-thua">
     5.2. Tính kế thừa
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#module-va-package">
     5.3. Module và package
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#tong-ket">
     5.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#bai-tap">
     5.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html#tai-lieu">
     5.6. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch_appendix/index_pipeline.html">
   6. Sklearn Pipeline
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html">
     6.1. Thiết kế pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#danh-gia-cheo-cross-validation">
     6.2. Đánh giá cheó (
     <em>
      cross validation
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#gridsearch">
     6.3. GridSearch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#tong-ket">
     6.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#bai-tap">
     6.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html#tai-lieu-tham-khao">
     6.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Đại số tuyến tính
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html">
   1. Đại số tuyến tính
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html#tom-tat">
   2. Tóm tắt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html#bai-tap">
   3. Bài tập
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Giải tích
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html">
   1. Giải tích tích phân
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html#giai-tich-vi-phan">
   2. Giải tích vi phân
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html#bai-tap">
   3. Bài tập
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html#tai-lieu-tham-khao">
   4. Tài liệu tham khảo
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Xác suất
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html">
   1. Xác suất
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html#phan-phoi-xac-suat">
   2. Phân phối xác suất
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html#bai-tap">
   3. Bài tập
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html#tai-lieu-tham-khao">
   4. Tài liệu tham khảo
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="index_MLIntroduce.html">
   1. Khái quát Machine Learning
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_prediction.html">
   2. Bài toán dự báo
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html">
     2.1. Ứng dụng của hồi qui tuyến tính
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#ham-mat-mat">
     2.2. Hàm mất mát
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#hoi-qui-tuyen-tinh-da-bien">
     2.3. Hồi qui tuyến tính đa biến
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#dien-giai-xac-suat-cua-hoi-qui-tuyen-tinh">
     2.4. Diễn giải xác suất của hồi qui tuyến tính
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#huan-luyen-mo-hinh-hoi-qui-tuyen-tinh-tren-sklearn">
     2.5. Huấn luyện mô hình hồi qui tuyến tính trên sklearn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#do-thi-hoa-ket-qua-mo-hinh">
     2.6. Đồ thị hoá kết quả mô hình
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#danh-gia-mo-hinh-hoi-qui-tuyen-tinh-da-bien">
     2.7. Đánh gía mô hình hổi qui tuyến tính đa biến
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#ridge-regression-va-lasso-regression">
     2.8. Ridge regression và Lasso regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#tom-tat">
     2.9. Tóm tắt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html#bai-tap">
     2.10. Bài tập
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_classification.html">
   3. Bài toán phân loại
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html">
     3.1. Hồi qui Logistic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#tim-nghiem-toi-uu-bang-ha-doc-gradient-descent">
     3.2. Tìm nghiệm tối ưu bằng hạ dốc (
     <em>
      gradient descent
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#hoi-qui-logistic-tren-sklearn">
     3.3. Hồi qui Logistic trên sklearn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#tong-ket">
     3.4. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#bai-tap">
     3.5. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html#tai-lieu-tham-khao">
     3.6. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_OvfAndUdf.html">
   4. Độ chệch (
   <em>
    bias
   </em>
   ) và phương sai (
   <em>
    variance
   </em>
   )
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html">
     4.1. Sự đánh đổi giữa độ chệch và phương sai
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#qua-khop-overfitting-va-vi-khop-underfitting">
     4.2. Quá khớp (
     <em>
      Overfitting
     </em>
     ) và vị khớp (
     <em>
      Underfitting
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#xu-ly-hien-tuong-qua-khop">
     4.3. Xử lý hiện tượng quá khớp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#xu-ly-hien-tuong-vi-khop">
     4.4. Xử lý hiện tượng vị khớp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#tong-ket">
     4.5. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#bai-tap-tham-khao">
     4.6. Bài tập tham khảo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html#tai-lieu-tham-khao">
     4.7. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_ModelMetric.html">
   5. Thước đo mô hình phân loại
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html">
     5.1. Bộ dữ liệu
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-chinh-xac-accuracy">
     5.2. Độ chính xác (accuracy)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-chuan-xac-precision">
     5.3. Độ chuẩn xác (
     <em>
      precision
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-phu-recall">
     5.4. Độ phủ (
     <em>
      Recall
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#trade-off-giua-do-chuan-xac-va-do-phu">
     5.5. Trade off giữa
     <em>
      độ chuẩn xác
     </em>
     và
     <em>
      độ phủ
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#f1-score">
     5.6. f1 Score
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#tai-sao-f1-score-khong-la-trung-binh-cong-do-chuan-xac-va-do-phu">
     5.7. Tại sao f1 score không là trung bình cộng
     <em>
      độ chuẩn xác
     </em>
     và
     <em>
      độ phủ
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#do-chinh-xac-accuracy-va-f1-score">
     5.8. Độ chính xác (
     <em>
      accuracy
     </em>
     ) và
     <em>
      f1 score
     </em>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#auc">
     5.9. AUC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#moi-quan-he-giua-tpr-va-fpr">
     5.10. Mối quan hệ giữa TPR và FPR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#gini-va-cap">
     5.11. Gini và CAP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#tong-ket">
     5.12. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#bai-tap">
     5.13. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html#tai-lieu-tham-khao">
     5.14. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_creditScorecard.html">
   6. Ứng dụng mô hình scorecard
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="creditScorecard.html">
     6.1. Phương pháp chuyên gia và mô hình
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="creditScorecard.html#xay-dung-mo-hinh-credit-scorecard">
     6.2. Xây dựng mô hình credit scorecard
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="index_SVM.html">
   7. Giới thiệu về SVM
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     7.1. Hàm mất mát của SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#duong-bien-va-le-trong-svm">
     7.2. Đường biên và lề trong SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#sorf-margin-classification">
     7.3. Sorf Margin Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#kernel-trong-svm">
     7.4. Kernel trong SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#vi-du-ve-bai-toan-svm">
     7.5. Ví dụ về bài toán SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#tong-ket">
     7.6. Tổng kết
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#bai-tap">
     7.7. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#tai-lieu">
     7.8. Tài liệu
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="index_DecisionTree.html">
   8. Khái niệm về cây quyết định
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html">
     8.1. Mô hình cây quyết định (
     <em>
      decision tree
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#bai-toan-phan-loai-cay-quyet-dinh-tren-bo-du-lieu-boston">
     8.2. Bài toán phân loại cây quyết định trên bộ dữ liệu boston
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#duong-bien-phan-chia-cua-cay-quyet-dinh">
     8.3. Đường biên phân chia của cây quyết định
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#cach-khoi-tao-cay-quyet-dinh">
     8.4. Cách khởi tạo cây quyết định
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#thuat-toan-id3">
     8.5. Thuật toán ID3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#chi-so-gini">
     8.6. Chỉ số Gini
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#cay-quyet-dinh-cho-bai-toan-du-bao">
     8.7. Cây quyết định cho bài toán dự báo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#dieu-kien-dung-de-giam-qua-khop-overfitting">
     8.8. Điều kiện dừng để giảm quá khớp (
     <em>
      overfitting
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#cat-tia-pruning">
     8.9. Cắt tỉa  (
     <em>
      pruning
     </em>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#tuning-sieu-tham-so-cho-mo-hinh-cay-quyet-dinh">
     8.10. Tuning siêu tham số cho mô hình cây quyết định
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#bai-tap">
     8.11. Bài tập
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html#tai-lieu-tham-khao">
     8. 12. Tài liệu tham khảo
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Đóng góp từ các tác giả khác
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/fubini_and_riemann.html">
   Tích phân Riemann và định lý Fubini
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/information_theory.html">
   Lý thuyết thông tin
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/ch_ml/SVM.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ch_ml/SVM.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/phamdinhkhanh/deepai-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/phamdinhkhanh/deepai-book/issues/new?title=Issue%20on%20page%20%2Fch_ml/SVM.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/phamdinhkhanh/deepai-book/edit/main/book/ch_ml/SVM.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/phamdinhkhanh/deepai-book/main?urlpath=tree/book/ch_ml/SVM.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   7.1. Hàm mất mát của SVM
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#goc-nhin-tu-hoi-qui-logistic">
     7.1.1. Góc nhìn từ hồi qui Logistic
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tu-logistic-toi-svm">
     7.1.2. Từ Logistic tới SVM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#duong-bien-va-le-trong-svm">
   7.2. Đường biên và lề trong SVM
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sorf-margin-classification">
   7.3. Sorf Margin Classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#so-sanh-giua-le-cung-hard-margin-va-le-mem-soft-margin">
     7.3.1. So sánh giữa lề cứng (
     <em>
      hard margin
     </em>
     ) và lề mềm (
     <em>
      soft margin
     </em>
     )
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#suy-xet-lai-ham-chi-phi-cho-phan-loai-duong-bien-mem-svm">
     7.3.2. Suy xét lại hàm chi phí cho phân loại đường biên mềm SVM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-trong-svm">
   7.4. Kernel trong SVM
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kernel-rbf">
     7.4.1. Kernel RBF
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dieu-kien-cua-ham-kernel">
     7.4.2. Điều kiện của hàm kernel
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cac-kernel-khac-cho-svm">
     7.4.3. Các kernel khác cho SVM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vi-du-ve-bai-toan-svm">
   7.5. Ví dụ về bài toán SVM
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bai-toan-svm-cho-du-lieu-dang-phi-tuyen">
     7.5.1. Bài toán SVM cho dữ liệu dạng phi tuyến
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#su-dung-kernel-svm">
     7.5.2. Sử dụng kernel SVM
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tunning-sieu-tham-so-cho-mot-kernel">
     7.5.3. Tunning siêu tham số cho một kernel
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tong-ket">
   7.6. Tổng kết
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bai-tap">
   7.7. Bài tập
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tai-lieu">
   7.8. Tài liệu
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="ham-mat-mat-cua-svm">
<h1>7.1. Hàm mất mát của SVM<a class="headerlink" href="#ham-mat-mat-cua-svm" title="Permalink to this headline">¶</a></h1>
<div class="section" id="goc-nhin-tu-hoi-qui-logistic">
<h2>7.1.1. Góc nhìn từ hồi qui Logistic<a class="headerlink" href="#goc-nhin-tu-hoi-qui-logistic" title="Permalink to this headline">¶</a></h2>
<p>Trong <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/classification.html">hồi qui Logistic</a> chúng ta đã làm quen với <em>hàm mất mát</em> (<em>loss function</em>) dạng:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\mathbf{w}) = \sum_{i=1}^{n} -[y_i\log(\hat{y_i}) + (1-y_i)\log(1-\hat{y}_i)]\]</div>
<p>Bản chất của hàm mất mát trong hồi qui Logistic là một <em>thước đo</em> về sự tương quan giữa phân phối xác suất dự báo với <em>ground truth</em>.</p>
<p>Trong đó phân phối xác suất được ước tính dựa trên hàm <code class="docutils literal notranslate"><span class="pre">Sigmoid</span></code> theo công thức <span class="math notranslate nohighlight">\(\hat{y} = \sigma(z) = \frac{1}{1+e^{-z}}\)</span>.</p>
<p>Ta cũng biết rằng đường biên phân loại của hồi qui Logistic là một siêu phẳng có phương trình <span class="math notranslate nohighlight">\(\mathbf{w}^{\intercal}\mathbf{x}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
y = \left\{
\begin{matrix}
1 \text{ if } \mathbf{w}^{\intercal}\mathbf{x} &gt; 0 \\
0 \text{ if } \mathbf{w}^{\intercal}\mathbf{x} \leq 0
\end{matrix}
\right.\end{split}
\end{split}\]</div>
<p>Tiếp theo chúng ta sẽ cùng phân tích <em>hàm mất mát</em> của mô hình trong hai trường hợp <span class="math notranslate nohighlight">\(y=0\)</span> và <span class="math notranslate nohighlight">\(y=1\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
  <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="n">y0</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span> <span class="c1"># Trường hợp ground truth = 0</span>
<span class="n">y1</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span> <span class="c1"># Trường hợp ground truth = 1</span>

<span class="c1"># Hàm mất mát nếu ground truth = 0</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;L(y, yhat)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;y=0&#39;</span><span class="p">)</span>

<span class="c1"># Hàm mất mát nếu ground truth = 1</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;L(y, yhat)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;y=1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/SVM_2_0.png" src="../_images/SVM_2_0.png" />
</div>
</div>
<p>Ta nhận thấy hình dạng của <em>hàm mất mát</em> trong hai trường hợp tương ứng với <span class="math notranslate nohighlight">\(y=1\)</span> và <span class="math notranslate nohighlight">\(y=0\)</span> là trái ngược nhau:</p>
<ul class="simple">
<li><p>Đối với trường hợp nhãn <span class="math notranslate nohighlight">\(y = 0\)</span>: Khi giá trị của <span class="math notranslate nohighlight">\(z\)</span> càng lớn thì hàm mất mát sẽ tiệm cận 0. Điều đó đồng nghĩa với mô hình sẽ phạt ít những trường hợp <span class="math notranslate nohighlight">\(z\)</span> lớn và có nhãn 0. Những trường hợp này tương ứng với những điểm nằm cách xa đường biên phân chia.</p></li>
<li><p>Đối với nhãn <span class="math notranslate nohighlight">\(y=1\)</span> thì trái lại, mô hình có xu hướng phạt ít với những giá trị <span class="math notranslate nohighlight">\(z\)</span> nhỏ. Khi đó những điểm này sẽ nằm cách xa đường biên về phía nửa mặt phẳng <span class="math notranslate nohighlight">\(y=1\)</span>.</p></li>
</ul>
<p>Những phân tích ở trên là hợp lý vì ở các mức giá trị <span class="math notranslate nohighlight">\(z\)</span> đủ lớn hoặc đủ nhỏ thì đều là các điểm nằm cách xa đường biên phân chia nên chúng ta có thể dễ dàng dự báo đúng nhãn cho chúng. Việc phạt những điểm này nếu phân loại sai không mang nhiều ý nghĩa bằng phạt những điểm nằm gần đường biên và được xem như là case khó (<em>hard case</em>). Thậm chí nếu phạt những điểm nằm xa đường biên một giá trị lớn dễ khiến xảy ra nguy cơ <em>quá khớp</em> vì hầu hết những điểm đó đều là <em>ngoại lai</em>.</p>
</div>
<div class="section" id="tu-logistic-toi-svm">
<h2>7.1.2. Từ Logistic tới SVM<a class="headerlink" href="#tu-logistic-toi-svm" title="Permalink to this headline">¶</a></h2>
<p>Trong SVM chúng ta có một thay đổi đột phá đó là tìm cách xấp xỉ hàm mất mát dạng cross-entropy của Logistic bằng một hàm mà chỉ phạt những điểm ở gần đường biên thay vì phạt những điểm ở xa đường biên bằng cách đưa mức phạt về 0.</p>
<p>Cụ thể đó là hai hàm phạt <span class="math notranslate nohighlight">\(\text{cost}_1()\)</span> và <span class="math notranslate nohighlight">\(\text{cost}_2()\)</span> tương ứng với <span class="math notranslate nohighlight">\(y=0\)</span> và <span class="math notranslate nohighlight">\(y=1\)</span> như bên dưới:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
\left\{
\begin{matrix}
\text{cost}_1(z) = \max(0, 1-z) ~ \text{if } y=0 \\
\text{cost}_2(z) = \max(1+z, 0) ~ \text{if } y=1
\end{matrix}
\right.\end{split}\end{split}\]</div>
<p>Hai hàm này thể hiện chi phí phải bỏ ra nếu phân loại sai các nhãn lần lượt thuộc <span class="math notranslate nohighlight">\(0\)</span> hoặc <span class="math notranslate nohighlight">\(1\)</span>. Dạng tổng quát của chúng là <span class="math notranslate nohighlight">\(\max(0, t)\)</span> còn được gọi là hàm hingloss. Đây là một trong những hàm mất mát mà bạn sẽ gặp khá nhiều trong machine learning.</p>
<p>Bên dưới là hình dạng của hai hàm <span class="math notranslate nohighlight">\(\text{cost}_1()\)</span> và <span class="math notranslate nohighlight">\(\text{cost}_2()\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
  <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="n">y0</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span> <span class="c1"># Trường hợp ground truth = 0</span>
<span class="n">y1</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span> <span class="c1"># Trường hợp ground truth = 1</span>

<span class="n">cost1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">z</span><span class="p">)</span>
<span class="n">cost2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">z</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Hàm mất mát nếu ground truth = 0</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">cost1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;L(y, yhat)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cross-entropy&#39;</span><span class="p">,</span> <span class="s1">&#39;cost1&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;y=0&#39;</span><span class="p">)</span>

<span class="c1"># Hàm mất mát nếu ground truth = 1</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">cost2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;L(y, yhat)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cross-entropy&#39;</span><span class="p">,</span> <span class="s1">&#39;cost2&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;y=1&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/SVM_5_0.png" src="../_images/SVM_5_0.png" />
</div>
</div>
<p>Ta nhận thấy hình dạng của các hàm mất mát <span class="math notranslate nohighlight">\(\text{cost}_1\)</span> và <span class="math notranslate nohighlight">\(\text{cost}_2\)</span> cũng gần tương tự như cross-entropy. Điểm khác biệt chính đó là giá trị của mất mát bằng 0 nếu <span class="math notranslate nohighlight">\(z \geq 1\)</span> (đối với nhãn <span class="math notranslate nohighlight">\(y=0\)</span>) hoặc <span class="math notranslate nohighlight">\(z \leq -1\)</span> (đối với nhãn <span class="math notranslate nohighlight">\(y=1\)</span>). Theo các hàm mất mát mới này, chúng ta bỏ qua việc phạt phân loại sai những điểm nằm xa đường biên. Đối với những điểm nằm gần đường biên nhất thì mới ảnh hưởng tới hàm mất mát. Tập hợp những điểm nằm gần đường biên sẽ giúp xác định đường biên và được gọi là tập điểm hỗ trợ (<em>support vector</em>).</p>
<p>Như vậy sau khi thay đổi hàm phạt ta thu được hàm mất mát mới dạng:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\mathbf{w}) = \sum_{i=1}^{n} -[y_i\text{cost}_1(\hat{y_i}) + (1-y_i)\text{cost}_2(1-\hat{y}_i)]\]</div>
<p>SVM cho phép ta giảm thiểu <em>quá khớp</em> thông qua một thành phần điều chuẩn cũng tương tự như hồi qui Logistic.</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\mathbf{w}) = C(\sum_{i=1}^{n} -[y_i\text{cost}_1(\hat{y_i}) + (1-y_i)\text{cost}_2(1-\hat{y}_i)])+\frac{\lambda}{2} \underbrace{||\mathbf{w}||_2^2}_{\text{regularization term}}\]</div>
<p>Trong công thức trên thì hằng số <span class="math notranslate nohighlight">\(C &gt; 0\)</span> thể hiện ảnh hưởng của sai số phân loại lên hàm mất mát. Trong khi <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span> là hằng số của thành phần điều chuẩn (<em>regularization term</em>) thể hiện tác động của độ lớn trọng số hồi qui <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> lên hàm mất mát.</p>
<p>Khi tăng tỷ lệ <span class="math notranslate nohighlight">\(\frac{\lambda}{C}\)</span> có thể giúp các trọng số của mô hình được kiểm soát về độ lớn, thông qua đó làm cho độ phức tạp của đường biên phân chia giảm và kiểm soát hiện tượng <em>quá khớp</em>.</p>
<p>Đối với phương trình hồi qui Logistic thì chúng ta sẽ xác định nhãn dựa trên dấu của <span class="math notranslate nohighlight">\(\mathbf{w}^{\intercal}\mathbf{x}\)</span>. Còn trong thuật toán SVM, đối với một tập dữ liệu mà các nhãn là phân tuyến (<em>linear seperable</em>) (tức là tồn tại ít nhất 1 đường biên phân loại đúng toàn bộ các điểm) thì chúng ta sẽ mở rộng đường biên phân chia về hai phía là 1 đơn vị. Khi đó một điểm được dự báo là:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
y = \left\{
\begin{matrix}
0 ~ \text{if } \mathbf{w}^{\intercal}\mathbf{x} \leq -1 \\
1 ~ \text{if } \mathbf{w}^{\intercal}\mathbf{x} \geq 1 
\end{matrix}
\right.\end{split}\end{split}\]</div>
<p>Ý nghĩa của việc mở rộng đường biên đó là khiến cho các điểm nằm gần với đường biên sẽ trở nên tách biệt hơn. Tiếp theo chúng ta sẽ tìm hiểu cơ chế nào hoạt động và cách xác định đường biên đối với thuật toán SVM.</p>
</div>
</div>
<div class="section" id="duong-bien-va-le-trong-svm">
<h1>7.2. Đường biên và lề trong SVM<a class="headerlink" href="#duong-bien-va-le-trong-svm" title="Permalink to this headline">¶</a></h1>
<p><strong>Tập dữ liệu của bài toán SVM</strong></p>
<p>Giả sử tập dữ liệu huấn luyện <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> bao gồm <span class="math notranslate nohighlight">\(N\)</span> điểm dữ liệu. Trong đó điểm dữ liệu thứ <span class="math notranslate nohighlight">\(i\)</span> là <span class="math notranslate nohighlight">\(Z_i = (\mathbf{x}_i, y_i)\)</span> với <span class="math notranslate nohighlight">\(\mathbf{x}_i \in \mathbb{R}^{d}\)</span> là véc tơ đầu vào và <span class="math notranslate nohighlight">\(y_i\)</span> là biến mục tiêu là một trong hai giá trị <span class="math notranslate nohighlight">\(\{-1, 1\}\)</span> phân tuyến (<em>linear seperable</em>).</p>
<p>Bên dưới là hình ảnh tập dữ liệu phân tuyến, đường biên và lề trong thuật toán SVM.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>


<span class="c1"># we create 40 separable points</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span> <span class="n">cluster_std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">idx_cls_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">idx_cls_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># fit the model, don&#39;t regularize for illustration purposes</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx_cls_0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_cls_0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx_cls_1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_cls_1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># plot the decision function</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">xlim</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">()</span>
<span class="n">ylim</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">()</span>

<span class="c1"># create grid to evaluate model</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ylim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ylim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">YY</span><span class="p">,</span> <span class="n">XX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">yy</span><span class="p">,</span> <span class="n">xx</span><span class="p">)</span>
<span class="n">xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">XX</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">YY</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">B</span><span class="o">-</span><span class="mf">0.9</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">B</span><span class="o">+</span><span class="mf">0.8</span>
<span class="c1"># plot decision boundary and margins</span>
<span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span>  <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
           <span class="n">linestyles</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">])</span>

<span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
           <span class="n">linestyles</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;-&#39;</span><span class="p">])</span>

<span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
           <span class="n">linestyles</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;-&#39;</span><span class="p">])</span>

<span class="c1"># plot support vectors</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">support_vectors_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">clf</span><span class="o">.</span><span class="n">support_vectors_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
           <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/SVM_10_0.png" src="../_images/SVM_10_0.png" />
</div>
</div>
<p><strong>Hình 1:</strong> Hình ảnh về tập dữ liệu trong bài toán phân loại nhị phân mà các lớp là <em>phân tuyến</em>. Ba đường thẳng <code class="docutils literal notranslate"><span class="pre">A,</span> <span class="pre">B,</span> <span class="pre">C</span></code> đại diện cho ba đường biên phân chia đúng <strong>mọi điểm dữ liệu</strong>. Những điểm hình tròn nằm bên trái thuộc mặt dương có nhãn <span class="math notranslate nohighlight">\(y=1\)</span>, những điểm dấu nhân nhằm bên phải thuộc mặt âm nhãn <span class="math notranslate nohighlight">\(y=-1\)</span>.</p>
<p>Trên đồ thị chúng ta qui ước nhãn <span class="math notranslate nohighlight">\(1\)</span> cho các điểm nằm bên trái mặt phân chia (mặt dương) và nhãn <span class="math notranslate nohighlight">\(-1\)</span> cho các điểm nằm ở bên phải mặt phân chia (mặt âm). Sở dĩ chúng ta gán nhãn như vậy là vì tại cùng một dữ liệu đầu vào <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> thì mặt dương bên trái sẽ có giá trị lớn hơn mặt âm bên phải.</p>
<p><strong>Lựa chọn đường biên phân chia tương ứng với một phương</strong></p>
<p>Ba đường thẳng <code class="docutils literal notranslate"><span class="pre">A,</span> <span class="pre">B,</span> <span class="pre">C</span></code> ở ví dụ trên là ba đường biên phân chia song song và có cùng phương. Trong ba đường biên phân chia thì đường biên <code class="docutils literal notranslate"><span class="pre">B</span></code> là công bằng nhất vì chúng cách đều các điểm gần nhất thuộc hai lớp. Còn lựa chọn <code class="docutils literal notranslate"><span class="pre">A</span></code> và <code class="docutils literal notranslate"><span class="pre">C</span></code> sẽ không công bằng vì chúng ta sẽ dễ thiên vị một lớp hơn lớp còn lại.</p>
<p>Như vậy để cho công bằng thì đường biên phải luôn nằm chính giữa và cách đều các điểm gần nhất với nó. Đồng thời đối với bài toán Hard-Margin SVM thì tập dữ liệu là phân tuyến nên đường biên cần phải phân loại đúng mọi điểm dữ liệu. Chúng ta coi độ rộng của đường biên là lề (<em>margin</em>). Ngoài ra tập hợp những điểm nằm sát đường biên nhất thì được gọi là tập hỗ trợ. Những điểm này sẽ hỗ trợ tìm ra đường biên vì những đường thẳng nét đứt đi qua chúng song song với đường biên.</p>
<p>Trong không gian hai chiều thì đường biên là một đường thẳng. Trong không gian 3 chiều chúng sẽ là một mặt phẳng (<em>plane</em>). Trong không gian nhiều hơn 3 chiều chúng ta gọi đường biên phân chia là siêu phẳng (<em>hyperplane</em>).</p>
<p>Một câu hỏi đặt ra đó là có vô số những đường biên phân loại, vậy thì đường biên nào là phù hợp nhất?</p>
<p>Mục tiêu của SVM đó là tìm ra một siêu phẳng (<em>hyperplane</em>) trong không gian <span class="math notranslate nohighlight">\(d\)</span> chiều làm đường biên phân chia sao cho độ rộng <strong>lề</strong> của chúng là lớn nhất vì khi phân chia theo đường biên này thì các nhóm là tách biệt nhất.</p>
<p><img alt="" src="https://i.imgur.com/oKeJOcW.jpeg" /></p>
<p>Giả sử phương trình của đường biên phân chia hai điểm dữ liệu là:</p>
<div class="math notranslate nohighlight">
\[b + w_1 x_1 + w_2 x_2 + \dots + w_N x_N = b + \mathbf{w}^{\intercal}\mathbf{x} = 0\]</div>
<p><span class="math notranslate nohighlight">\(b\)</span> là hệ số tự do, <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> là các véc tơ hệ số. <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> là véc tơ quan sát đầu vào.</p>
<p>Trong chương trình THPT chúng ta đã được học về công thức khoảng cách từ một điểm <span class="math notranslate nohighlight">\(A = (x_1, x_2)\)</span> tới một đường thẳng <span class="math notranslate nohighlight">\(l\)</span> có phương trình <span class="math notranslate nohighlight">\(w_0 + w_1 x_1 + w_2 x_2 = 0\)</span> là:</p>
<div class="math notranslate nohighlight">
\[d(A, l) = \frac{|b + w_1 x_1 + w_2 x_2|}{\sqrt{w_1^2 + w_2^2}} = \frac{|b + w_1 x_1 + w_2 x_2|}{||\mathbf{w}||_2}\]</div>
<p>Trong trường hợp tổng quát, khoảng cách từ một điểm bất kỳ <span class="math notranslate nohighlight">\(Z_i = (\mathbf{x}_i, y_i)\)</span> tới biên là siêu phẳng <span class="math notranslate nohighlight">\(H\)</span> có phương trình <span class="math notranslate nohighlight">\(b+\mathbf{w}^{\intercal}\mathbf{x} = 0\)</span> sẽ là:</p>
<div class="math notranslate nohighlight">
\[d(Z_i, H) = \frac{|b+\mathbf{w}^{\intercal}\mathbf{x}_i|}{||\mathbf{w}||_2} = \frac{y_i(b+\mathbf{w}^{\intercal}\mathbf{x}_i)}{||\mathbf{w}||_2}\]</div>
<p>Trong công thức trên thì <span class="math notranslate nohighlight">\(|b+\mathbf{w}^{\intercal}\mathbf{x}| = y_i(b+\mathbf{w}^{\intercal}\mathbf{x}_i)\)</span> là vì:</p>
<ul class="simple">
<li><p>Xét trường hợp nhãn <span class="math notranslate nohighlight">\(y_i=-1\)</span> thì điểm <span class="math notranslate nohighlight">\(Z_i\)</span> nằm ở mặt âm và có <span class="math notranslate nohighlight">\(b+\mathbf{w}^{\intercal}\mathbf{x}_i \leq 0\)</span>. Do đó <span class="math notranslate nohighlight">\(y_i(b+\mathbf{w}^{\intercal}\mathbf{x}_i) \geq 0\)</span>.</p></li>
<li><p>Xét trường hợp nhãn <span class="math notranslate nohighlight">\(y_i = 1\)</span> thì <span class="math notranslate nohighlight">\(Z_i\)</span> nằm ở mặt dương và có <span class="math notranslate nohighlight">\(b+\mathbf{w}^{\intercal}\mathbf{x}_i \geq 0\)</span>. Từ đó suy ra  <span class="math notranslate nohighlight">\(y_i(b+\mathbf{w}^{\intercal}\mathbf{x}_i) \geq 0\)</span>.</p></li>
</ul>
<p>Trong cả hai trường hợp thì đẳng thức <span class="math notranslate nohighlight">\(|b+\mathbf{w}^{\intercal}\mathbf{x}| = y_i(b+\mathbf{w}^{\intercal}\mathbf{x}_i)\)</span> luôn xảy ra.</p>
<p><strong>Tìm đường biên có lề lớn nhất</strong></p>
<p>Tập hợp các điểm nằm gần nhất với một đường biên sẽ giúp xác định phương trình đường biên nên chúng còn được gọi là tập hợp các điểm hỗ trợ (<em>support points</em>), ký hiệu là <span class="math notranslate nohighlight">\(S\)</span>. Trong hình vẽ thì các điểm được khoanh tròn chính là các điểm thuộc tập hỗ trợ. Để tìm ra đường biên có độ rộng lề là lớn nhất thì chúng ta cần tối đa hoá khoảng cách từ các điểm thuộc tập hỗ trợ tới đường biên. Điều này tương đương với giải bài toán tối ưu:</p>
<div class="math notranslate nohighlight">
\[\begin{eqnarray}
\hat{\mathbf{w}}, \hat{b} &amp; = &amp; \arg \max \{\min_{(\mathbf{x}_i, y_i) \in \mathcal{Z}} \frac{b+y_i(\mathbf{w}^{\intercal}\mathbf{x}_i)}{||\mathbf{w}||_2} \} \
\end{eqnarray} \tag{1}\]</div>
<p>Khi nhân vào phương trình đường biên với một hệ số <span class="math notranslate nohighlight">\(k\)</span> thì đường biên không thay đổi. Do đó khoảng cách từ mọi điểm tới đường biên không thay đổi. Tức là khoảng cách từ các điểm thuộc tập hỗ trợ tới đường biên không thay đổi và dẫn tới độ rộng của lề là không thay đổi. Nhờ tính chất này chúng ta có thể nhân thêm vào các trọng số <span class="math notranslate nohighlight">\(w_i\)</span> của phương trình đường biên một hệ số <span class="math notranslate nohighlight">\(k\)</span> sao cho với các điểm dữ liệu thuộc tập hỗ trợ <span class="math notranslate nohighlight">\(S\)</span> thì <span class="math notranslate nohighlight">\(b+y_i(\mathbf{w}^{\intercal}\mathbf{x}_i) = 1\)</span>. Điều đó cũng đồng nghĩa với luôn tìm được một cách nhân với <span class="math notranslate nohighlight">\(k\)</span> sao cho đường biên:</p>
<div class="math notranslate nohighlight">
\[\min_{(\mathbf{x}_i, y_i) \in \mathcal{Z}} b+y_i(\mathbf{w}^{\intercal}\mathbf{x}_i) = 1\]</div>
<p>Bài toán <span class="math notranslate nohighlight">\((1)\)</span> trở thành bài toán tối ưu với ràng buộc tuyến tính:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\hat{\mathbf{w}}, \hat{b} &amp; = &amp; \arg \max \frac{1}{||\mathbf{w}||_2} \\
\text{subject} &amp; : &amp; y_i(b+\mathbf{w}^{\intercal}\mathbf{x}_i) \geq 1, \forall i=\overline{1, N} \tag{2}
\end{eqnarray}\end{split}\]</div>
<p>Điều kiện ràng buộc <span class="math notranslate nohighlight">\(y_i(b+\mathbf{w}^{\intercal}\mathbf{x}_i) \geq 1, \forall i=\overline{1, N}\)</span> là vì khoảng cách từ mọi điểm luôn lớn hơn khoảng cách từ điểm hỗ trợ tới đường biên phân chia và khoảng cách này bằng 1 vì theo giả định ta đã nhân với hệ số <span class="math notranslate nohighlight">\(k\)</span> vào phương trình đường biên.</p>
<p>Để đơn giản hoá thì bài toán tối ưu <span class="math notranslate nohighlight">\((2)\)</span> có thể nghịch đảo hàm mục tiêu để chuyển sang dạng tương đương:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\hat{\mathbf{w}}, \hat{b} &amp; = &amp; \arg \min ||\mathbf{w}||_2 \\
\text{subject} &amp; : &amp; y_i(b+\mathbf{w}^{\intercal}\mathbf{x}_i) \geq 1, \forall i=\overline{1, N} \tag{3}
\end{eqnarray}\end{split}\]</div>
<p>Bài toán tối ưu <span class="math notranslate nohighlight">\((3)\)</span> là một bài toán dạng <a class="reference external" href="https://en.wikipedia.org/wiki/Quadratic_form">Quadratic Form</a> nên chúng ta có thể dễ dàng tìm được lời giải của chúng thông qua hệ <a class="reference external" href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">điều kiện KKT</a>. Để giải bài toán tối ưu này có thể sử dụng package <a class="reference external" href="https://pypi.org/project/cvxopt/">cvxopt</a> trong python. Đây là một package chuyên biệt giúp giải quyết các bài toán tối ưu lồi. Trong khuôn khổ của cuốn sách này, với mục tiêu đơn giản hoá mọi thứ, chúng ta sẽ không đi sâu vào cách giải hệ điều kiện KKT.</p>
</div>
<div class="section" id="sorf-margin-classification">
<h1>7.3. Sorf Margin Classification<a class="headerlink" href="#sorf-margin-classification" title="Permalink to this headline">¶</a></h1>
<div class="section" id="so-sanh-giua-le-cung-hard-margin-va-le-mem-soft-margin">
<h2>7.3.1. So sánh giữa lề cứng (<em>hard margin</em>) và lề mềm (<em>soft margin</em>)<a class="headerlink" href="#so-sanh-giua-le-cung-hard-margin-va-le-mem-soft-margin" title="Permalink to this headline">¶</a></h2>
<p>Đường biên phân chia của thuật toán SVM sẽ chịu ảnh hưởng bởi những điểm thuộc tập hỗ trợ <span class="math notranslate nohighlight">\(S\)</span>. Trong trường hợp đường biên phân chia <strong>đúng mọi điểm điểm dữ liệu</strong> thì được gọi là bài toán phân loại theo đường biên cứng (<em>hard margin classification</em>). Tuy nhiên đường biên cứng tỏ ra hạn chế nếu tồn tại dữ liệu .ngoại lai (<em>outlier</em>). Chúng ta cùng phân tích hạn chế này ở hình minh hoạ bên dưới.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>

<span class="c1"># we create 40 separable points</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span> <span class="n">cluster_std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">idx_cls_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">idx_cls_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">id_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># fit the model</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="c1"># Adjust outlier</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">X</span><span class="p">[</span><span class="n">id_max</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> 

    <span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># get the separating hyperplane</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">yy</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">xx</span> <span class="o">-</span> <span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># plot the parallels to the separating hyperplane that pass through the</span>
    <span class="c1"># support vectors (margin away from hyperplane in direction</span>
    <span class="c1"># perpendicular to hyperplane). This is sqrt(1+a^2) away vertically in</span>
    <span class="c1"># 2-d.</span>
    <span class="n">margin</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">yy_down</span> <span class="o">=</span> <span class="n">yy</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">a</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">margin</span>
    <span class="n">yy_up</span> <span class="o">=</span> <span class="n">yy</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">a</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">margin</span>
    <span class="c1"># plot the line, the points, and the nearest vectors to the plane</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_down</span><span class="p">,</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_up</span><span class="p">,</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">support_vectors_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">clf</span><span class="o">.</span><span class="n">support_vectors_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
                <span class="n">facecolors</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
                <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;RdBu&#39;</span><span class="p">))</span>
    

    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx_cls_0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_cls_0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx_cls_1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_cls_1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

    <span class="n">YY</span><span class="p">,</span> <span class="n">XX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">yy</span><span class="p">,</span> <span class="n">xx</span><span class="p">)</span>
    <span class="n">xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">XX</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">YY</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">x_min</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.5</span>
    <span class="n">x_max</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">y_min</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">y_max</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="c1"># Put the result into a contour plot</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
           <span class="n">linestyles</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">])</span>

    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Hard Margin SVM&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Hard Margin SVM with Outlier&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/SVM_15_0.png" src="../_images/SVM_15_0.png" />
</div>
</div>
<!-- ![](https://imgur.com/8B67kPe.png) -->
<p><strong>Hình 2:</strong> Hình bên trái là <em>phân loại đường biên cứng</em> (<em>Hard margin SVM</em>) đối với tập dữ liệu thông thường. Hình bên phải là <em>phân loại đường biên cứng</em> đối với dữ liệu chứa điểm ngoại lai (là điểm hình sao được khoanh tròn nằm bên trái). Phương pháp <em>phân loại đường biên cứng</em> buộc phải phân loại đúng mọi điểm dữ liệu, bao gồm cả điểm ngoại lai. Điều này khiến cho đường biên phân chia bị thu hẹp lại. Khi đó qui luật phân chia sẽ không còn giữ được yếu tố tổng quát và dẫn tới hiện tượng quá khớp (<em>overfitting</em>). Kết quả dự báo trên tập <em>kiểm tra</em> khi đó sẽ kém hơn so với tập <em>huấn luyện</em>.</p>
<p>Để khắc phục hạn chế của <em>phân loại đường biên cứng</em>, kỹ thuật <em>phân loại đường biên mềm</em> (<em>Sorf Margin Classification</em>) chấp nhận đánh đổi để mở rộng lề và cho phép phân loại sai các điểm ngoại lai. Cụ thể hơn, thuật toán sẽ chấp nhận một số điểm bị rơi vào vùng của lề (vùng nằm giữa hai đường nét đứt, vùng này còn được gọi là vùng không an toàn) nhưng trái lại, chi phí cơ hội của sự đánh đổi đó là độ rộng lề lớn hơn. Đường biên phân chia được tạo ra từ kỹ thuật này thường nắm được tính <em>tổng quát</em> và hạn chế hiện tượng <em>quá khớp</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># fit the modelf</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">penalty</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([(</span><span class="s1">&#39;hard margin&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;soft margin&#39;</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)]):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">penalty</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># get the separating hyperplane</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">yy</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">xx</span> <span class="o">-</span> <span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># plot the parallels to the separating hyperplane that pass through the</span>
    <span class="c1"># support vectors (margin away from hyperplane in direction</span>
    <span class="c1"># perpendicular to hyperplane). This is sqrt(1+a^2) away vertically in</span>
    <span class="c1"># 2-d.</span>
    <span class="n">margin</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">yy_down</span> <span class="o">=</span> <span class="n">yy</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">a</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">margin</span>
    <span class="n">yy_up</span> <span class="o">=</span> <span class="n">yy</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">a</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">margin</span>

    <span class="c1"># plot the line, the points, and the nearest vectors to the plane</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_down</span><span class="p">,</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_up</span><span class="p">,</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">support_vectors_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">clf</span><span class="o">.</span><span class="n">support_vectors_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
                <span class="n">facecolors</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
                <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;RdBu&#39;</span><span class="p">))</span>
    

    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx_cls_0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_cls_0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx_cls_1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_cls_1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

    <span class="n">YY</span><span class="p">,</span> <span class="n">XX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">yy</span><span class="p">,</span> <span class="n">xx</span><span class="p">)</span>
    <span class="n">xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">XX</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">YY</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">x_min</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.5</span>
    <span class="n">x_max</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">y_min</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">y_max</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="c1"># Put the result into a contour plot</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
           <span class="n">linestyles</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">])</span>

    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Hard Margin SVM, C=&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">penalty</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Soft Margin SVM, C=&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">penalty</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/SVM_17_0.png" src="../_images/SVM_17_0.png" />
</div>
</div>
<p><strong>Hình 3:</strong> Phân loại biên cứng (bên trái) và phân loại biên mềm (bên phải) trong SVM. Chúng ta nhận thấy đối với đường biên mềm thì SVM chấp nhận một số điểm rơi vào vùng an toàn để nhằm tạo ra một đường biên phân chia tổng quát hơn. Trong khi phân loại theo đường biên cứng thì không chấp nhận những điểm dữ liệu bị lấn sang phía bên kia của vùng an toàn (là đường nét đứt).</p>
</div>
<div class="section" id="suy-xet-lai-ham-chi-phi-cho-phan-loai-duong-bien-mem-svm">
<h2>7.3.2. Suy xét lại hàm chi phí cho phân loại đường biên mềm SVM<a class="headerlink" href="#suy-xet-lai-ham-chi-phi-cho-phan-loai-duong-bien-mem-svm" title="Permalink to this headline">¶</a></h2>
<p>Ý tưởng của <em>phân loại đường biên mềm</em> là mở rộng lề. Nhưng chúng ta không thể mở rộng lề ra vô cùng vì như vậy mọi điểm đều nằm trong đường biên phân chia và đường biên phân chia là vô nghĩa. Quá trình mở rộng lề sẽ bị kìm hãn ở một mức độ nhất định sao cho nếu các điểm bị lấn vào đường biên thì không được lấn quá nhiều. Tức là đối với những điểm bị rơi vào <em>vùng không an toàn</em> thì tổng khoảng cách của chúng tới mép của lề (là các đường nét đứt) là nhỏ nhất. Khoảng cách từ một điểm tới mép đường biên (nét đứt) khi nó bị lấn lề là:</p>
<div class="math notranslate nohighlight">
\[d(Z_i, H) \triangleq \xi_i = |b+\mathbf{w}^{\intercal}\mathbf{x}_i-y_i|\]</div>
<p><strong>Bài tập:</strong> Chứng minh công thức khoảng cách trên khá đơn giản, xin dành cho bạn đọc.</p>
<p><span class="math notranslate nohighlight">\(xi_i\)</span> chính là giá trị tối đa mà chúng ta cho phép để một điểm bị lần sang phần bên kia của lề. Trong hàm mất mát chúng ta cần tối thiểu hoá thêm tổng khoảng cách của những phần bị lấn này bằng cách cộng thêm chúng vào hàm mất mát:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\hat{\mathbf{w}}, \hat{b} &amp; = &amp; \arg \min ~[~||\mathbf{w}||_2 + C \sum_{Z_j \in \mathcal{M}} |b+\mathbf{w}^{\intercal}\mathbf{x}_i-y_i|~] \\
&amp; = &amp; \arg \min ~[~||\mathbf{w}||_2 + C \sum_{Z_j \in \mathcal{M}} \xi_i~]\\
\text{subject} &amp; : &amp; y_i(b+\mathbf{w}^{\intercal}\mathbf{x}_i) \geq 1 - \xi_i, \xi_i \geq 0 ~ \forall i=\overline{1, N} \tag{4}
\end{eqnarray}\end{split}\]</div>
<p>Với <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> là tập hợp các điểm bị lấn lề.</p>
<ul class="simple">
<li><p>Khi toàn bộ các giá trị <span class="math notranslate nohighlight">\(\xi_i = 0\)</span> đồng nghĩa với việc chúng ta không chấp nhận việc lấn lề là xảy ra và đường biên mềm trở thành đường biên cứng.</p></li>
<li><p>Nếu một điểm có <span class="math notranslate nohighlight">\(0 \geq \xi_i \geq 1\)</span> thì chúng ta cho phép một điểm rơi vào vùng không an toàn nhưng không được rời xa quá đường biên. Tức là điểm đó vẫn được phân loại đúng nhưng bị lấn vào vùng lề.</p></li>
<li><p>Nếu một điểm có <span class="math notranslate nohighlight">\(\xi_i &gt; 1\)</span> thì điểm đó sẽ bị lấn vượt quá đường biên và bị phân loại sai.</p></li>
</ul>
<p>Hệ số <span class="math notranslate nohighlight">\(C\)</span> là một hệ số rất quan trọng thể hiện tỷ lệ đánh đối giữa độ rộng lề và sự vi phạm bằng cách xâm lấn vào lề. Một hệ số <span class="math notranslate nohighlight">\(C\)</span> lớn sẽ cho thấy đóng góp vào hàm mất mát của một điểm vi phạm sẽ lớn hơn việc mở rộng lề. Do đó để hàm mất mát nhỏ thì chúng ta cần hạn chế các điểm vi phạm và chấp nhận một độ rộng lề nhỏ hơn.</p>
<p>Trái lại trường hợp <span class="math notranslate nohighlight">\(C\)</span> nhỏ thường trả lại một độ rộng của lề lớn hơn và đồng thời mức độ xâm lấn là nhỏ hơn.</p>
<p>Khi tiến hành tinh chỉnh mô hình, chúng ta quan tâm nhiều tới hệ số <span class="math notranslate nohighlight">\(C\)</span> vì nó ảnh hưởng trực tiếp tới hình dạng của đường biên và kiểm soát hiện tượng <em>quá khớp</em>.</p>
<p>Trong python để <em>phân loại đường biên mềm</em> thì chúng ta có thể sử dụng module <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">sklearn.svm.SVC</a> hoặc <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html">sklearn.svm.LinearSVC</a> thông qua việc thiết lập đối số <span class="math notranslate nohighlight">\(C\)</span> thấp. Ở ví dụ hình 2 bạn cũng có thể thấy với <code class="docutils literal notranslate"><span class="pre">Soft</span> <span class="pre">Margin</span> <span class="pre">SVM</span></code> thì chúng ta để <span class="math notranslate nohighlight">\(C=0.05\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> cũng tương ứng với <code class="docutils literal notranslate"><span class="pre">SVC</span></code> với cấu hình <code class="docutils literal notranslate"><span class="pre">kernel='linear'</span></code>, module <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> có tốc độ nhanh hơn so với <code class="docutils literal notranslate"><span class="pre">SVC</span></code> nên được khuyến nghị hồi qui với những tập dữ liệu lớn. Khi huấn luyện với bộ dữ liệu kích thước nhỏ (khoảng vài ngàn quan sát) thì có thể sử dụng SVC. Ưu điểm của <code class="docutils literal notranslate"><span class="pre">SVC</span></code> đó là chúng ta được phép lựa chọn đa dạng các phép biến đổi kernel. Trong khi <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> là phương pháp dựa trên kernel <code class="docutils literal notranslate"><span class="pre">linear</span></code>. Trong <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> cho phép chúng ta lựa chọn được loại hàm điều chuẩn thông qua đối số <code class="docutils literal notranslate"><span class="pre">penalty</span></code> và dạng của hàm mất mát thông qua đối số <code class="docutils literal notranslate"><span class="pre">loss</span></code>.</p>
<p>Tiếp theo chúng ta sẽ cùng tìm hiểu về kernel trong thuật toán SVM.</p>
</div>
</div>
<div class="section" id="kernel-trong-svm">
<h1>7.4. Kernel trong SVM<a class="headerlink" href="#kernel-trong-svm" title="Permalink to this headline">¶</a></h1>
<p>Trong thuật toán <em>phân loại đường biên mềm</em> SVM chúng ta sẽ quyết định nhãn cho một điểm dữ liệu dựa vào đường biên phân loại như sau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
y = \left\{
\begin{matrix}
1 \text{ if } b + \mathbf{w}^{\intercal}\mathbf{x}_i \geq 0 \\
-1 \text{ if otherwise}
\end{matrix}
\right.\end{split}\end{split}\]</div>
<p>Như vậy trong trường hợp mô hình phân loại kém thì <span class="math notranslate nohighlight">\(b + \mathbf{w}^{\intercal}\mathbf{x}_i\)</span> sẽ là một đường biên rất đơn giản. Để tạo tính phi tuyến cho đường biên phân chia thì trong SVM chúng ta sử dụng các hàm kernel thay cho biến đầu vào.</p>
<p>Một cách khái quát, giả định các hàm <span class="math notranslate nohighlight">\(f_1(.), f_2(.), \dots , f_n(.)\)</span> là các hàm biến đổi phi tuyến. Khi đó phương trình đường biên sẽ được chuyển sang phương trình của hàm biến đổi phi tuyến như sau:</p>
<div class="math notranslate nohighlight">
\[h(\mathbf{x}, \mathbf{w}) = b + w_1f_1(\mathbf{x}) + w_2 f_2(\mathbf{x}) + \dots + w_n f_n(\mathbf{x}) \tag{5}\]</div>
<p>Thông qua biến đổi phi tuyến có thể tạo ra được những đường biên phân loại phức tạp hơn và giúp cải thiện độ chính xác của mô hình phân loại.</p>
<p>Để tìm ra những hàm biến đổi phi tuyến, chúng ta phải căn cứ vào các hàm kernel được sử dụng trong SVM. Hàm kernel chính là tích vô hướng giữa hai véc tơ trong không gian cao chiều sau khi đi qua biến đổi phi tuyến. Thông thường chúng ta có thể tính được trực tiếp hàm kernel thông qua toạ độ của các véc tơ trong không gian gốc.</p>
<div class="section" id="kernel-rbf">
<h2>7.4.1. Kernel RBF<a class="headerlink" href="#kernel-rbf" title="Permalink to this headline">¶</a></h2>
<p>Trên phân phối của tập dữ liệu chúng ta xác định một tập hợp các điểm landmark.
Landmark ở đây có thể được hiểu như là những điểm tiêu biểu đại diện cho các nhãn.</p>
<p>Hàm kernel RGB đo lường mức độ tương đồng giữa một điểm dữ liệu <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> bất kỳ với một điểm landmark <span class="math notranslate nohighlight">\(l\)</span> có dạng như sau:</p>
<div class="math notranslate nohighlight">
\[\phi(\mathbf{x}, l) = \exp(-\frac{||\mathbf{x}-l||_2^2}{2\sigma^2})\]</div>
<p>Ký hiệu <span class="math notranslate nohighlight">\(||\mathbf{x}||_2\)</span> là <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_algebra/appendix_algebra.html#khai-niem-chuan">chuẩn bậc hai</a> của <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. Các bạn có nhận ra hàm số trên quen thuộc chứ ? Nếu chúng ta coi <span class="math notranslate nohighlight">\(l\)</span> như là tâm của các phân phối dữ liệu và <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> là các điểm dữ liệu ngẫu nhiên thì hàm <span class="math notranslate nohighlight">\(\phi(\mathbf{x}, l)\)</span> chính là <em>hàm mật độ xác suất</em> pdf của phân phối chuẩn có tâm là <span class="math notranslate nohighlight">\(l\)</span>. Hình dạng của phân phối này là một hình quả chuông đối xứng hai bên qua tâm.</p>
<p><img alt="" src="https://ds055uzetaobb.cloudfront.net/image_optimizer/1dbcc5a80e3fb541aa4678fcff58bb26ca717902.png" /></p>
<p>Giá trị của <span class="math notranslate nohighlight">\(\phi(\mathbf{x}, l)\)</span> sẽ tiến gần tới 1 trong trường hợp <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> và <span class="math notranslate nohighlight">\(l\)</span> gần nhau và trường hợp những điểm này là cách xa nhau thì giá trị <span class="math notranslate nohighlight">\(\phi(\mathbf{x}, l)\)</span> sẽ tiến dần tới 0.</p>
<p>Ý tưởng của phương pháp kernel RGB đó là đưa thêm thước đo độ tương đồng giữa điểm dữ liệu với các landmark vào mô hình. Như vậy các điểm phân phối gần landmark thì có giá trị kernel gần 1 và tách biệt so với các điểm nằm cách xa landmark. Những điểm này sẽ có giá trị gần 0. Sử dụng toạ độ được tính toán sau khi chiếu lên không gian kernel thì chúng ta sẽ thấy được sự tách biệt rõ ràng giữa hai nhóm.</p>
<p><img alt="" src="https://i.imgur.com/wlBAdui.jpeg" /></p>
<p>Chẳng hạn trong hình minh hoạ trên chúng ta có hai điểm landmark là <span class="math notranslate nohighlight">\(l_1\)</span> và <span class="math notranslate nohighlight">\(l_2\)</span> tạo thành một hình dạng phân phối đặc trưng cho một lớp (phân phối được bao quanh bởi đường nét đứt). Điểm <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> gần <span class="math notranslate nohighlight">\(l_1\)</span> và <span class="math notranslate nohighlight">\(\mathbf{x}_2\)</span> nằm gần <span class="math notranslate nohighlight">\(l_2\)</span>. Khi thực hiện phép biến đổi theo kernel RBF trên hai điểm landmark thì chúng ta chuyển sang một hệ trục toạ độ mới là <span class="math notranslate nohighlight">\(f_1\)</span> và <span class="math notranslate nohighlight">\(f_2\)</span>. Giá trị ánh xạ từ một điểm <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> lên trục toạ độ này là một điểm có toạ độ:</p>
<div class="math notranslate nohighlight">
\[(\phi(\mathbf{x}, l_1), \phi(\mathbf{x},l_2))\]</div>
<p>Thể hiện trên hình bên phải là 3 điểm ảnh <span class="math notranslate nohighlight">\(\mathbf{x}_1, \mathbf{x}_2, \mathbf{x}_3\)</span> của hình bên trái. Ta nhận thấy <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> do gần <span class="math notranslate nohighlight">\(l_1\)</span> hơn nên có <span class="math notranslate nohighlight">\(f_1\)</span> cao và <span class="math notranslate nohighlight">\(f_2\)</span> thấp; tương tự như vậy <span class="math notranslate nohighlight">\(\mathbf{x}_2\)</span> gần <span class="math notranslate nohighlight">\(l_2\)</span> hơn nên có <span class="math notranslate nohighlight">\(f_2\)</span> cao, <span class="math notranslate nohighlight">\(f_1\)</span> thấp. <span class="math notranslate nohighlight">\(\mathbf{x}_3\)</span> thì cách xa cả hai điểm landmarks này nên có toạ độ sát điểm <span class="math notranslate nohighlight">\((0, 0)\)</span>. Trên không gian chiếu ta dễ dàng phân biệt được ảnh của các điểm này bằng một đường biên nét đứt.</p>
</div>
<div class="section" id="dieu-kien-cua-ham-kernel">
<h2>7.4.2. Điều kiện của hàm kernel<a class="headerlink" href="#dieu-kien-cua-ham-kernel" title="Permalink to this headline">¶</a></h2>
<p>Theo định lý merce thì hàm <span class="math notranslate nohighlight">\(\phi(\mathbf{x},\mathbf{y})\)</span> cần thoả mãn một số điều kiện để trở thành một hàm kernel. Trong đó một điều kiện quan trọng là <span class="math notranslate nohighlight">\(\phi()\)</span> phải là một hàm liên tục và đối xứng. Tức là <span class="math notranslate nohighlight">\(\phi(\mathbf{x},\mathbf{y}) = \phi(\mathbf{x},\mathbf{y})\)</span>. Tính chất này là để đảm bảo tồn tại một hàm <span class="math notranslate nohighlight">\(\varphi\)</span> ánh xạ các véc tơ <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> và <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> lên không gian cao chiều sao cho tích vô hướng: <span class="math notranslate nohighlight">\(\phi(\mathbf{x},\mathbf{y}) = \varphi(\mathbf{x})^{\intercal} \varphi(\mathbf{y})\)</span>.</p>
<p>Lưu ý rằng hầu hết mọi hàm kernel đều thoả mãn mọi điều kiện merce nhưng vẫn có một số hàm kernel không thoả mãn vẫn hoạt động khá hiệu quả, chẳng hạn như Kernel Sigmoid mà ta sẽ tìm hiểu sau.</p>
<p><span class="math notranslate nohighlight">\(\varphi(\mathbf{x})\)</span> chính là biểu diễn các véc tơ <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> trong không gian cao chiều mới. Giả định chúng ta muốn áp dụng một hàm kernel đa thức bậc 2 dạng <span class="math notranslate nohighlight">\(\phi(\mathbf{x}, \mathbf{y}) = (\mathbf{x}^{\intercal}\mathbf{y})^2\)</span> thì <span class="math notranslate nohighlight">\(\varphi\)</span> có thể là hàm <span class="math notranslate nohighlight">\(\varphi(\mathbf{x}) = [x_1^2, \sqrt{2 x_1 x_2}, x_2^2]^{\intercal}\)</span>. Trong đó <span class="math notranslate nohighlight">\(\mathbf{x} = [x_1, x_2]\)</span> và <span class="math notranslate nohighlight">\(\mathbf{y} = [y_1, y_2]\)</span>. Thật vậy:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
\varphi(\mathbf{x})^{\intercal} \varphi(\mathbf{y}) &amp; = &amp; [x_1^2, \sqrt{2 x_1 x_2}, x_2^2] [y_1^2, \sqrt{2 y_1 y_2}, y_2^2]^{\intercal} \\
&amp; = &amp; x_1^2y_1^2 + 2 x_1 x_2 y_1 y_2 + x_2^2 y_2^2 = (x_1 y_1 + x_2 y_2)^2 = (\mathbf{x}^{\intercal}\mathbf{y})^2
\end{eqnarray}\end{split}\]</div>
<p>Như vậy từ không gian 2 chiều, các véc tơ đã được biến đổi sang không gian 3 chiều. Ngoài hàm kernel RBF mà chúng ta đã tìm hiểu ở mục 7.4.1 thì chúng ta còn một số hàm kernel khác được áp dụng phổ biến trong SVM.</p>
</div>
<div class="section" id="cac-kernel-khac-cho-svm">
<h2>7.4.3. Các kernel khác cho SVM<a class="headerlink" href="#cac-kernel-khac-cho-svm" title="Permalink to this headline">¶</a></h2>
<p>Ngoài kernel RBF chúng ta còn một số kernel khác cho SVM như sau:</p>
<ul class="simple">
<li><p>Kernel tuyến tính (<em>linear</em>): Đây là tích vô hướng giữa hai véc tơ.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\phi(\mathbf{x}_1\mathbf{x}_2) = \mathbf{x}_1^{\intercal}\mathbf{x}_2\]</div>
<ul class="simple">
<li><p>Kernel đa thức (<em>poly</em>): Tạo ra một đa thức bậc cao kết hợp giữa hai véc tơ.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\phi(\mathbf{x}_1, \mathbf{x}_2) = (\gamma \mathbf{x}_1^{\intercal}\mathbf{x}_2+r)^d\]</div>
<ul class="simple">
<li><p>Kernel Sigmoid: Dựa trên kernel về đa thức, chúng ta đưa chuyển tiếp qua hàm tanh. Hàm tanh có thể biểu diễn theo hàm sigmoid nên đây được gọi là kernel Sigmoid.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\phi(\mathbf{x}_1, \mathbf{x}_2) = \text{tanh}(\gamma \mathbf{x}_1^{\intercal}\mathbf{x}_2+r)\]</div>
<p>Trong quá trình huấn luyện SVM chúng ta cần thử với những kernel khác nhau để tìm ra một kernel hiệu quả. Ở mục 6 thực hành các bạn sẽ được làm quen với việc tunning kernel.</p>
<p>Chú ý đối với các từng kernel thì chúng ta lại có thể tunning các siêu tham số (<em>hyperameter</em>) của chúng. Chẳng hạn như trong kernel đa thức chúng ta có thể tunning đối với bậc <span class="math notranslate nohighlight">\(d\)</span> của đa thức và hệ số <span class="math notranslate nohighlight">\(\gamma\)</span>. Những phần này sẽ được hướng dẫn chi tiết hơn ở mục 6.</p>
</div>
</div>
<div class="section" id="vi-du-ve-bai-toan-svm">
<h1>7.5. Ví dụ về bài toán SVM<a class="headerlink" href="#vi-du-ve-bai-toan-svm" title="Permalink to this headline">¶</a></h1>
<p>Tiếp theo chúng ta sẽ cùng sử dụng SVM để phân loại bộ dữ liệu <code class="docutils literal notranslate"><span class="pre">iris</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RepeatedStratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span> <span class="c1"># 1 if virginica, 0 else</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv</span> <span class="o">=</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">svm_pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">((</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;linear_svc&quot;</span><span class="p">,</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">probability</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>
  <span class="p">)</span>
<span class="p">)</span>

<span class="n">svm_pl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">svm_pl</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean Accuracy: </span><span class="si">{:.03f}</span><span class="s1">, Standard Deviation Accuracy: </span><span class="si">{:.03f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">scores</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean Accuracy: 0.960, Standard Deviation Accuracy: 0.050
</pre></div>
</div>
</div>
</div>
<p>Dự báo cho một quan sát mới</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dự báo nhãn</span>
<span class="n">svm_pl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">]]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1], dtype=int8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dự báo xác suất, chỉ được khi probability trong SVC() được set True.</span>
<span class="n">svm_pl</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">3.2</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">]]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[3.0000009e-14, 1.0000000e+00]])
</pre></div>
</div>
</div>
</div>
<div class="section" id="bai-toan-svm-cho-du-lieu-dang-phi-tuyen">
<h2>7.5.1. Bài toán SVM cho dữ liệu dạng phi tuyến<a class="headerlink" href="#bai-toan-svm-cho-du-lieu-dang-phi-tuyen" title="Permalink to this headline">¶</a></h2>
<p>Mặc dù SVM có kết quả khá tốt cho bài toán phân loại nhưng có một số tình huống dữ liệu là phức tạp và yêu cầu chúng ta phải thực hiện các phép biến đổi phi tuyến đối với biến đầu vào để tạo thành những đường biên phức tạp hơn. Kỹ thuật chuẩn hoá đa thức (<em>polynormial</em>) được áp dụng để tạo ra những biến bậc cao sẽ hữu ích trong những tình huống này:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="n">svm_ply_pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">((</span>
    <span class="p">(</span><span class="s2">&quot;poly_features&quot;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">)),</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;linear_svc&quot;</span><span class="p">,</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">probability</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>
  <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv</span> <span class="o">=</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">svm_ply_pl</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean Accuracy: </span><span class="si">{:.03f}</span><span class="s1">, Standard Deviation Accuracy: </span><span class="si">{:.03f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">scores</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean Accuracy: 0.969, Standard Deviation Accuracy: 0.041
</pre></div>
</div>
</div>
</div>
<p>Như vậy sau khi áp dụng <em>chuẩn hoá đa thức</em> thì độ chính xác đã tăng lên từ <code class="docutils literal notranslate"><span class="pre">0.96</span></code> lên <code class="docutils literal notranslate"><span class="pre">0.969</span></code>. Đây là một trong những kỹ thuật thường được áp dụng để giúp cải thiện độ chính xác cho SVM.</p>
<p>Trên thực thế thì kỹ thuật chuẩn hoá đa thức cũng tương tự như việc sử dụng kernel <code class="docutils literal notranslate"><span class="pre">poly</span></code> trong module SVC. Lưu ý rằng mặc dù kỹ thuật chuẩn hoá đa thức thường mang lại sự cải tiến đáng kể về độ chính xác cho mô hình nhưng số lượng biến mà nó tạo ra bao gồm những biến tích chéo (dạng <span class="math notranslate nohighlight">\(x_1^p x_2^q\)</span>) và biến bậc cao (dạng <span class="math notranslate nohighlight">\(x_1^l\)</span>) là rất lớn. Do đó sẽ dễ xảy ra hiện tượng <em>quá khớp</em> và đồng thời gia tăng chi phí huấn luyện và tính toán.</p>
<p>Tiếp theo ta sẽ thực hành tunning kernel trong SVM.</p>
</div>
<div class="section" id="su-dung-kernel-svm">
<h2>7.5.2. Sử dụng kernel SVM<a class="headerlink" href="#su-dung-kernel-svm" title="Permalink to this headline">¶</a></h2>
<p>Khi huấn luyện mô hình SVM chúng ta cần thử với nhiều kernels khác nhau để tìm ra kernel tốt nhất cho bộ dữ liệu huấn luyện. Các kernel phổ biến đó là:
<code class="docutils literal notranslate"><span class="pre">linear,</span> <span class="pre">poly,</span> <span class="pre">rbf,</span> <span class="pre">sigmoid</span></code> như đã được giới thiệu ở mục 5.</p>
<p>Ngoài ra nếu mô hình gặp hiện tượng quá khớp thì chúng ta cần điều chỉnh giảm hệ số <span class="math notranslate nohighlight">\(C\)</span> của mô hình SVM để gia tăng ảnh hưởng của thành phần kiểm soát.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>


<span class="n">kernels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">]</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">all_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># Đánh giá toàn bộ các mô hình trên tập K-Fold đã chia</span>
<span class="k">for</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="n">kernels</span><span class="p">:</span>
  <span class="n">svm_kn_pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">((</span>
      <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
      <span class="p">(</span><span class="s2">&quot;linear_svc&quot;</span><span class="p">,</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">probability</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>
    <span class="p">)</span>
  <span class="p">)</span>
  <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">svm_kn_pl</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">all_scores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">kernel</span><span class="p">,</span> <span class="n">scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Draw bboxplot </span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">([</span><span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">all_scores</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Scale&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;cm&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">kernels</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernels</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Scores Metrics&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Scores Metrics&#39;)
</pre></div>
</div>
<img alt="../_images/SVM_35_1.png" src="../_images/SVM_35_1.png" />
</div>
</div>
<p>Như vậy ta có thể thấy các kernel hiệu quả chính là <code class="docutils literal notranslate"><span class="pre">rbf</span></code> và <code class="docutils literal notranslate"><span class="pre">linear</span></code> khi cùng có giá trị trung vị vào khoảng 0.97 và cao hơn mức trung bình của kernel kém nhất là <code class="docutils literal notranslate"><span class="pre">Sigmoid</span></code> là 0.07 điểm. Đây là một mức cải thiện khá đáng kể cho một bài toán phân loại nhị phân.</p>
</div>
<div class="section" id="tunning-sieu-tham-so-cho-mot-kernel">
<h2>7.5.3. Tunning siêu tham số cho một kernel<a class="headerlink" href="#tunning-sieu-tham-so-cho-mot-kernel" title="Permalink to this headline">¶</a></h2>
<p>Đối với mỗi một dạng hàm kernel, căn cứ vào phương trình của chúng ta có thể xác định được những siêu tham số cần tunning.</p>
<p>Chẳng hạn như đối với danh sách các kernel được cung cấp ở mục 5.1 thì chúng ta có thể tunning các tham số như sau:</p>
<ul class="simple">
<li><p>kernel tuyến tính: tham số C.</p></li>
<li><p>kernel đa thức: tham số <span class="math notranslate nohighlight">\(C, \gamma, d\)</span></p></li>
<li><p>kernel RBF: tham số <span class="math notranslate nohighlight">\(C, \gamma\)</span>.</p></li>
<li><p>kernel sigmoid: tham số <span class="math notranslate nohighlight">\(C, \gamma, d\)</span></p></li>
</ul>
<p>Công thức tổng quát của một mô hình SVC:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sklearn</span><span class="o">.</span><span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> 
  <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> 
  <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> 
  <span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
  <span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> 
  <span class="n">coef0</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> 
  <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
  <span class="n">decision_function_shape</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">,</span>
  <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Trong class SVC của sklearn thì hệ số <span class="math notranslate nohighlight">\(\gamma\)</span> tương ứng với đối số <code class="docutils literal notranslate"><span class="pre">coef0</span></code>, hệ số bậc đa thức <span class="math notranslate nohighlight">\(d\)</span> là đối số <code class="docutils literal notranslate"><span class="pre">degree</span></code>, trọng số <span class="math notranslate nohighlight">\(C\)</span> của hàm chi phí chính là đối số <code class="docutils literal notranslate"><span class="pre">C</span></code> và loại kernel là đối số <code class="docutils literal notranslate"><span class="pre">kernel</span></code>.</p>
<p>Ngoài ra trong trường hợp mẫu bị mất cân bằng nghiêm trọng thì chúng ta thiết lập <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> để phạt nặng hơn những trường hợp mẫu thiểu số.</p>
<p><code class="docutils literal notranslate"><span class="pre">decision_function_shape</span></code> là đối số cho phép chúng ta cấu hình kết quả xác suất dự báo trả về là theo phương pháp <code class="docutils literal notranslate"><span class="pre">one-vs-rest</span></code> hay <code class="docutils literal notranslate"><span class="pre">one-vs-one</span></code>. Nếu theo phương pháp <code class="docutils literal notranslate"><span class="pre">one-vs-rest</span></code> thì mô hình phân loại gồm <span class="math notranslate nohighlight">\(C\)</span> nhãn sẽ được chia thành <span class="math notranslate nohighlight">\(C\)</span> bài toán phân loại con, mỗi một bài toán tương ứng với một dự báo xác suất thuộc về nhãn <span class="math notranslate nohighlight">\(i\)</span>. Còn đối với bài toán <code class="docutils literal notranslate"><span class="pre">one-vs-one</span></code> chúng ta sẽ tìm cách xây dựng <span class="math notranslate nohighlight">\(C\times(C-1)\)</span> mô hình phân loại cho một cặp nhãn <span class="math notranslate nohighlight">\((i, j)\)</span> bất kỳ. Đối với bài toán phân loại nhị phân thì <code class="docutils literal notranslate"><span class="pre">decision_function_shape</span> <span class="pre">=</span> <span class="pre">ovr</span></code> tương ứng với dự báo xác suất tương ứng với nhãn <span class="math notranslate nohighlight">\((0, 1)\)</span>.</p>
<p>Bên dưới là một ví dụ mẫu về cách tunning tham số trên GridSearch đối với mô hình SVM.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;clf__kernel&#39;</span><span class="p">:[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">],</span>  <span class="c1"># Các dạng hàm kernel</span>
    <span class="s1">&#39;clf__C&#39;</span><span class="p">:[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="c1"># Trọng số của phạt phân loại sai</span>
    <span class="s1">&#39;clf__coef0&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="c1"># Tương ứng với tham số gamma của đa thức</span>
    <span class="s1">&#39;clf__degree&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="c1"># Bậc d của đa thức</span>
<span class="p">}</span>


<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;clf&quot;</span><span class="p">,</span> <span class="n">SVC</span><span class="p">())]</span>
<span class="p">)</span>

<span class="n">gscv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">gscv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 72 candidates, totalling 360 fits
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GridSearchCV(cv=5, error_score=0, estimator=Pipeline(steps=[(&#39;clf&#39;, SVC())]),
             n_jobs=12,
             param_grid={&#39;clf__C&#39;: [0.05, 1, 100], &#39;clf__coef0&#39;: [2, 4],
                         &#39;clf__degree&#39;: [1, 2, 3],
                         &#39;clf__kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;, &#39;poly&#39;, &#39;sigmoid&#39;]},
             return_train_score=True, scoring=&#39;accuracy&#39;, verbose=3)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="tong-ket">
<h1>7.6. Tổng kết<a class="headerlink" href="#tong-ket" title="Permalink to this headline">¶</a></h1>
<p>Như vậy qua chương này bạn đọc đã được giới thiệu những kiến thức cơ bản gồm:</p>
<ol class="simple">
<li><p>Hàm mất mát trong SVM.</p></li>
<li><p>Khái niệm về đường biên và lề.</p></li>
<li><p>Bài toán phân loại SVM với đường biên mềm và đường biên cứng.</p></li>
<li><p>Các dạng bộ lọc trong SVM.</p></li>
<li><p>Phương pháp tunning tham số đối với mô hình SVM.</p></li>
</ol>
<p>SVM làm một trong những thuật toán hoạt động khá hiệu quả trong lớp các bài toán phân loại và dự báo của học có giám sát. Nắm vững thuật toán này, bạn đọc sẽ có thêm công cụ để tạo ra những mô hình mạnh giúp giải quyết những vấn đề thực tế.</p>
</div>
<div class="section" id="bai-tap">
<h1>7.7. Bài tập<a class="headerlink" href="#bai-tap" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p>Hàm mất mát của SVM có dạng là một hàm có dạng như thế nào?</p></li>
<li><p>Giả định mô hình hồi qui SVM đang gặp hiện tượng <em>quá khớp</em>. Làm thế nào để giảm thiểu hiện tượng quá khớp cho mô hình SVM?</p></li>
<li><p>Kernel trong SVM là gì? Kernel có tác dụng như thế nào đối với mô hình SVM?</p></li>
<li><p>Có những dạng kernel chính nào trong SVM? Đặc điểm của chúng là gì?</p></li>
<li><p>Khi huấn luyện một mô hình SVM thì chúng ta cần tinh chỉnh những siêu tham số nào là chủ yếu?</p></li>
</ol>
</div>
<div class="section" id="tai-lieu">
<h1>7.8. Tài liệu<a class="headerlink" href="#tai-lieu" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Support-vector_machine">SVM - wikipedia</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47">Support Vector Machine introduction to Machine Learning Algorithms</a></p></li>
<li><p><a class="reference external" href="https://machinelearningcoban.com/2017/04/09/smv/">SVM - Machine Learning Cơ bản</a></p></li>
<li><p><a class="reference external" href="https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738">Chapter 7, Sparse Kernel Machines - Pattern Recognition Learning Information Statistics</a></p></li>
<li><p><a class="reference external" href="https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291">Chapter 5, SVM - Hands-On Machine Learning with Scikit-Learn and TensorFlow</a></p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html">SVM model sklearn</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-iii-5dff33fa015d#:%7E:text=The%20loss%20function%20of%20SVM,the%20raw%20model%20output%2C%20%CE%B8%E1%B5%80x.">Optimization loss function under the hood par</a></p></li>
</ol>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="index_SVM.html" title="previous page">7. Giới thiệu về SVM</a>
    <a class='right-next' id="next-link" href="index_DecisionTree.html" title="next page">8. Khái niệm về cây quyết định</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Pham Dinh Khanh<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>